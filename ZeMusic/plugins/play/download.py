# -*- coding: utf-8 -*-
"""
ğŸš€ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø®Ø§Ø±Ù‚ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ØªØ·ÙˆØ±Ø© V2
=====================================================
ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ù„ÙŠØ¯Ø¹Ù…:
- 5000 Ù…Ø¬Ù…ÙˆØ¹Ø© Ùˆ70,000 Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø®Ø§Øµ
- ØªØ­Ù…ÙŠÙ„ Ù…ØªÙˆØ§Ø²ÙŠ ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©
- Ø¥Ø¯Ø§Ø±Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ù…ÙˆØ§Ø±Ø¯
- Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø©
- Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© ÙˆØªØªØ¨Ø¹ Ù…ØªÙ‚Ø¯Ù…
"""

import os
import re
import asyncio
import logging
import time
import sqlite3
import hashlib
import concurrent.futures
from typing import Dict, Optional, List, Tuple
from itertools import cycle
import aiohttp
import aiofiles
from telethon.tl.types import DocumentAttributeAudio
from pathlib import Path
import uvloop
import psutil
import random
import string
from contextlib import asynccontextmanager
import orjson

# ØªØ·Ø¨ÙŠÙ‚ UVLoop Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ asyncio
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    import yt_dlp
except ImportError:
    yt_dlp = None
    
try:
    from youtube_search import YoutubeSearch
except ImportError:
    try:
        from youtubesearchpython import VideosSearch
        YoutubeSearch = VideosSearch
    except ImportError:
        YoutubeSearch = None

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Telethon
from telethon import events
from telethon.types import Message

import config
from ZeMusic.core.telethon_client import telethon_manager
from ZeMusic.logging import LOGGER
from ZeMusic.utils.database import is_search_enabled, is_search_enabled1
# from ZeMusic.utils.monitoring import PerformanceMonitor

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ ---
REQUEST_TIMEOUT = 8
DOWNLOAD_TIMEOUT = 90
MAX_SESSIONS = min(100, (psutil.cpu_count() * 4))  # Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
MAX_WORKERS = min(200, (psutil.cpu_count() * 10))  # Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬

# Ù‚Ù†Ø§Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ (ÙŠÙˆØ²Ø± Ø£Ùˆ ID)
SMART_CACHE_CHANNEL = config.CACHE_CHANNEL_ID

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¶
channel = getattr(config, 'STORE_LINK', '')
lnk = f"https://t.me/{channel}" if channel else None

# --- ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØ§Ù„Ø®ÙˆØ§Ø¯Ù… ---
YT_API_KEYS = config.YT_API_KEYS
API_KEYS_CYCLE = cycle(YT_API_KEYS) if YT_API_KEYS else None

INVIDIOUS_SERVERS = config.INVIDIOUS_SERVERS
INVIDIOUS_CYCLE = cycle(INVIDIOUS_SERVERS) if INVIDIOUS_SERVERS else None

# ØªØ¯ÙˆÙŠØ± Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆÙƒÙŠØ²
COOKIES_FILES = config.COOKIES_FILES
COOKIES_CYCLE = cycle(COOKIES_FILES) if COOKIES_FILES else None

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª yt-dlp Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¯Ø§Ø¡ ---
def get_ytdlp_opts(cookies_file=None) -> Dict:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù€ yt-dlp Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    opts = {
        "format": "bestaudio/best",
        "noplaylist": True,
        "quiet": True,
        "retries": 2,
        "no-cache-dir": True,
        "ignoreerrors": True,
        "socket-timeout": REQUEST_TIMEOUT,
        "force-ipv4": True,
        "throttled-rate": "1M",
        "extractor-args": "youtube:player_client=android,web",
        "concurrent-fragments": 16,  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
        "outtmpl": "downloads/%(id)s.%(ext)s",
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "192",
        }],
        "postprocessor_args": ["-ar", "44100", "-threads", "4"],
        "noprogress": True,
        "verbose": False,
        "http-chunk-size": "1M",
        "limit-rate": "5M",
        "buffer-size": "16M",
        "extractor-retries": 3,
        "fragment-retries": 5,
        "skip-unavailable-fragments": True,
        "merge-output-format": "mp3",
    }
    
    if cookies_file and os.path.exists(cookies_file):
        opts["cookiefile"] = cookies_file
    
    # Ø¥Ø¶Ø§ÙØ© aria2c Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±
    import shutil
    if shutil.which("aria2c"):
        opts.update({
            "external_downloader": "aria2c",
            "external_downloader_args": [
                "-x", "16", 
                "-s", "16", 
                "-k", "2M",
                "--file-allocation=none",
                "--summary-interval=0"
            ],
        })
    
    return opts

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„Ø§Øª
os.makedirs("downloads", exist_ok=True)

# --- Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø°ÙƒÙŠØ© ---
DB_FILE = "smart_cache.db"

async def init_database():
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    # ØªØ­Ø³ÙŠÙ† Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS channel_index (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            message_id INTEGER UNIQUE,
            file_id TEXT UNIQUE,
            file_unique_id TEXT,
            
            search_hash TEXT UNIQUE,
            title_normalized TEXT,
            artist_normalized TEXT,
            keywords_vector TEXT,
            
            original_title TEXT,
            original_artist TEXT,
            duration INTEGER,
            file_size INTEGER,
            
            access_count INTEGER DEFAULT 0,
            last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            popularity_rank REAL DEFAULT 0,
            
            phonetic_hash TEXT,
            partial_matches TEXT,
            
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙÙ‡Ø§Ø±Ø³
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_search_hash ON channel_index(search_hash)",
        "CREATE INDEX IF NOT EXISTS idx_title_norm ON channel_index(title_normalized)",
        "CREATE INDEX IF NOT EXISTS idx_artist_norm ON channel_index(artist_normalized)",
        "CREATE INDEX IF NOT EXISTS idx_popularity ON channel_index(popularity_rank DESC)",
        "CREATE INDEX IF NOT EXISTS idx_message_id ON channel_index(message_id)",
        "CREATE INDEX IF NOT EXISTS idx_file_id ON channel_index(file_id)",
        "CREATE INDEX IF NOT EXISTS idx_keywords ON channel_index(keywords_vector)"
    ]
    
    for index_sql in indexes:
        cursor.execute(index_sql)
    
    conn.commit()
    conn.close()

# ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ÙˆØ­Ø¯Ø©
# Ø³ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø£ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù…
_database_initialized = False

async def ensure_database_initialized():
    """Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    global _database_initialized
    if not _database_initialized:
        await init_database()
        _database_initialized = True

# ================================================================
#                 Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
# ================================================================
class ConnectionManager:
    """Ù…Ø¯ÙŠØ± Ø§ØªØµØ§Ù„Ø§Øª Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª"""
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._session_pool = []
            cls._instance._executor_pool = None
            cls._instance._db_connections = {}
        return cls._instance
    
    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© ØªØ¬Ù…Ø¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        # ØªØ¬Ù…Ø¹ Ø¬Ù„Ø³Ø§Øª HTTP
        connector = aiohttp.TCPConnector(
            limit_per_host=200,
            ttl_dns_cache=600,
            use_dns_cache=True,
            keepalive_timeout=45,
            enable_cleanup_closed=True
        )
        
        self._session_pool = [
            aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT),
                headers={'User-Agent': f'ZeMusic-{i}'},
                json_serialize=orjson.dumps
            ) for i in range(MAX_SESSIONS)
        ]
        
        # ØªØ¬Ù…Ø¹ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ†ÙÙŠØ°
        self._executor_pool = concurrent.futures.ThreadPoolExecutor(
            max_workers=MAX_WORKERS,
            thread_name_prefix="DLWorker"
        )
        
        LOGGER(__name__).info(f"ğŸš€ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª: {MAX_SESSIONS} Ø¬Ù„Ø³Ø©, {MAX_WORKERS} Ø¹Ø§Ù…Ù„")
    
    @property
    def session_pool(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¬Ù…Ø¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª"""
        if not self._session_pool:
            raise RuntimeError("ConnectionManager not initialized")
        return self._session_pool
    
    @property
    def executor_pool(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¬Ù…Ø¹ Ø§Ù„Ø¹Ù…Ø§Ù„"""
        if not self._executor_pool:
            raise RuntimeError("Executor pool not initialized")
        return self._executor_pool
    
    async def get_session(self) -> aiohttp.ClientSession:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù„Ø³Ø© Ù…ØªØ§Ø­Ø©"""
        if not self._session_pool:
            await self.initialize()
        return random.choice(self._session_pool)
    
    @asynccontextmanager
    async def db_connection(self):
        """Ø¥Ø¯Ø§Ø±Ø© Ø§ØªØµØ§Ù„Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        conn = sqlite3.connect(DB_FILE, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()
    
    async def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯"""
        for session in self._session_pool:
            await session.close()
        self._executor_pool.shutdown(wait=True)
        LOGGER(__name__).info("ğŸ”Œ ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø¬Ù…ÙŠØ¹ Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„")

# ================================================================
#                 Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø®Ø§Ø±Ù‚
# ================================================================
class HyperSpeedDownloader:
    """Ù†Ø³Ø®Ø© Ù…ØªØ·ÙˆØ±Ø© Ù…Ù† Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù…ÙˆØ§Ø±Ø¯"""
    
    def __init__(self):
        self.conn_manager = ConnectionManager()
        self.method_performance = {
            'cache': {'weight': 1000, 'active': True, 'avg_time': 0.001},
            'youtube_api': {'weight': 100, 'active': True, 'avg_time': 1.5},
            'invidious': {'weight': 90, 'active': True, 'avg_time': 2.5},
            'ytdlp_cookies': {'weight': 85, 'active': True, 'avg_time': 4.0},
            'ytdlp_no_cookies': {'weight': 70, 'active': True, 'avg_time': 6.0},
            'youtube_search': {'weight': 60, 'active': True, 'avg_time': 3.5}
        }
        # self.monitor = PerformanceMonitor()
        self.active_tasks = set()
        self.cache_hits = 0
        self.cache_misses = 0
        self.last_health_check = time.time()
        
        # ØªØ³Ø¬ÙŠÙ„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„
        LOGGER(__name__).info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØ·ÙˆØ± V2")
    
    async def health_check(self):
        """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±ÙŠ"""
        if time.time() - self.last_health_check > 300:  # ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚
            self.last_health_check = time.time()
            
            # ØªØ³Ø¬ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
            stats = {
                'cache_hits': self.cache_hits,
                'cache_misses': self.cache_misses,
                'cache_hit_rate': self.cache_hits / max(1, self.cache_hits + self.cache_misses) * 100,
                'active_tasks': len(self.active_tasks),
                'memory_usage': psutil.virtual_memory().percent,
                'cpu_usage': psutil.cpu_percent(),
            }
            
            LOGGER(__name__).info(
                f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…: "
                f"Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {stats['memory_usage']}% | "
                f"Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {stats['cpu_usage']}% | "
                f"Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: {stats['active_tasks']} | "
                f"Ù†Ø³Ø¨Ø© Ø§Ù„ÙƒØ§Ø´: {stats['cache_hit_rate']:.1f}%"
            )
    
    def normalize_text(self, text: str) -> str:
        """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ù„Ù„Ø¨Ø­Ø« Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if not text:
            return ""
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ø£Ø­Ø±Ù Ø§Ù„ØµØºÙŠØ±Ø© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
        text = text.lower()
        text = re.sub(r'[\u064B-\u065F]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        text = re.sub(r'[^\w\s]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²
        text = re.sub(r'\s+', ' ', text).strip()  # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¬Ø¯ÙˆÙ„ ØªØ­ÙˆÙŠÙ„
        replacements = {
            'Ø©': 'Ù‡', 'ÙŠ': 'Ù‰', 'Ø£': 'Ø§', 'Ø¥': 'Ø§',
            'Ø¢': 'Ø§', 'Ø¤': 'Ùˆ', 'Ø¦': 'ÙŠ', 'Ù±': 'Ø§',
            'Ù°': '', 'Ù‘': '', 'Ù’': '', 'ÙŒ': '',
            'Ù': '', 'Ù‹': '', 'Ù': '', 'Ù': '',
            'Ù': '', '~': '', 'Ù€': ''
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text
    
    def create_search_hash(self, title: str, artist: str = "") -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø§Ø´ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø£Ø³Ø±Ø¹"""
        normalized_title = self.normalize_text(title)
        normalized_artist = self.normalize_text(artist)
        combined = f"{normalized_title}_{normalized_artist}".encode()
        return hashlib.md5(combined, usedforsecurity=False).hexdigest()[:12]
    
    async def lightning_search_cache(self, query: str) -> Optional[Dict]:
        """Ø¨Ø­Ø« Ø®Ø§Ø·Ù ÙÙŠ Ø§Ù„ÙƒØ§Ø´ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            normalized_query = self.normalize_text(query)
            search_hash = self.create_search_hash(normalized_query)
            
            async with self.conn_manager.db_connection() as conn:
                cursor = conn.cursor()
                
                # Ø¨Ø­Ø« Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ù„Ù‡Ø§Ø´
                cursor.execute(
                    "SELECT message_id, file_id, original_title, original_artist, duration "
                    "FROM channel_index WHERE search_hash = ? LIMIT 1",
                    (search_hash,)
                )
                result = cursor.fetchone()
                
                if result:
                    # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
                    cursor.execute(
                        "UPDATE channel_index SET access_count = access_count + 1, "
                        "last_accessed = CURRENT_TIMESTAMP WHERE search_hash = ?",
                        (search_hash,)
                    )
                    conn.commit()
                    
                    self.cache_hits += 1
                    return {
                        'message_id': result[0],
                        'file_id': result[1],
                        'title': result[2],
                        'artist': result[3],
                        'duration': result[4],
                        'source': 'cache',
                        'cached': True
                    }
                
                # Ø¨Ø­Ø« ØªÙ‚Ø±ÙŠØ¨ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙ‡Ø±Ø³ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
                keywords = normalized_query.split()
                keyword_conditions = " OR ".join(["keywords_vector LIKE ?" for _ in keywords])
                params = [f"%{kw}%" for kw in keywords]
                
                cursor.execute(
                    f"SELECT message_id, file_id, original_title, original_artist, duration "
                    f"FROM channel_index WHERE {keyword_conditions} "
                    f"ORDER BY popularity_rank DESC LIMIT 1",
                    params
                )
                result = cursor.fetchone()
                
                if result:
                    self.cache_hits += 1
                    return {
                        'message_id': result[0],
                        'file_id': result[1],
                        'title': result[2],
                        'artist': result[3],
                        'duration': result[4],
                        'source': 'cache_fuzzy',
                        'cached': True
                    }
            
            self.cache_misses += 1
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹: {e}")
            self.monitor.log_error('cache_search')
        
        return None
    
    async def youtube_api_search(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± YouTube Data API Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if not API_KEYS_CYCLE:
            return None
        
        session = await self.conn_manager.get_session()
        start_time = time.time()
        
        try:
            for _ in range(len(YT_API_KEYS)):
                key = next(API_KEYS_CYCLE)
                params = {
                    "part": "snippet",
                    "q": query,
                    "type": "video",
                    "maxResults": 1,
                    "key": key,
                    "videoCategoryId": "10",  # Ù…ÙˆØ³ÙŠÙ‚Ù‰ ÙÙ‚Ø·
                    "relevanceLanguage": "ar,en"
                }
                
                try:
                    async with session.get(
                        "https://www.googleapis.com/youtube/v3/search",
                        params=params,
                        timeout=REQUEST_TIMEOUT
                    ) as resp:
                        if resp.status == 403:
                            LOGGER(__name__).warning(f"Ù…ÙØªØ§Ø­ API Ù…Ø­Ø¸ÙˆØ±: {key[:5]}...")
                            continue
                            
                        if resp.status != 200:
                            continue
                        
                        data = await resp.json()
                        items = data.get("items", [])
                        if not items:
                            continue
                        
                        item = items[0]
                        video_id = item["id"]["videoId"]
                        snippet = item["snippet"]
                        
                        self.method_performance['youtube_api']['avg_time'] = (
                            self.method_performance['youtube_api']['avg_time'] * 0.7 + 
                            (time.time() - start_time) * 0.3
                        )
                        
                        return {
                            "video_id": video_id,
                            "title": snippet.get("title", "")[:60],
                            "artist": snippet.get("channelTitle", "Unknown"),
                            "thumb": snippet.get("thumbnails", {}).get("high", {}).get("url"),
                            "source": "youtube_api"
                        }
                
                except (asyncio.TimeoutError, aiohttp.ClientError):
                    continue
        
        except Exception as e:
            LOGGER(__name__).warning(f"ÙØ´Ù„ YouTube API: {e}")
            self.monitor.log_error('youtube_api')
        
        return None
    
    async def invidious_search(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± Invidious Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if not INVIDIOUS_CYCLE:
            return None
        
        session = await self.conn_manager.get_session()
        start_time = time.time()
        
        try:
            for _ in range(len(INVIDIOUS_SERVERS)):
                server = next(INVIDIOUS_CYCLE)
                url = f"{server}/api/v1/search"
                params = {
                    "q": query, 
                    "type": "video",
                    "sort_by": "relevance",
                    "duration": "short"
                }
                
                try:
                    async with session.get(
                        url, 
                        params=params,
                        timeout=REQUEST_TIMEOUT
                    ) as resp:
                        if resp.status != 200:
                            continue
                        
                        content_type = resp.headers.get('content-type', '')
                        if 'application/json' not in content_type:
                            continue
                        
                        data = await resp.json()
                        video = next((item for item in data if item.get("type") == "video"), None)
                        if not video:
                            continue
                        
                        self.method_performance['invidious']['avg_time'] = (
                            self.method_performance['invidious']['avg_time'] * 0.7 + 
                            (time.time() - start_time) * 0.3
                        )
                        
                        return {
                            "video_id": video.get("videoId"),
                            "title": video.get("title", "")[:60],
                            "artist": video.get("author", "Unknown"),
                            "duration": int(video.get("lengthSeconds", 0)),
                            "thumb": next(
                                (t.get("url") for t in reversed(video.get("videoThumbnails", []))),
                                None
                            ),
                            "source": "invidious"
                        }
                
                except (asyncio.TimeoutError, aiohttp.ClientError):
                    continue
        
        except Exception as e:
            LOGGER(__name__).warning(f"ÙØ´Ù„ Invidious: {e}")
            self.monitor.log_error('invidious')
        
        return None
    
    async def youtube_search_simple(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ø¨Ø± youtube_search Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù†Ø©"""
        if not YoutubeSearch:
            return None
        
        start_time = time.time()
            
        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… youtube_search Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù†Ø©
            search = YoutubeSearch(query, max_results=1)
            results = search.result()['result'] if hasattr(search, 'result') else search.to_dict()
            
            if not results:
                return None
            
            result = results[0]
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ video_id
            video_id = result.get('id') or result.get('link', '').split('=')[-1]
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø©
            duration = result.get('duration', '0:00')
            if isinstance(duration, str) and ':' in duration:
                parts = duration.split(':')
                if len(parts) == 2:
                    duration = int(parts[0]) * 60 + int(parts[1])
                elif len(parts) == 3:
                    duration = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
                else:
                    duration = 0
            else:
                duration = int(duration)
            
            self.method_performance['youtube_search']['avg_time'] = (
                self.method_performance['youtube_search']['avg_time'] * 0.7 + 
                (time.time() - start_time) * 0.3
            )
            
            return {
                "video_id": video_id,
                "title": result.get("title", "Unknown Title")[:60],
                "artist": result.get("channel", {}).get("name", "Unknown Artist") if isinstance(result.get("channel"), dict) else result.get("channel", "Unknown Artist"),
                "duration": duration,
                "thumb": result.get("thumbnails", [None])[0] if result.get("thumbnails") else None,
                "link": f"https://youtube.com/watch?v={video_id}",
                "source": "youtube_search"
            }
            
        except Exception as e:
            LOGGER(__name__).warning(f"ÙØ´Ù„ YouTube Search: {e}")
            self.monitor.log_error('youtube_search')
            return None
    
    async def download_with_ytdlp(self, video_info: Dict) -> Optional[Dict]:
        """ØªØ­Ù…ÙŠÙ„ Ø¹Ø¨Ø± yt-dlp Ù…Ø¹ ØªØ¯ÙˆÙŠØ± Ø§Ù„ÙƒÙˆÙƒÙŠØ²"""
        if not yt_dlp:
            return None
            
        video_id = video_info.get("video_id")
        if not video_id:
            return None
        
        url = f"https://youtu.be/{video_id}"
        start_time = time.time()
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ù…Ø¯ÙŠØ± Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø§Ù„Ø°ÙƒÙŠ
        try:
            from ZeMusic.core.cookies_manager import cookies_manager, report_cookie_success, report_cookie_failure
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ø£ÙˆÙ„Ø§Ù‹
            for attempt in range(2):  # Ù…Ø­Ø§ÙˆÙ„Ø© ÙƒÙˆÙƒÙŠØ²ÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†
                try:
                    cookies_file = await cookies_manager.get_next_cookie()
                    if not cookies_file:
                        break
                        
                    opts = get_ytdlp_opts(cookies_file)
                    
                    loop = asyncio.get_running_loop()
                    info = await loop.run_in_executor(
                        self.conn_manager.executor_pool,
                        lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
                    )
                    
                    if info:
                        audio_path = f"downloads/{video_id}.mp3"
                        if os.path.exists(audio_path):
                            # ØªÙ‚Ø±ÙŠØ± Ù†Ø¬Ø§Ø­ ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø¯Ø§Ø¡
                            await report_cookie_success(cookies_file)
                            self.method_performance['ytdlp_cookies']['avg_time'] = (
                                self.method_performance['ytdlp_cookies']['avg_time'] * 0.7 + 
                                (time.time() - start_time) * 0.3
                            )
                            
                            return {
                                "audio_path": audio_path,
                                "title": info.get("title", video_info.get("title", ""))[:60],
                                "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                                "duration": int(info.get("duration", 0)),
                                "file_size": os.path.getsize(audio_path),
                                "source": f"ytdlp_cookies_{Path(cookies_file).name}"
                            }
                
                except Exception as e:
                    # ØªÙ‚Ø±ÙŠØ± ÙØ´Ù„
                    if 'cookies_file' in locals() and cookies_file:
                        await report_cookie_failure(cookies_file, str(e))
                    LOGGER(__name__).warning(f"ÙØ´Ù„ yt-dlp Ù…Ø¹ ÙƒÙˆÙƒÙŠØ² {cookies_file}: {e}")
                    continue
                    
        except ImportError:
            # Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ù…Ø¯ÙŠØ± Ù…ØªØ§Ø­Ø§Ù‹
            if COOKIES_CYCLE:
                for _ in range(len(COOKIES_FILES)):
                    try:
                        cookies_file = next(COOKIES_CYCLE)
                        opts = get_ytdlp_opts(cookies_file)
                        
                        loop = asyncio.get_running_loop()
                        info = await loop.run_in_executor(
                            self.conn_manager.executor_pool,
                            lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
                        )
                        
                        if info:
                            audio_path = f"downloads/{video_id}.mp3"
                            if os.path.exists(audio_path):
                                return {
                                    "audio_path": audio_path,
                                    "title": info.get("title", video_info.get("title", ""))[:60],
                                    "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                                    "duration": int(info.get("duration", 0)),
                                    "file_size": os.path.getsize(audio_path),
                                    "source": f"ytdlp_cookies_{cookies_file}"
                                }
                    
                    except Exception as e:
                        LOGGER(__name__).warning(f"ÙØ´Ù„ yt-dlp Ù…Ø¹ ÙƒÙˆÙƒÙŠØ² {cookies_file}: {e}")
                        continue
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙˆÙ† ÙƒÙˆÙƒÙŠØ²
        try:
            opts = get_ytdlp_opts()
            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(
                self.conn_manager.executor_pool,
                lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
            )
            
            if info:
                audio_path = f"downloads/{video_id}.mp3"
                if os.path.exists(audio_path):
                    self.method_performance['ytdlp_no_cookies']['avg_time'] = (
                        self.method_performance['ytdlp_no_cookies']['avg_time'] * 0.7 + 
                        (time.time() - start_time) * 0.3
                    )
                    return {
                        "audio_path": audio_path,
                        "title": info.get("title", video_info.get("title", ""))[:60],
                        "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                        "duration": int(info.get("duration", 0)),
                        "file_size": os.path.getsize(audio_path),
                        "source": "ytdlp_no_cookies"
                    }
        
        except Exception as e:
            LOGGER(__name__).error(f"ÙØ´Ù„ yt-dlp Ø¨Ø¯ÙˆÙ† ÙƒÙˆÙƒÙŠØ²: {e}")
            self.monitor.log_error('ytdlp_download')
        
        return None
    
    async def cache_to_channel(self, audio_info: Dict, search_query: str) -> Optional[str]:
        """Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù‚Ù†Ø§Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Telethon"""
        if not SMART_CACHE_CHANNEL or not telethon_manager.bot_client:
            return None
        
        try:
            audio_path = audio_info["audio_path"]
            title = audio_info["title"]
            artist = audio_info["artist"]
            duration = audio_info["duration"]
            file_size = audio_info["file_size"]
            
            # Ø¥Ù†Ø´Ø§Ø¡ caption Ù„Ù„Ù…Ù„Ù
            caption = f"""ğŸµ {title}
ğŸ¤ {artist}
â±ï¸ {duration}s | ğŸ“Š {file_size/1024/1024:.1f}MB
ğŸ”— {audio_info["source"]}
ğŸ” {search_query[:50]}"""
            
            # Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ù„Ù„Ù‚Ù†Ø§Ø©
            message = await telethon_manager.bot_client.send_file(
                entity=SMART_CACHE_CHANNEL,
                file=audio_path,
                caption=caption,
                attributes=[
                    DocumentAttributeAudio(
                        duration=duration,
                        title=title[:60],
                        performer=artist[:40]
                    )
                ],
                supports_streaming=True
            )
            
            # Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            search_hash = self.create_search_hash(title, artist)
            normalized_title = self.normalize_text(title)
            normalized_artist = self.normalize_text(artist)
            keywords = f"{normalized_title} {normalized_artist} {self.normalize_text(search_query)}"
            
            async with self.conn_manager.db_connection() as conn:
                cursor = conn.cursor()
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ file_id Ù…Ù† Telethon
                file_id = message.document.id if message.document else None
                file_unique_id = getattr(message.document, 'access_hash', None)
                
                cursor.execute('''
                    INSERT OR REPLACE INTO channel_index 
                    (message_id, file_id, file_unique_id, search_hash, title_normalized, artist_normalized, 
                     keywords_vector, original_title, original_artist, duration, file_size)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    message.id, str(file_id), str(file_unique_id),
                    search_hash, normalized_title, normalized_artist, keywords,
                    title, artist, duration, file_size
                ))
                
                conn.commit()
            
            LOGGER(__name__).info(f"âœ… ØªÙ… Ø­ÙØ¸ {title} ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ")
            return str(file_id)
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ®Ø²ÙŠÙ†: {e}")
            self.monitor.log_error('cache_save')
        
        return None
    
    async def hyper_download(self, query: str) -> Optional[Dict]:
        """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ù‚ Ù„Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ø±Ù‚"""
        task_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
        self.active_tasks.add(task_id)
        start_time = time.time()
        
        try:
            # ÙØ­Øµ Ø§Ù„ØµØ­Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠ
            await self.health_check()
            
            # Ø®Ø·ÙˆØ© 1: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙÙˆØ±ÙŠ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
            cached_result = await self.lightning_search_cache(query)
            if cached_result:
                LOGGER(__name__).info(f"âš¡ ÙƒØ§Ø´ ÙÙˆØ±ÙŠ: {query} ({time.time() - start_time:.3f}s)")
                return cached_result
            
            # Ø®Ø·ÙˆØ© 2: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
            search_methods = []
            
            if API_KEYS_CYCLE:
                search_methods.append(self.youtube_api_search(query))
            if INVIDIOUS_CYCLE:
                search_methods.append(self.invidious_search(query))
            if YoutubeSearch:
                search_methods.append(self.youtube_search_simple(query))
            
            # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
            done, pending = await asyncio.wait(
                search_methods,
                timeout=REQUEST_TIMEOUT * 1.5,
                return_when=asyncio.FIRST_COMPLETED
            )
            
            # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
            for task in pending:
                task.cancel()
            
            # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù†ØªÙŠØ¬Ø© Ù†Ø§Ø¬Ø­Ø©
            video_info = None
            for task in done:
                result = task.result()
                if result:
                    video_info = result
                    break
            
            if not video_info:
                return None
            
            # Ø®Ø·ÙˆØ© 3: ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
            audio_info = await self.download_with_ytdlp(video_info)
            if not audio_info:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
                audio_info = await self.download_without_cookies(video_info)
                if not audio_info:
                    return None
            
            # Ø®Ø·ÙˆØ© 4: Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ (ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©)
            if SMART_CACHE_CHANNEL:
                asyncio.create_task(self.cache_to_channel(audio_info, query))
            
            LOGGER(__name__).info(f"âœ… ØªØ­Ù…ÙŠÙ„ Ø¬Ø¯ÙŠØ¯: {query} ({time.time() - start_time:.3f}s)")
            
            return {
                'audio_path': audio_info['audio_path'],
                'title': audio_info['title'],
                'artist': audio_info['artist'],
                'duration': audio_info['duration'],
                'source': audio_info['source'],
                'cached': False
            }
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ø§Ø±Ù‚: {e}")
            self.monitor.log_error('hyper_download')
            return None
        finally:
            self.active_tasks.discard(task_id)
    
    async def direct_ytdlp_download(self, video_id: str, title: str = "Unknown") -> Optional[Dict]:
        """ØªØ­Ù…ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… yt-dlp Ù…Ø¹ cookies"""
        if not yt_dlp:
            return None
            
        task_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
        self.active_tasks.add(task_id)
        start_time = time.time()
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª
            temp_dir = Path("downloads/temp")
            temp_dir.mkdir(parents=True, exist_ok=True)
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ yt-dlp
            try:
                from ZeMusic.core.cookies_manager import cookies_manager
                best_cookie = await cookies_manager.get_next_cookie()
            except:
                best_cookie = None
            
            ydl_opts = {
                'format': 'bestaudio[ext=m4a]/best[ext=m4a]/bestaudio/best',
                'outtmpl': str(temp_dir / f'{video_id}.%(ext)s'),
                'quiet': True,
                'no_warnings': True,
                'extract_flat': False,
                'writethumbnail': False,
                'noplaylist': True,
                'socket_timeout': REQUEST_TIMEOUT,
                'retries': 3,
                'fragment_retries': 5,
                'skip_unavailable_fragments': True,
            }
            
            # Ø¥Ø¶Ø§ÙØ© cookies Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
            if best_cookie:
                ydl_opts['cookiefile'] = best_cookie
            
            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(
                self.conn_manager.executor_pool,
                lambda: yt_dlp.YoutubeDL(ydl_opts).extract_info(
                    f"https://www.youtube.com/watch?v={video_id}",
                    download=True
                )
            )
            
            if info:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù…Ù„
                for file_path in temp_dir.glob(f"{video_id}.*"):
                    if file_path.suffix in ['.m4a', '.mp3', '.webm', '.mp4']:
                        return {
                            'success': True,
                            'file_path': str(file_path),
                            'title': info.get('title', title),
                            'duration': info.get('duration', 0),
                            'uploader': info.get('uploader', 'Unknown'),
                            'elapsed': time.time() - start_time
                        }
            
            return None
            
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {e}")
            self.monitor.log_error('direct_download')
            return None
        finally:
            self.active_tasks.discard(task_id)

    async def download_without_cookies(self, video_info: Dict) -> Optional[Dict]:
        """ØªØ­Ù…ÙŠÙ„ Ø¨Ø¯ÙˆÙ† ÙƒÙˆÙƒÙŠØ² - Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© ÙˆØ³Ø±ÙŠØ¹Ø©"""
        if not yt_dlp:
            return None
            
        video_id = video_info.get("video_id")
        if not video_id:
            return None
        
        task_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
        self.active_tasks.add(task_id)
        start_time = time.time()
        
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø³Ø±ÙŠØ¹Ø© ÙˆÙ…ÙˆØ«ÙˆÙ‚Ø©
            opts = {
                'format': 'worstaudio[ext=m4a]/worstaudio',
                'outtmpl': f'downloads/{video_id}_fallback.%(ext)s',
                'quiet': True,
                'no_warnings': True,
                'ignoreerrors': True,
                'extract_flat': False,
                'writethumbnail': False,
                'writeinfojson': False,
                'user_agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X)',
                'referer': 'https://www.google.com/',
                'timeout': 15,
                'retries': 1,
                'fragment_retries': 1,
                'skip_unavailable_fragments': True,
                'noprogress': True,
                'socket_timeout': 10,
                'force_generic_extractor': True,
            }
            
            url = f"https://youtu.be/{video_id}"
            
            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(
                self.conn_manager.executor_pool,
                lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
            )
            
            if info:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù…Ù„
                possible_files = [
                    f"downloads/{video_id}_fallback.m4a",
                    f"downloads/{video_id}_fallback.mp3",
                    f"downloads/{video_id}_fallback.webm"
                ]
                
                for audio_path in possible_files:
                    if os.path.exists(audio_path):
                        return {
                            "audio_path": audio_path,
                            "title": info.get("title", video_info.get("title", ""))[:60],
                            "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                            "duration": int(info.get("duration", 0)),
                            "file_size": os.path.getsize(audio_path),
                            "source": "ytdlp_simple_fallback",
                            "elapsed": time.time() - start_time
                        }
                        
        except Exception as e:
            LOGGER(__name__).error(f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø¯ÙˆÙ† ÙƒÙˆÙƒÙŠØ²: {e}")
            self.monitor.log_error('fallback_download')
        finally:
            self.active_tasks.discard(task_id)
            
        return None

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ
downloader = HyperSpeedDownloader()

async def remove_temp_files(*paths):
    """Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†"""
    for path in paths:
        if path and os.path.exists(path):
            try:
                os.remove(path)
                LOGGER(__name__).debug(f"ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª: {path}")
            except Exception as e:
                LOGGER(__name__).warning(f"ÙØ´Ù„ Ø­Ø°Ù {path}: {e}")

async def download_thumbnail(url: str, title: str) -> Optional[str]:
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØµØºØ±Ø© Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
    if not url:
        return None
    
    try:
        title_clean = re.sub(r'[\\/*?:"<>|]', "", title)
        thumb_path = f"downloads/thumb_{title_clean[:20]}.jpg"
        
        session = await downloader.conn_manager.get_session()
        async with session.get(url) as resp:
            if resp.status == 200:
                async with aiofiles.open(thumb_path, mode='wb') as f:
                    await f.write(await resp.read())
                return thumb_path
    except Exception as e:
        LOGGER(__name__).warning(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {e}")
    
    return None

# --- Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ù…Ø¹ Telethon ---
async def smart_download_handler(event):
    """Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù…ÙˆØ§Ø±Ø¯"""
    try:
        # ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ù‡ÙŠØ£Ø©
        await ensure_database_initialized()
        
        chat_id = event.chat_id
        if chat_id > 0:  # Ù…Ø­Ø§Ø¯Ø«Ø© Ø®Ø§ØµØ©
            if not await is_search_enabled1():
                await event.reply("âŸ¡ Ø¹Ø°Ø±Ø§Ù‹ Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨ Ù…Ø¹Ø·Ù„ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø·ÙˆØ±")
                return
        else:  # Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ùˆ Ù‚Ù†Ø§Ø©
            if not await is_search_enabled(chat_id):
                await event.reply("âŸ¡ Ø¹Ø°Ø±Ø§Ù‹ Ø¹Ø²ÙŠØ²ÙŠ Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨ Ù…Ø¹Ø·Ù„ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø·ÙˆØ±")
                return
    except:
        pass
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ø±Ø³Ù„ Ù„ÙŠØ³ Ø¨ÙˆØª
    if event.sender.bot:
        return
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù…Ù† pattern
    match = event.pattern_match
    if not match:
        return
    
    query = match.group(2) if match.group(2) else ""
    
    if not query:
        await event.reply("ğŸ“ **Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** `Ø¨Ø­Ø« Ø§Ø³Ù… Ø§Ù„Ø£ØºÙ†ÙŠØ©`")
        return
    
    # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    status_msg = await event.reply("âš¡ **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ...**")
    
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        if not yt_dlp and not YoutubeSearch:
            await status_msg.edit("âŒ **Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©**\n\nğŸ”§ **ÙŠØ­ØªØ§Ø¬ ØªØ«Ø¨ÙŠØª:** yt-dlp, youtube-search")
            return
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        await status_msg.edit("ğŸ” **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£ØºÙ†ÙŠØ©...**")
        video_info = None
        
        try:
            from youtubesearchpython import VideosSearch
            search = VideosSearch(query, limit=1)
            results = search.result()
            if results.get('result'):
                video_info = results['result'][0]
        except:
            try:
                from youtube_search import YoutubeSearch
                search = YoutubeSearch(query, max_results=1)
                video_info = search.to_dict()[0] if search.to_dict() else None
            except:
                pass
        
        if not video_info:
            await status_msg.edit("âŒ **Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø¨Ø­Ø«**\n\nğŸ’¡ **Ø¬Ø±Ø¨:**\nâ€¢ ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ©\nâ€¢ Ø§Ø³Ù… Ø§Ù„ÙÙ†Ø§Ù†\nâ€¢ Ø¬Ø²Ø¡ Ù…Ù† ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ØºÙ†ÙŠØ©")
            return
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ video_id
        video_id = video_info.get('id') or (video_info.get('link', '').split('=')[-1])
        
        if not video_id:
            await status_msg.edit("âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„ÙÙŠØ¯ÙŠÙˆ**")
            return
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
        await status_msg.edit("ğŸ”„ **Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ...**")
        download_result = await downloader.direct_ytdlp_download(video_id, video_info.get('title', 'Unknown'))
        
        if download_result and download_result.get('success'):
            # Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ø¬Ø­ - Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù
            audio_file = download_result.get('file_path')
            if audio_file and Path(audio_file).exists():
                await status_msg.edit("ğŸ“¤ **Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù...**")
                
                # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©
                duration = download_result.get('duration', 0)
                duration_str = f"{duration//60}:{duration%60:02d}" if duration > 0 else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
                
                caption = f"""ğŸµ **{download_result.get('title', 'Unknown')[:60]}**
ğŸ¤ **{download_result.get('uploader', 'Unknown')[:40]}**
â±ï¸ **{duration_str}** | âš¡ **{download_result.get('elapsed', 0):.1f} Ø«Ø§Ù†ÙŠØ©**"""
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù
                await event.respond(
                    caption,
                    file=audio_file,
                    attributes=[
                        DocumentAttributeAudio(
                            duration=duration,
                            title=download_result.get('title', 'Unknown')[:60],
                            performer=download_result.get('uploader', 'Unknown')[:40]
                        )
                    ]
                )
                await status_msg.delete()
                
                # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                await remove_temp_files(audio_file)
                return
        
        # Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙØ´Ù„ - Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ù‚
        try:
            await status_msg.edit("ğŸ”„ **ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ù‚...**")
            result = await downloader.hyper_download(query)
            
            if result:
                audio_file = result['audio_path']
                if Path(audio_file).exists():
                    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ©
                    duration = result.get('duration', 0)
                    duration_str = f"{duration//60}:{duration%60:02d}" if duration > 0 else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
                    
                    caption = f"""ğŸµ **{result.get('title', 'Ù…Ù‚Ø·Ø¹ ØµÙˆØªÙŠ')}**
ğŸ¤ **{result.get('artist', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}**
â±ï¸ **{duration_str}** | ğŸ“¦ **{result.get('source', '')}**

ğŸ’¡ **Ù…ÙØ­Ù…Ù‘Ù„ Ø¨ÙˆØ§Ø³Ø·Ø©:** @{config.BOT_USERNAME}"""
                    
                    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù
                    await telethon_manager.bot_client.send_file(
                        event.chat_id,
                        audio_file,
                        caption=caption,
                        reply_to=event.message.id,
                        supports_streaming=True,
                        attributes=[
                            DocumentAttributeAudio(
                                duration=duration,
                                title=result.get('title', '')[60],
                                performer=result.get('artist', '')[:40]
                            )
                        ]
                    )
                    
                    await status_msg.delete()
                    # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                    await remove_temp_files(audio_file)
                    return
                    
        except Exception as e:
            LOGGER(__name__).warning(f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ù‚: {e}")
        
        # Ø§Ù„ØªØ­Ù…ÙŠÙ„ ÙØ´Ù„ ÙƒÙ„ÙŠØ§Ù‹ - Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        result_text = f"""ğŸ” **ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£ØºÙ†ÙŠØ©:**

ğŸ“ **Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:** {video_info.get('title', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}
ğŸ¤ **Ø§Ù„ÙÙ†Ø§Ù†:** {video_info.get('channel', {}).get('name', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ') if isinstance(video_info.get('channel'), dict) else video_info.get('channel', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}
â±ï¸ **Ø§Ù„Ù…Ø¯Ø©:** {video_info.get('duration', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}
ğŸ‘ï¸ **Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø§Øª:** {video_info.get('viewCount', {}).get('short', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ') if isinstance(video_info.get('viewCount'), dict) else video_info.get('viewCount', 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ')}

ğŸ”— **Ø§Ù„Ø±Ø§Ø¨Ø·:** https://youtu.be/{video_id}

âš ï¸ **Ø§Ù„ØªØ­Ù…ÙŠÙ„ ØºÙŠØ± Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠØ§Ù‹:**
â€¢ Ø§Ù†ØªÙ‡Øª ØµÙ„Ø§Ø­ÙŠØ© Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆÙƒÙŠØ²
â€¢ Ù‚ÙŠÙˆØ¯ Ø£Ù…Ù†ÙŠØ© Ù…Ù† YouTube
â€¢ Ù…Ø´ÙƒÙ„Ø© Ù…Ø¤Ù‚ØªØ© ÙÙŠ Ø§Ù„Ø®Ø¯Ù…Ø©

ğŸ’¡ **Ø§Ù„Ø­Ù„:** ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø£Ø¹Ù„Ø§Ù‡
ğŸ”§ **Ù„Ù„Ù…Ø·ÙˆØ±:** ØªØ­Ø¯ÙŠØ« Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆÙƒÙŠØ² Ù…Ø·Ù„ÙˆØ¨"""
        
        await status_msg.edit(result_text)
        
    except Exception as e:
        LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {e}")
        try:
            await status_msg.edit("âŒ **Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**\n\nğŸ’¡ **Ø¬Ø±Ø¨:**\nâ€¢ ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ©\nâ€¢ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹")
        except:
            pass

# --- Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø·ÙˆØ± Ù…Ø¹ Telethon ---
async def cache_stats_handler(event):
    """Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ"""
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        async with downloader.conn_manager.db_connection() as conn:
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM channel_index")
            total_cached = cursor.fetchone()[0]
            
            cursor.execute("SELECT SUM(access_count) FROM channel_index")
            total_hits = cursor.fetchone()[0] or 0
            
            cursor.execute("SELECT original_title, access_count FROM channel_index ORDER BY access_count DESC LIMIT 5")
            top_songs = cursor.fetchall()
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
            mem_usage = psutil.virtual_memory().percent
            cpu_usage = psutil.cpu_percent()
            active_tasks = len(downloader.active_tasks)
            cache_hit_rate = downloader.cache_hits / max(1, downloader.cache_hits + downloader.cache_misses) * 100
            
            stats_text = f"""ğŸ“Š **Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©**

ğŸ’¾ **Ø§Ù„Ù…Ø­ÙÙˆØ¸:** {total_cached} Ù…Ù„Ù
âš¡ **Ù…Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:** {total_hits}
ğŸ“ˆ **Ù†Ø³Ø¨Ø© Ø§Ù„ÙƒØ§Ø´:** {cache_hit_rate:.1f}%
ğŸ“º **Ù‚Ù†Ø§Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ†:** {SMART_CACHE_CHANNEL or "ØºÙŠØ± Ù…ÙØ¹Ø¯Ø©"}

ğŸ§  **Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:**
â€¢ Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {mem_usage}%
â€¢ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {cpu_usage}%
â€¢ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù†Ø´Ø·Ø©: {active_tasks}

ğŸµ **Ø§Ù„Ø£ÙƒØ«Ø± Ø·Ù„Ø¨Ø§Ù‹:**"""
            
            for i, row in enumerate(top_songs, 1):
                stats_text += f"\n{i}. {row[0][:30]}... ({row[1]})"
            
            await event.reply(stats_text)
            
    except Exception as e:
        await event.reply(f"âŒ Ø®Ø·Ø£: {e}")

async def clear_cache_handler(event):
    """Ù…Ø³Ø­ ÙƒØ§Ø´ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ"""
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        async with downloader.conn_manager.db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM channel_index")
            total_before = cursor.fetchone()[0]
            cursor.execute("DELETE FROM channel_index")
            conn.commit()
        
        downloader.cache_hits = 0
        downloader.cache_misses = 0
        
        await event.reply(f"""ğŸ§¹ **ØªÙ… Ù…Ø³Ø­ ÙƒØ§Ø´ Ø§Ù„ØªØ®Ø²ÙŠÙ†!**

ğŸ“Š **Ø§Ù„Ù…Ø­Ø°ÙˆÙ:** {total_before} Ù…Ù„Ù
ğŸ’½ **Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** ØªÙ… ØªÙ†Ø¸ÙŠÙÙ‡Ø§
ğŸ”„ **Ø§Ù„ÙƒØ§Ø´:** ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ†Ù‡

âš¡ Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙƒØ§Ø´ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…""")
        
    except Exception as e:
        await event.reply(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´: {e}")

async def system_stats_handler(event):
    """Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"""
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        mem = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        load_avg = os.getloadavg()
        
        stats_text = f"""ğŸ“¡ **Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©**

ğŸ§  **Ø§Ù„Ø°Ø§ÙƒØ±Ø©:**
â€¢ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {mem.total // (1024**3)} GB
â€¢ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {mem.used // (1024**3)} GB
â€¢ Ø§Ù„Ø­Ø±: {mem.free // (1024**3)} GB
â€¢ Ø§Ù„Ù†Ø³Ø¨Ø©: {mem.percent}%

ğŸ’¾ **Ø§Ù„ØªØ®Ø²ÙŠÙ†:**
â€¢ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {disk.total // (1024**3)} GB
â€¢ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {disk.used // (1024**3)} GB
â€¢ Ø§Ù„Ù†Ø³Ø¨Ø©: {disk.percent}%

âš™ï¸ **Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬:**
â€¢ Ø§Ù„Ù†ÙˆÙ‰: {psutil.cpu_count()}
â€¢ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: {psutil.cpu_percent()}%
â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ­Ù…ÙŠÙ„ (1/5/15 Ø¯): {load_avg[0]:.2f}/{load_avg[1]:.2f}/{load_avg[2]:.2f}

ğŸ“¶ **Ø§Ù„Ø´Ø¨ÙƒØ©:**
â€¢ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: {len(psutil.net_connections())}
"""
        await event.reply(stats_text)
        
    except Exception as e:
        await event.reply(f"âŒ Ø®Ø·Ø£: {e}")

# --- Ø¥Ø¯Ø§Ø±Ø© Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù… ---
async def shutdown_system():
    """Ø¥ØºÙ„Ø§Ù‚ Ø¬Ù…ÙŠØ¹ Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù†"""
    LOGGER(__name__).info("ğŸ”´ Ø¨Ø¯Ø¡ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù…...")
    await downloader.conn_manager.close()
    LOGGER(__name__).info("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯")

# ØªØ³Ø¬ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚
import atexit
atexit.register(lambda: asyncio.run(shutdown_system()))

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ
async def download_song_smart(message, query: str):
    """
    Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    ØªØ³ØªØ®Ø¯Ù… Ù…Ù† Ù‚Ø¨Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
    """
    try:
        # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„Ø©
        status_msg = await message.reply_text(
            "âš¡ **Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ**\n\n"
            "ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."
        )
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬ÙˆØ¯Ø©
        quality = "medium"
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        await status_msg.edit("ğŸ” **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£ØºÙ†ÙŠØ©...**")
        video_info = None
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©
        try:
            from youtubesearchpython import VideosSearch
            search = VideosSearch(query, limit=1)
            results = search.result()
            if results.get('result'):
                video_info = results['result'][0]
        except:
            try:
                from youtube_search import YoutubeSearch
                search = YoutubeSearch(query, max_results=1)
                search_results = search.to_dict()
                if search_results:
                    video_info = search_results[0]
            except:
                pass
        
        if not video_info:
            await status_msg.edit(
                "âŒ **Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬**\n\n"
                "ğŸ’¡ **Ø¬Ø±Ø¨:**\n"
                "â€¢ ÙƒÙ„Ù…Ø§Øª Ù…Ø®ØªÙ„ÙØ©\n"
                "â€¢ Ø§Ø³Ù… Ø§Ù„ÙÙ†Ø§Ù†\n"
                "â€¢ Ø¬Ø²Ø¡ Ù…Ù† ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ØºÙ†ÙŠØ©"
            )
            return
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
        title = video_info.get('title', 'Ø£ØºÙ†ÙŠØ©')
        video_id = video_info.get('id', '')
        duration_text = video_info.get('duration', '0:00')
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ø© Ø¥Ù„Ù‰ Ø«ÙˆØ§Ù†
        duration = 0
        try:
            if ':' in duration_text:
                parts = duration_text.split(':')
                if len(parts) == 2:
                    duration = int(parts[0]) * 60 + int(parts[1])
                elif len(parts) == 3:
                    duration = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
        except:
            duration = 0
        
        # Ø§Ù„ØªØ­Ù…ÙŠÙ„
        await status_msg.edit("ğŸ“¥ **Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„...**")
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… yt-dlp Ù„Ù„ØªØ­Ù…ÙŠÙ„
        if not yt_dlp:
            await status_msg.edit("âŒ **Ø®Ø·Ø£:** yt-dlp ØºÙŠØ± Ù…ØªØ§Ø­")
            return
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': f'downloads/{video_id}.%(ext)s',
            'noplaylist': True,
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                video_url = f"https://www.youtube.com/watch?v={video_id}"
                info = ydl.extract_info(video_url, download=True)
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­Ù…Ù„
                downloaded_file = None
                for ext in ['mp3', 'webm', 'm4a', 'ogg']:
                    file_path = f'downloads/{video_id}.{ext}'
                    if os.path.exists(file_path):
                        downloaded_file = file_path
                        break
                
                if not downloaded_file:
                    await status_msg.edit("âŒ **Ø®Ø·Ø£:** ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù")
                    return
                
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù
                await status_msg.edit("ğŸ“¤ **Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„...**")
                
                await message.reply_audio(
                    audio=downloaded_file,
                    caption=f"ğŸµ **{title}**\n\n"
                           f"â±ï¸ Ø§Ù„Ù…Ø¯Ø©: {duration // 60}:{duration % 60:02d}\n"
                           f"ğŸ¤– Ø¨ÙˆØ§Ø³Ø·Ø©: ZeMusic Bot",
                    duration=duration,
                    title=title,
                    performer="ZeMusic Bot"
                )
                
                # Ø­Ø°Ù Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„Ø©
                try:
                    await status_msg.delete()
                except:
                    pass
                
                # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                try:
                    os.remove(downloaded_file)
                except:
                    pass
                
                LOGGER(__name__).info(f"âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£ØºÙ†ÙŠØ©: {title}")
                
        except Exception as e:
            LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {e}")
            await status_msg.edit("âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„**")
        
    except Exception as e:
        LOGGER(__name__).error(f"Ø®Ø·Ø£ ÙÙŠ download_song_smart: {e}")
        try:
            await message.reply_text(
                "âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«**\n\n"
                "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ\n"
                "ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"
            )
        except:
            pass

LOGGER(__name__).info("ğŸš€ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø®Ø§Ø±Ù‚ Ø§Ù„Ù…ØªØ·ÙˆØ± V2")
