# -*- coding: utf-8 -*-
"""
ЁЯЪА ┘Ж╪╕╪з┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ╪з┘Д╪о╪з╪▒┘В - ╪з┘Д┘Ж╪│╪о╪й ╪з┘Д┘Е╪к╪╖┘И╪▒╪й V2
=====================================================
╪к┘Е ╪з┘Д╪к╪╖┘И┘К╪▒ ┘Д┘К╪п╪╣┘Е:
- 5000 ┘Е╪м┘Е┘И╪╣╪й ┘И70,000 ┘Е╪│╪к╪о╪п┘Е ┘Б┘К ╪з┘Д╪о╪з╪╡
- ╪к╪н┘Е┘К┘Д ┘Е╪к┘И╪з╪▓┘К ┘Б╪з╪ж┘В ╪з┘Д╪│╪▒╪╣╪й
- ╪е╪п╪з╪▒╪й ╪░┘Г┘К╪й ┘Д┘Д┘Е┘И╪з╪▒╪п
- ┘В╪з╪╣╪п╪й ╪и┘К╪з┘Ж╪з╪к ╪║┘К╪▒ ┘Е╪к╪▓╪з┘Е┘Ж╪й
- ┘Ж╪╕╪з┘Е ┘Е╪▒╪з┘В╪и╪й ┘И╪к╪к╪и╪╣ ┘Е╪к┘В╪п┘Е
"""

import os
import re
import asyncio
import logging
import time
import sqlite3
import hashlib
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Dict, Optional, List, Tuple
from itertools import cycle
from collections import defaultdict, deque
from asyncio import Semaphore
import threading
import aiohttp
import aiofiles
from telethon.tl.types import DocumentAttributeAudio
from pathlib import Path
import uvloop
import psutil
import random
import string
import atexit
from contextlib import asynccontextmanager
import orjson

# ╪к╪╖╪и┘К┘В UVLoop ┘Д╪к╪н╪│┘К┘Ж ╪г╪п╪з╪б asyncio

def get_audio_duration(file_path: str) -> int:
    """╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪п╪й ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪╡┘И╪к┘К ╪и╪з┘Д╪л┘И╪з┘Ж┘К"""
    try:
        if not os.path.exists(file_path):
            return 0
            
        # ┘Е╪н╪з┘И┘Д╪й ╪з╪│╪к╪о╪п╪з┘Е yt-dlp ┘Д┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д┘Е╪╣┘Д┘И┘Е╪з╪к
        if yt_dlp:
            try:
                with yt_dlp.YoutubeDL({'quiet': True}) as ydl:
                    info = ydl.extract_info(file_path, download=False)
                    duration = info.get('duration', 0)
                    if duration and duration > 0:
                        return int(duration)
            except:
                pass
        
        # ┘Е╪н╪з┘И┘Д╪й ╪з╪│╪к╪о╪п╪з┘Е ffprobe
        try:
            import subprocess
            result = subprocess.run([
                'ffprobe', '-v', 'quiet', '-show_entries', 
                'format=duration', '-of', 'csv=p=0', file_path
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                return int(float(result.stdout.strip()))
        except:
            pass
            
        # ╪к┘В╪п┘К╪▒ ╪к┘В╪▒┘К╪и┘К ╪и┘Ж╪з╪б┘Л ╪╣┘Д┘Й ╪н╪м┘Е ╪з┘Д┘Е┘Д┘Б (┘Д┘Д┘Е┘Д┘Б╪з╪к ╪з┘Д╪╡┘И╪к┘К╪й)
        try:
            file_size = os.path.getsize(file_path)
            # ╪к┘В╪п┘К╪▒: 128kbps = 16KB/s ╪к┘В╪▒┘К╪и╪з┘Л
            estimated_duration = file_size // 16000
            return max(1, estimated_duration)
        except:
            return 0
            
    except Exception as e:
        LOGGER.warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪п╪й ╪з┘Д╪╡┘И╪к: {e}")
        return 0
asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())

# ╪з╪│╪к┘К╪▒╪з╪п ╪з┘Д┘Е┘Г╪к╪и╪з╪к ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪г╪о╪╖╪з╪б
try:
    import yt_dlp
except ImportError:
    yt_dlp = None
    
try:
    from youtube_search import YoutubeSearch
    YOUTUBE_SEARCH_AVAILABLE = True
except ImportError:
    YoutubeSearch = None
    YOUTUBE_SEARCH_AVAILABLE = False

# ╪з╪│╪к┘К╪▒╪з╪п Telethon
from telethon import events
from telethon.types import Message

import config
from ZeMusic.core.telethon_client import telethon_manager
from ZeMusic.logging import LOGGER
from ZeMusic.utils.database import is_search_enabled, is_search_enabled1
# from ZeMusic.utils.monitoring import PerformanceMonitor

# --- ╪е╪╣╪п╪з╪п╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪░┘Г┘К ---
REQUEST_TIMEOUT = 8
DOWNLOAD_TIMEOUT = 90
MAX_SESSIONS = min(100, (psutil.cpu_count() * 4))  # ╪п┘К┘Ж╪з┘Е┘К┘Г┘К ╪н╪│╪и ╪з┘Д┘Е╪╣╪з┘Д╪м
MAX_WORKERS = min(200, (psutil.cpu_count() * 10))  # ╪п┘К┘Ж╪з┘Е┘К┘Г┘К ╪н╪│╪и ╪з┘Д┘Е╪╣╪з┘Д╪м

# ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К (┘К┘И╪▓╪▒ ╪г┘И ID)
SMART_CACHE_CHANNEL = config.CACHE_CHANNEL_ID
DATABASE_PATH = "zemusic.db"
DB_FILE = DATABASE_PATH  # ╪к┘И╪н┘К╪п ╪г╪│┘Е╪з╪б ┘В┘И╪з╪╣╪п ╪з┘Д╪и┘К╪з┘Ж╪з╪к

def normalize_arabic_text(text: str) -> str:
    """╪к╪╖╪и┘К╪╣ ╪з┘Д┘Ж╪╡ ╪з┘Д╪╣╪▒╪и┘К ┘Д┘Д╪и╪н╪л ╪з┘Д┘Е╪н╪│┘Ж"""
    if not text:
        return ""
    
    # ╪е╪▓╪з┘Д╪й ╪з┘Д╪к╪┤┘Г┘К┘Д ┘И╪з┘Д╪▒┘Е┘И╪▓ ╪з┘Д╪о╪з╪╡╪й
    import re
    text = re.sub(r'[\u064B-\u065F\u0670\u0640]', '', text)  # ╪е╪▓╪з┘Д╪й ╪з┘Д╪к╪┤┘Г┘К┘Д
    text = re.sub(r'[^\w\s\u0600-\u06FF]', ' ', text)  # ╪з┘Д╪з╪н╪к┘Б╪з╪╕ ╪и╪з┘Д╪╣╪▒╪и┘К╪й ┘И╪з┘Д╪е┘Ж╪м┘Д┘К╪▓┘К╪й ┘Б┘В╪╖
    text = re.sub(r'\s+', ' ', text).strip()  # ╪е╪▓╪з┘Д╪й ╪з┘Д┘Е╪│╪з┘Б╪з╪к ╪з┘Д╪▓╪з╪ж╪п╪й
    return text

# ╪е╪╣╪п╪з╪п╪з╪к ╪з┘Д╪╣╪▒╪╢
channel = getattr(config, 'STORE_LINK', '')
lnk = f"https://t.me/{channel}" if channel else None

# --- ╪к╪п┘И┘К╪▒ ╪з┘Д┘Е┘Б╪з╪к┘К╪н ┘И╪з┘Д╪о┘И╪з╪п┘Е ---
YT_API_KEYS = config.YT_API_KEYS
API_KEYS_CYCLE = cycle(YT_API_KEYS) if YT_API_KEYS else None

INVIDIOUS_SERVERS = config.INVIDIOUS_SERVERS
INVIDIOUS_CYCLE = cycle(INVIDIOUS_SERVERS) if INVIDIOUS_SERVERS else None

# ╪к╪п┘И┘К╪▒ ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓
COOKIES_FILES = config.COOKIES_FILES
COOKIES_CYCLE = cycle(COOKIES_FILES) if COOKIES_FILES else None

# --- ╪е╪╣╪п╪з╪п╪з╪к yt-dlp ╪╣╪з┘Д┘К╪й ╪з┘Д╪г╪п╪з╪б ---
def get_ytdlp_opts(cookies_file=None) -> Dict:
    """╪е╪╣╪п╪з╪п╪з╪к ┘Е╪к┘В╪п┘Е╪й ┘Д┘А yt-dlp ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к ╪з┘Д╪г╪п╪з╪б"""
    opts = {
        "format": "bestaudio/best",
        "noplaylist": True,
        "quiet": True,
        "retries": 2,
        "no-cache-dir": True,
        "ignoreerrors": True,
        "socket-timeout": REQUEST_TIMEOUT,
        "force-ipv4": True,
        "throttled-rate": "1M",
        "extractor-args": "youtube:player_client=android,web",
        "concurrent-fragments": 16,  # ╪▓┘К╪з╪п╪й ╪з┘Д╪к╪м╪▓╪ж╪й ╪з┘Д┘Е╪к┘И╪з╪▓┘К╪й
        "outtmpl": "downloads/%(id)s.%(ext)s",
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "192",
        }],
        "postprocessor_args": ["-ar", "44100", "-threads", "4"],
        "noprogress": True,
        "verbose": False,
        "http-chunk-size": "1M",
        "limit-rate": "5M",
        "buffer-size": "16M",
        "extractor-retries": 3,
        "fragment-retries": 5,
        "skip-unavailable-fragments": True,
        "merge-output-format": "mp3",
    }
    
    if cookies_file and os.path.exists(cookies_file):
        opts["cookiefile"] = cookies_file
    
    # ╪е╪╢╪з┘Б╪й aria2c ╪е╪░╪з ┘Е╪к┘И┘Б╪▒
    import shutil
    if shutil.which("aria2c"):
        opts.update({
            "external_downloader": "aria2c",
            "external_downloader_args": [
                "-x", "16", 
                "-s", "16", 
                "-k", "2M",
                "--file-allocation=none",
                "--summary-interval=0"
            ],
        })
    
    return opts

# ╪е┘Ж╪┤╪з╪б ┘Е╪м┘Д╪п ╪з┘Д╪к╪н┘Е┘К┘Д╪з╪к
os.makedirs("downloads", exist_ok=True)

# --- ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Д┘Д┘Б┘З╪▒╪│╪й ╪з┘Д╪░┘Г┘К╪й ---
# DB_FILE ╪к┘Е ╪к╪╣╪▒┘К┘Б┘З ┘Б┘К ╪з┘Д╪г╪╣┘Д┘Й

async def init_database():
    """╪к┘З┘К╪ж╪й ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪и╪┤┘Г┘Д ╪║┘К╪▒ ┘Е╪к╪▓╪з┘Е┘Ж"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    # ╪к╪н╪│┘К┘Ж ┘З┘К┘Г┘Д ╪з┘Д╪м╪п┘И┘Д
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS channel_index (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            message_id INTEGER UNIQUE,
            file_id TEXT UNIQUE,
            file_unique_id TEXT,
            
            search_hash TEXT UNIQUE,
            title_normalized TEXT,
            artist_normalized TEXT,
            keywords_vector TEXT,
            
            original_title TEXT,
            original_artist TEXT,
            duration INTEGER,
            file_size INTEGER,
            
            access_count INTEGER DEFAULT 0,
            last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            popularity_rank REAL DEFAULT 0,
            
            phonetic_hash TEXT,
            partial_matches TEXT,
            
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # ╪к╪н╪│┘К┘Ж ╪з┘Д┘Б┘З╪з╪▒╪│
    indexes = [
        "CREATE INDEX IF NOT EXISTS idx_search_hash ON channel_index(search_hash)",
        "CREATE INDEX IF NOT EXISTS idx_title_norm ON channel_index(title_normalized)",
        "CREATE INDEX IF NOT EXISTS idx_artist_norm ON channel_index(artist_normalized)",
        "CREATE INDEX IF NOT EXISTS idx_popularity ON channel_index(popularity_rank DESC)",
        "CREATE INDEX IF NOT EXISTS idx_message_id ON channel_index(message_id)",
        "CREATE INDEX IF NOT EXISTS idx_file_id ON channel_index(file_id)",
        "CREATE INDEX IF NOT EXISTS idx_keywords ON channel_index(keywords_vector)"
    ]
    
    for index_sql in indexes:
        cursor.execute(index_sql)
    
    conn.commit()
    conn.close()

# ╪к┘З┘К╪ж╪й ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪╣┘Ж╪п ╪и╪п╪б ╪з┘Д┘И╪н╪п╪й
# ╪│┘К╪к┘Е ╪к┘З┘К╪ж╪й ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪╣┘Ж╪п ╪г┘И┘Д ╪з╪│╪к╪о╪п╪з┘Е
_database_initialized = False

async def ensure_database_initialized():
    """╪з┘Д╪к╪г┘Г╪п ┘Е┘Ж ╪к┘З┘К╪ж╪й ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к"""
    global _database_initialized
    if not _database_initialized:
        await init_database()
        _database_initialized = True

# ================================================================
#                 ┘Ж╪╕╪з┘Е ╪е╪п╪з╪▒╪й ╪з┘Д╪з╪к╪╡╪з┘Д╪з╪к ╪з┘Д┘Е╪к┘В╪п┘Е
# ================================================================
class ConnectionManager:
    """┘Е╪п┘К╪▒ ╪з╪к╪╡╪з┘Д╪з╪к ┘Е╪к┘В╪п┘Е ┘Е╪╣ ╪к╪м┘Е┘К╪╣ ╪з┘Д╪м┘Д╪│╪з╪к"""
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._session_pool = []
            cls._instance._executor_pool = None
            cls._instance._db_connections = {}
        return cls._instance
    
    async def initialize(self):
        """╪к┘З┘К╪ж╪й ╪к╪м┘Е╪╣ ╪з┘Д┘Е┘И╪з╪▒╪п"""
        # ╪к╪м┘Е╪╣ ╪м┘Д╪│╪з╪к HTTP
        connector = aiohttp.TCPConnector(
            limit_per_host=200,
            ttl_dns_cache=600,
            use_dns_cache=True,
            keepalive_timeout=45,
            enable_cleanup_closed=True
        )
        
        self._session_pool = [
            aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=REQUEST_TIMEOUT),
                headers={'User-Agent': f'ZeMusic-{i}'},
                json_serialize=orjson.dumps
            ) for i in range(MAX_SESSIONS)
        ]
        
        # ╪к╪м┘Е╪╣ ┘Е╪д╪┤╪▒╪з╪к ╪з┘Д╪к┘Ж┘Б┘К╪░
        self._executor_pool = concurrent.futures.ThreadPoolExecutor(
            max_workers=MAX_WORKERS,
            thread_name_prefix="DLWorker"
        )
        
        LOGGER(__name__).info(f"ЁЯЪА ╪к┘Е ╪к┘З┘К╪ж╪й ┘Ж╪╕╪з┘Е ╪з┘Д╪з╪к╪╡╪з┘Д╪з╪к: {MAX_SESSIONS} ╪м┘Д╪│╪й, {MAX_WORKERS} ╪╣╪з┘Е┘Д")
    
    @property
    def session_pool(self):
        """╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪к╪м┘Е╪╣ ╪з┘Д╪м┘Д╪│╪з╪к"""
        if not self._session_pool:
            raise RuntimeError("ConnectionManager not initialized")
        return self._session_pool
    
    @property
    def executor_pool(self):
        """╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪к╪м┘Е╪╣ ╪з┘Д╪╣┘Е╪з┘Д"""
        if not self._executor_pool:
            raise RuntimeError("Executor pool not initialized")
        return self._executor_pool
    
    async def get_session(self) -> aiohttp.ClientSession:
        """╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪м┘Д╪│╪й ┘Е╪к╪з╪н╪й"""
        if not self._session_pool:
            await self.initialize()
        return random.choice(self._session_pool)
    
    @asynccontextmanager
    async def db_connection(self):
        """╪е╪п╪з╪▒╪й ╪з╪к╪╡╪з┘Д╪з╪к ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к"""
        conn = sqlite3.connect(DB_FILE, check_same_thread=False)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()
    
    async def close(self):
        """╪е╪║┘Д╪з┘В ╪м┘Е┘К╪╣ ╪з┘Д┘Е┘И╪з╪▒╪п"""
        try:
            if self._session_pool:
                for session in self._session_pool:
                    if session and not session.closed:
                        await session.close()
            if self._executor_pool:
                self._executor_pool.shutdown(wait=True)
            LOGGER(__name__).info("ЁЯФМ ╪к┘Е ╪е╪║┘Д╪з┘В ╪м┘Е┘К╪╣ ┘Е┘И╪з╪▒╪п ╪з┘Д╪з╪к╪╡╪з┘Д")
        except Exception as e:
            LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪е╪║┘Д╪з┘В ╪з┘Д┘Е┘И╪з╪▒╪п: {e}")

# ================================================================
#                 ┘Ж╪╕╪з┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ╪з┘Д╪о╪з╪▒┘В
# ================================================================
class HyperSpeedDownloader:
    """┘Ж╪│╪о╪й ┘Е╪и╪│╪╖╪й ┘Е┘Ж ┘Ж╪╕╪з┘Е ╪з┘Д╪к╪н┘Е┘К┘Д"""
    
    def __init__(self):
        self.downloads_folder = "downloads"
        os.makedirs(self.downloads_folder, exist_ok=True)
        
        # ╪е╪╣╪п╪з╪п ╪з┘Д┘Е╪к╪║┘К╪▒╪з╪к ╪з┘Д┘Е╪╖┘Д┘И╪и╪й
        self.cache_hits = 0
        self.cache_misses = 0
        self.active_tasks = set()
        self.last_health_check = time.time()
        
        # ╪е╪╣╪п╪з╪п ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б
        self.method_performance = {
            'youtube_api': {'avg_time': 0},
            'invidious': {'avg_time': 0},
            'youtube_search': {'avg_time': 0},
            'ytdlp_cookies': {'avg_time': 0},
            'ytdlp_no_cookies': {'avg_time': 0}
        }
        
        # ╪е╪╣╪п╪з╪п ┘Е╪п┘К╪▒ ╪з┘Д╪з╪к╪╡╪з┘Д╪з╪к
        try:
            self.conn_manager = ConnectionManager()
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к┘З┘К╪ж╪й ┘Е╪п┘К╪▒ ╪з┘Д╪з╪к╪╡╪з┘Д╪з╪к: {e}")
            self.conn_manager = None
        
        # ╪к╪│╪м┘К┘Д ╪и╪п╪б ╪з┘Д╪к╪┤╪║┘К┘Д
        LOGGER(__name__).info("ЁЯЪА ╪и╪п╪б ╪к╪┤╪║┘К┘Д ┘Ж╪╕╪з┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪н╪│┘Ж")
    
    async def search_in_smart_cache(self, query: str) -> Optional[Dict]:
        """╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Е╪╣ ╪в┘Д┘К╪й ┘Е╪к┘В╪п┘Е╪й"""
        try:
            # ╪з┘Д╪и╪н╪л ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪г┘И┘Д╪з┘Л
            normalized_query = normalize_arabic_text(query)
            
            conn = sqlite3.connect(DATABASE_PATH)
            cursor = conn.cursor()
            
            # ╪з┘Д╪и╪н╪л ╪и╪з┘Д╪╣┘Ж┘И╪з┘Ж ┘И╪з┘Д┘Б┘Ж╪з┘Ж
            cursor.execute("""
                SELECT video_id, title, artist, duration, file_path, thumb, message_id, keywords
                FROM cached_audio 
                WHERE LOWER(title) LIKE ? OR LOWER(artist) LIKE ? OR LOWER(keywords) LIKE ?
                ORDER BY created_at DESC LIMIT 5
            """, (f'%{normalized_query.lower()}%', f'%{normalized_query.lower()}%', f'%{normalized_query.lower()}%'))
            
            results = cursor.fetchall()
            conn.close()
            
            if results:
                result = results[0]  # ╪г╪о╪░ ╪г┘И┘Д ┘Ж╪к┘К╪м╪й
                self.cache_hits += 1
                return {
                    "video_id": result[0],
                    "title": result[1],
                    "artist": result[2],
                    "duration": result[3],
                    "file_path": result[4],
                    "thumb": result[5],
                    "message_id": result[6],
                    "source": "smart_cache"
                }
            
            self.cache_misses += 1
            return None
            
        except Exception as e:
            LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣: {e}")
            self.cache_misses += 1
            return None
    
    async def health_check(self):
        """┘Б╪н╪╡ ╪╡╪н╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪и╪┤┘Г┘Д ╪п┘И╪▒┘К"""
        if time.time() - self.last_health_check > 300:  # ┘Г┘Д 5 ╪п┘В╪з╪ж┘В
            self.last_health_check = time.time()
            
            # ╪к╪│╪м┘К┘Д ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б
            stats = {
                'cache_hits': self.cache_hits,
                'cache_misses': self.cache_misses,
                'cache_hit_rate': self.cache_hits / max(1, self.cache_hits + self.cache_misses) * 100,
                'active_tasks': len(self.active_tasks),
                'memory_usage': psutil.virtual_memory().percent,
                'cpu_usage': psutil.cpu_percent(),
            }
            
            LOGGER(__name__).info(
                f"ЁЯУК ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е: "
                f"╪з┘Д╪░╪з┘Г╪▒╪й: {stats['memory_usage']}% | "
                f"╪з┘Д┘Е╪╣╪з┘Д╪м: {stats['cpu_usage']}% | "
                f"╪з┘Д╪╖┘Д╪и╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {stats['active_tasks']} | "
                f"┘Ж╪│╪и╪й ╪з┘Д┘Г╪з╪┤: {stats['cache_hit_rate']:.1f}%"
            )
    
    def normalize_text(self, text: str) -> str:
        """╪к╪╖╪и┘К╪╣ ╪з┘Д┘Ж╪╡ ┘Д┘Д╪и╪н╪л ┘Е╪╣ ╪к╪н╪│┘К┘Ж ╪з┘Д╪г╪п╪з╪б"""
        if not text:
            return ""
        
        # ╪к╪н┘И┘К┘Д ┘Д┘Д╪г╪н╪▒┘Б ╪з┘Д╪╡╪║┘К╪▒╪й ┘И╪е╪▓╪з┘Д╪й ╪з┘Д╪к╪┤┘Г┘К┘Д
        text = text.lower()
        text = re.sub(r'[\u064B-\u065F]', '', text)  # ╪е╪▓╪з┘Д╪й ╪з┘Д╪к╪┤┘Г┘К┘Д ╪з┘Д╪╣╪▒╪и┘К
        text = re.sub(r'[^\w\s]', '', text)  # ╪е╪▓╪з┘Д╪й ╪з┘Д╪▒┘Е┘И╪▓
        text = re.sub(r'\s+', ' ', text).strip()  # ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Е╪│╪з┘Б╪з╪к
        
        # ╪к╪╖╪и┘К╪╣ ╪з┘Д╪н╪▒┘И┘Б ╪з┘Д╪╣╪▒╪и┘К╪й ╪и╪з╪│╪к╪о╪п╪з┘Е ╪м╪п┘И┘Д ╪к╪н┘И┘К┘Д
        replacements = {
            '╪й': '┘З', '┘К': '┘Й', '╪г': '╪з', '╪е': '╪з',
            '╪в': '╪з', '╪д': '┘И', '╪ж': '┘К', '┘▒': '╪з',
            '┘░': '', '┘С': '', '┘Т': '', '┘М': '',
            '┘Н': '', '┘Л': '', '┘П': '', '┘О': '',
            '┘Р': '', '~': '', '┘А': ''
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text
    
    def create_search_hash(self, title: str, artist: str = "") -> str:
        """╪е┘Ж╪┤╪з╪б ┘З╪з╪┤ ┘Д┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣ ╪и╪з╪│╪к╪о╪п╪з┘Е ╪о┘И╪з╪▒╪▓┘Е┘К╪й ╪г╪│╪▒╪╣"""
        normalized_title = self.normalize_text(title)
        normalized_artist = self.normalize_text(artist)
        combined = f"{normalized_title}_{normalized_artist}".encode()
        return hashlib.md5(combined, usedforsecurity=False).hexdigest()[:12]
    
    async def lightning_search_cache(self, query: str) -> Optional[Dict]:
        """╪и╪н╪л ╪о╪з╪╖┘Б ┘Б┘К ╪з┘Д┘Г╪з╪┤ ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к ╪з┘Д╪г╪п╪з╪б"""
        try:
            normalized_query = self.normalize_text(query)
            search_hash = self.create_search_hash(normalized_query)
            
            async with self.conn_manager.db_connection() as conn:
                cursor = conn.cursor()
                
                # ╪и╪н╪л ┘Е╪и╪з╪┤╪▒ ╪и╪з┘Д┘З╪з╪┤
                cursor.execute(
                    "SELECT message_id, file_id, original_title, original_artist, duration "
                    "FROM channel_index WHERE search_hash = ? LIMIT 1",
                    (search_hash,)
                )
                result = cursor.fetchone()
                
                if result:
                    # ╪к╪н╪п┘К╪л ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪з╪│╪к╪о╪п╪з┘Е
                    cursor.execute(
                        "UPDATE channel_index SET access_count = access_count + 1, "
                        "last_accessed = CURRENT_TIMESTAMP WHERE search_hash = ?",
                        (search_hash,)
                    )
                    conn.commit()
                    
                    self.cache_hits += 1
                    return {
                        'message_id': result[0],
                        'file_id': result[1],
                        'title': result[2],
                        'artist': result[3],
                        'duration': result[4],
                        'source': 'cache',
                        'cached': True
                    }
                
                # ╪и╪н╪л ╪к┘В╪▒┘К╪и┘К ╪и╪з╪│╪к╪о╪п╪з┘Е ┘Б┘З╪▒╪│ ╪з┘Д┘Г┘Д┘Е╪з╪к
                keywords = normalized_query.split()
                keyword_conditions = " OR ".join(["keywords_vector LIKE ?" for _ in keywords])
                params = [f"%{kw}%" for kw in keywords]
                
                cursor.execute(
                    f"SELECT message_id, file_id, original_title, original_artist, duration "
                    f"FROM channel_index WHERE {keyword_conditions} "
                    f"ORDER BY popularity_rank DESC LIMIT 1",
                    params
                )
                result = cursor.fetchone()
                
                if result:
                    self.cache_hits += 1
                    return {
                        'message_id': result[0],
                        'file_id': result[1],
                        'title': result[2],
                        'artist': result[3],
                        'duration': result[4],
                        'source': 'cache_fuzzy',
                        'cached': True
                    }
            
            self.cache_misses += 1
        except Exception as e:
            LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣: {e}")
            # self.monitor.log_error('cache_search')
        
        return None
    
    async def youtube_api_search(self, query: str) -> Optional[Dict]:
        """╪з┘Д╪и╪н╪л ╪╣╪и╪▒ YouTube Data API ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к ╪з┘Д╪г╪п╪з╪б"""
        if not API_KEYS_CYCLE:
            return None
        
        session = await self.conn_manager.get_session()
        start_time = time.time()
        
        try:
            for attempt in range(len(YT_API_KEYS)):
                key = next(API_KEYS_CYCLE)
                LOGGER(__name__).info(f"ЁЯФС ┘Е╪н╪з┘И┘Д╪й YouTube API - ╪з┘Д┘Е╪н╪з┘И┘Д╪й {attempt + 1}")
                params = {
                    "part": "snippet",
                    "q": query,
                    "type": "video",
                    "maxResults": 1,
                    "key": key,
                    "videoCategoryId": "10",  # ┘Е┘И╪│┘К┘В┘Й ┘Б┘В╪╖
                    "relevanceLanguage": "ar,en"
                }
                
                try:
                    async with session.get(
                        "https://www.googleapis.com/youtube/v3/search",
                        params=params,
                        timeout=REQUEST_TIMEOUT
                    ) as resp:
                        if resp.status == 403:
                            LOGGER(__name__).warning(f"┘Е┘Б╪к╪з╪н API ┘Е╪н╪╕┘И╪▒: {key[:5]}...")
                            continue
                            
                        if resp.status != 200:
                            error_text = await resp.text()
                            LOGGER(__name__).warning(f"YouTube API ╪о╪╖╪г {resp.status}: {error_text[:100]}")
                            continue
                        
                        data = await resp.json()
                        items = data.get("items", [])
                        if not items:
                            LOGGER(__name__).warning(f"YouTube API: ┘Д╪з ╪к┘И╪м╪п ┘Ж╪к╪з╪ж╪м ┘Д┘А {query}")
                            continue
                        
                        item = items[0]
                        video_id = item["id"]["videoId"]
                        snippet = item["snippet"]
                        title = snippet.get("title", "")[:60]
                        
                        LOGGER(__name__).info(f"тЬЕ YouTube API ┘Ж╪м╪н: {title[:30]}...")
                        
                        self.method_performance['youtube_api']['avg_time'] = (
                            self.method_performance['youtube_api']['avg_time'] * 0.7 + 
                            (time.time() - start_time) * 0.3
                        )
                        
                        return {
                            "video_id": video_id,
                            "title": title,
                            "artist": snippet.get("channelTitle", "Unknown"),
                            "thumb": snippet.get("thumbnails", {}).get("high", {}).get("url"),
                            "source": "youtube_api"
                        }
                
                except (asyncio.TimeoutError, aiohttp.ClientError):
                    continue
        
        except Exception as e:
            LOGGER(__name__).warning(f"┘Б╪┤┘Д YouTube API: {e}")
            # self.monitor.log_error('youtube_api')
        
        return None
    
    async def invidious_search(self, query: str) -> Optional[Dict]:
        """╪з┘Д╪и╪н╪л ╪╣╪и╪▒ Invidious ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к ╪з┘Д╪г╪п╪з╪б"""
        if not INVIDIOUS_CYCLE:
            return None
        
        session = await self.conn_manager.get_session()
        start_time = time.time()
        
        try:
            for _ in range(len(INVIDIOUS_SERVERS)):
                server = next(INVIDIOUS_CYCLE)
                url = f"{server}/api/v1/search"
                params = {
                    "q": query, 
                    "type": "video",
                    "sort_by": "relevance",
                    "duration": "short"
                }
                
                try:
                    async with session.get(
                        url, 
                        params=params,
                        timeout=REQUEST_TIMEOUT
                    ) as resp:
                        if resp.status != 200:
                            continue
                        
                        content_type = resp.headers.get('content-type', '')
                        if 'application/json' not in content_type:
                            continue
                        
                        data = await resp.json()
                        video = next((item for item in data if item.get("type") == "video"), None)
                        if not video:
                            continue
                        
                        self.method_performance['invidious']['avg_time'] = (
                            self.method_performance['invidious']['avg_time'] * 0.7 + 
                            (time.time() - start_time) * 0.3
                        )
                        
                        return {
                            "video_id": video.get("videoId"),
                            "title": video.get("title", "")[:60],
                            "artist": video.get("author", "Unknown"),
                            "duration": int(video.get("lengthSeconds", 0)),
                            "thumb": next(
                                (t.get("url") for t in reversed(video.get("videoThumbnails", []))),
                                None
                            ),
                            "source": "invidious"
                        }
                
                except (asyncio.TimeoutError, aiohttp.ClientError):
                    continue
        
        except Exception as e:
            LOGGER(__name__).warning(f"┘Б╪┤┘Д Invidious: {e}")
            # self.monitor.log_error('invidious')
        
        return None
    
    async def youtube_search_simple(self, query: str) -> Optional[Dict]:
        """╪з┘Д╪и╪н╪л ╪╣╪и╪▒ youtube_search ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ┘Е╪н╪│┘Ж╪й"""
        if not YoutubeSearch:
            return None
        
        start_time = time.time()
            
        try:
            # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪к┘И┘Б╪▒ ┘Е┘Г╪к╪и╪й ╪з┘Д╪и╪н╪л
            if not YoutubeSearch:
                LOGGER(__name__).warning(f"YouTube Search ╪║┘К╪▒ ┘Е╪к╪з╪н")
                return None
            
            # ╪з╪│╪к╪о╪п╪з┘Е youtube_search
            LOGGER(__name__).info(f"ЁЯФН ╪и╪п╪б ╪з┘Д╪и╪н╪л ┘Б┘К YouTube Search: {query}")
            search = YoutubeSearch(query, max_results=1)
            results = search.to_dict()
            
            LOGGER(__name__).info(f"ЁЯУК ╪╣╪п╪п ╪з┘Д┘Ж╪к╪з╪ж╪м: {len(results) if results else 0}")
            
            if not results:
                LOGGER(__name__).warning(f"тЭМ ┘Д╪з ╪к┘И╪м╪п ┘Ж╪к╪з╪ж╪м ┘Д┘Д╪и╪н╪л: {query}")
                return None
                
            result = results[0]
            LOGGER(__name__).info(f"ЁЯУЭ ╪з┘Д┘Ж╪к┘К╪м╪й ╪з┘Д╪г┘И┘Д┘Й: {result.get('title', 'Unknown')[:30]}...")
            
            # ╪з╪│╪к╪о╪▒╪з╪м ┘Е╪╣╪▒┘Б ╪з┘Д┘Б┘К╪п┘К┘И
            video_id = result.get('id', '')
            
            # ╪е╪░╪з ┘Д┘Е ┘К┘Г┘Ж ╪з┘Д┘Е╪╣╪▒┘Б ┘Е┘И╪м┘И╪п╪М ╪н╪з┘И┘Д ╪з╪│╪к╪о╪▒╪з╪м┘З ┘Е┘Ж ╪з┘Д╪▒╪з╪и╪╖
            if not video_id:
                url_suffix = result.get('url_suffix', '')
                link = result.get('link', '')
                
                if url_suffix and 'watch?v=' in url_suffix:
                    video_id = url_suffix.split('watch?v=')[1].split('&')[0]
                elif link and 'watch?v=' in link:
                    video_id = link.split('watch?v=')[1].split('&')[0]
            
            LOGGER(__name__).info(f"ЁЯФЧ URL Suffix: {result.get('url_suffix', 'Unknown')}")
            LOGGER(__name__).info(f"ЁЯЖФ ┘Е╪╣╪▒┘Б ╪з┘Д┘Б┘К╪п┘К┘И ╪з┘Д┘Е╪│╪к╪о╪▒╪м: {video_id}")
            title = result.get('title', 'Unknown Title')
            artist = result.get('channel', 'Unknown Artist')
            duration_text = result.get('duration', '0:00')
            thumb = result.get('thumbnails', [None])[0] if result.get('thumbnails') else None
            
            LOGGER(__name__).info(f"ЁЯЖФ ┘Е╪╣╪▒┘Б ╪з┘Д┘Б┘К╪п┘К┘И: {video_id}")
            LOGGER(__name__).info(f"ЁЯО╡ ╪з┘Д╪╣┘Ж┘И╪з┘Ж: {title[:30]}...")
            LOGGER(__name__).info(f"ЁЯОд ╪з┘Д┘Б┘Ж╪з┘Ж: {artist[:20]}...")
            
            # ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д┘Е╪п╪й
            duration = 0
            if isinstance(duration_text, str) and ':' in duration_text:
                try:
                    parts = duration_text.split(':')
                    if len(parts) == 2:
                        duration = int(parts[0]) * 60 + int(parts[1])
                    elif len(parts) == 3:
                        duration = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
                except (ValueError, IndexError):
                    duration = 0
            
            if not video_id:
                return None
            
            self.method_performance['youtube_search']['avg_time'] = (
                self.method_performance['youtube_search']['avg_time'] * 0.7 + 
                (time.time() - start_time) * 0.3
            )
            
            return {
                "video_id": video_id,
                "title": title[:60],
                "artist": artist[:40] if artist else "Unknown Artist",
                "duration": duration,
                "thumb": thumb,
                "link": f"https://youtube.com/watch?v={video_id}",
                "source": "youtube_search"
            }
            
        except Exception as e:
            LOGGER(__name__).warning(f"┘Б╪┤┘Д YouTube Search: {e}")
            try:
                self.monitor.log_error('youtube_search')
            except:
                pass
            return None
    
    async def download_with_ytdlp(self, video_info: Dict) -> Optional[Dict]:
        """╪к╪н┘Е┘К┘Д ╪╣╪и╪▒ yt-dlp ┘Е╪╣ ╪к╪п┘И┘К╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓"""
        if not yt_dlp:
            return None
            
        video_id = video_info.get("video_id")
        if not video_id:
            return None
        
        url = f"https://youtu.be/{video_id}"
        start_time = time.time()
        
        # ┘Е╪н╪з┘И┘Д╪й ┘Е╪╣ ┘Е╪п┘К╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д╪░┘Г┘К
        try:
            from ZeMusic.core.cookies_manager import cookies_manager, report_cookie_success, report_cookie_failure
            
            # ┘Е╪н╪з┘И┘Д╪й ┘Е╪╣ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪г┘И┘Д╪з┘Л
            for attempt in range(2):  # ┘Е╪н╪з┘И┘Д╪й ┘Г┘И┘Г┘К╪▓┘К┘Ж ┘Е╪о╪к┘Д┘Б┘К┘Ж
                try:
                    cookies_file = await cookies_manager.get_next_cookie()
                    if not cookies_file:
                        break
                        
                    opts = get_ytdlp_opts(cookies_file)
                    
                    loop = asyncio.get_running_loop()
                    info = await loop.run_in_executor(
                        self.conn_manager.executor_pool,
                        lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
                    )
                    
                    if info:
                        audio_path = f"downloads/{video_id}.mp3"
                        if os.path.exists(audio_path):
                            # ╪к┘В╪▒┘К╪▒ ┘Ж╪м╪з╪н ┘И╪к╪н╪п┘К╪л ╪з┘Д╪г╪п╪з╪б
                            await report_cookie_success(cookies_file)
                            self.method_performance['ytdlp_cookies']['avg_time'] = (
                                self.method_performance['ytdlp_cookies']['avg_time'] * 0.7 + 
                                (time.time() - start_time) * 0.3
                            )
                            
                            return {
                                "audio_path": audio_path,
                                "title": info.get("title", video_info.get("title", ""))[:60],
                                "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                                "duration": int(info.get("duration", 0)),
                                "file_size": os.path.getsize(audio_path),
                                "source": f"ytdlp_cookies_{Path(cookies_file).name}"
                            }
                
                except Exception as e:
                    # ╪к┘В╪▒┘К╪▒ ┘Б╪┤┘Д
                    if 'cookies_file' in locals() and cookies_file:
                        await report_cookie_failure(cookies_file, str(e))
                    LOGGER(__name__).warning(f"┘Б╪┤┘Д yt-dlp ┘Е╪╣ ┘Г┘И┘Г┘К╪▓ {cookies_file}: {e}")
                    continue
                    
        except ImportError:
            # ╪з┘Д╪╣┘И╪п╪й ┘Д┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘В╪п┘К┘Е ╪е╪░╪з ┘Д┘Е ┘К┘Г┘Ж ╪з┘Д┘Е╪п┘К╪▒ ┘Е╪к╪з╪н╪з┘Л
            if COOKIES_CYCLE:
                for _ in range(len(COOKIES_FILES)):
                    try:
                        cookies_file = next(COOKIES_CYCLE)
                        opts = get_ytdlp_opts(cookies_file)
                        
                        loop = asyncio.get_running_loop()
                        info = await loop.run_in_executor(
                            self.conn_manager.executor_pool,
                            lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
                        )
                        
                        if info:
                            audio_path = f"downloads/{video_id}.mp3"
                            if os.path.exists(audio_path):
                                return {
                                    "audio_path": audio_path,
                                    "title": info.get("title", video_info.get("title", ""))[:60],
                                    "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                                    "duration": int(info.get("duration", 0)),
                                    "file_size": os.path.getsize(audio_path),
                                    "source": f"ytdlp_cookies_{cookies_file}"
                                }
                    
                    except Exception as e:
                        LOGGER(__name__).warning(f"┘Б╪┤┘Д yt-dlp ┘Е╪╣ ┘Г┘И┘Г┘К╪▓ {cookies_file}: {e}")
                        continue
        
        # ┘Е╪н╪з┘И┘Д╪й ╪и╪п┘И┘Ж ┘Г┘И┘Г┘К╪▓
        try:
            opts = get_ytdlp_opts()
            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(
                self.conn_manager.executor_pool,
                lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
            )
            
            if info:
                audio_path = f"downloads/{video_id}.mp3"
                if os.path.exists(audio_path):
                    self.method_performance['ytdlp_no_cookies']['avg_time'] = (
                        self.method_performance['ytdlp_no_cookies']['avg_time'] * 0.7 + 
                        (time.time() - start_time) * 0.3
                    )
                    return {
                        "audio_path": audio_path,
                        "title": info.get("title", video_info.get("title", ""))[:60],
                        "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                        "duration": int(info.get("duration", 0)),
                        "file_size": os.path.getsize(audio_path),
                        "source": "ytdlp_no_cookies"
                    }
        
        except Exception as e:
            LOGGER(__name__).error(f"┘Б╪┤┘Д yt-dlp ╪и╪п┘И┘Ж ┘Г┘И┘Г┘К╪▓: {e}")
            self.monitor.log_error('ytdlp_download')
        
        return None
    
    async def cache_to_channel(self, audio_info: Dict, search_query: str) -> Optional[str]:
        """╪н┘Б╪╕ ╪з┘Д┘Е┘Д┘Б ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪и╪з╪│╪к╪о╪п╪з┘Е Telethon"""
        if not SMART_CACHE_CHANNEL or not telethon_manager.bot_client:
            return None
        
        try:
            audio_path = audio_info["audio_path"]
            title = audio_info["title"]
            artist = audio_info["artist"]
            duration = audio_info["duration"]
            file_size = audio_info["file_size"]
            
            # ╪е┘Ж╪┤╪з╪б caption ┘Д┘Д┘Е┘Д┘Б
            caption = f"""ЁЯО╡ {title}
ЁЯОд {artist}
тП▒я╕П {duration}s | ЁЯУК {file_size/1024/1024:.1f}MB
ЁЯФЧ {audio_info["source"]}
ЁЯФН {search_query[:50]}"""
            
            # ╪▒┘Б╪╣ ╪з┘Д┘Е┘Д┘Б ┘Д┘Д┘В┘Ж╪з╪й
            message = await telethon_manager.bot_client.send_file(
                entity=SMART_CACHE_CHANNEL,
                file=audio_path,
                caption=caption,
                attributes=[
                    DocumentAttributeAudio(
                        duration=duration,
                        title=title[:60],
                        performer=artist[:40]
                    )
                ],
                supports_streaming=True
            )
            
            # ╪н┘Б╪╕ ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
            search_hash = self.create_search_hash(title, artist)
            normalized_title = self.normalize_text(title)
            normalized_artist = self.normalize_text(artist)
            keywords = f"{normalized_title} {normalized_artist} {self.normalize_text(search_query)}"
            
            async with self.conn_manager.db_connection() as conn:
                cursor = conn.cursor()
                
                # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й file_id ┘Е┘Ж Telethon
                file_id = message.document.id if message.document else None
                file_unique_id = getattr(message.document, 'access_hash', None)
                
                cursor.execute('''
                    INSERT OR REPLACE INTO channel_index 
                    (message_id, file_id, file_unique_id, search_hash, title_normalized, artist_normalized, 
                     keywords_vector, original_title, original_artist, duration, file_size)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    message.id, str(file_id), str(file_unique_id),
                    search_hash, normalized_title, normalized_artist, keywords,
                    title, artist, duration, file_size
                ))
                
                conn.commit()
            
            LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪н┘Б╪╕ {title} ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К")
            return str(file_id)
            
        except Exception as e:
            LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ╪з┘Д╪к╪о╪▓┘К┘Ж: {e}")
            self.monitor.log_error('cache_save')
        
        return None
    
    async def hyper_download(self, query: str) -> Optional[Dict]:
        """╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪о╪з╪▒┘В ┘Д┘Д╪к╪н┘Е┘К┘Д ┘Е╪╣ ╪м┘Е┘К╪╣ ╪з┘Д╪╖╪▒┘В"""
        task_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
        self.active_tasks.add(task_id)
        start_time = time.time()
        
        try:
            # ┘Б╪н╪╡ ╪з┘Д╪╡╪н╪й ╪з┘Д╪п┘И╪▒┘К
            await self.health_check()
            
            # ╪о╪╖┘И╪й 1: ╪з┘Д╪и╪н╪л ╪з┘Д┘Б┘И╪▒┘К ┘Б┘К ╪з┘Д┘Г╪з╪┤
            cached_result = await self.search_in_smart_cache(query)
            if cached_result:
                LOGGER(__name__).info(f"тЪб ┘Г╪з╪┤ ┘Б┘И╪▒┘К: {query} ({time.time() - start_time:.3f}s)")
                # ╪к╪н┘И┘К┘Д ╪з┘Д┘Ж╪к┘К╪м╪й ╪е┘Д┘Й ╪з┘Д╪к┘Ж╪│┘К┘В ╪з┘Д┘Е╪╖┘Д┘И╪и
                return {
                    'audio_path': cached_result.get('file_path'),
                    'title': cached_result.get('title', 'Unknown'),
                    'artist': cached_result.get('artist', 'Unknown'),
                    'duration': cached_result.get('duration', 0),
                    'source': 'smart_cache',
                    'cached': True
                }
            
            # ╪о╪╖┘И╪й 2: ╪з┘Д╪и╪н╪л ╪╣┘Ж ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Б┘К╪п┘К┘И ╪и╪з┘Д╪к┘И╪з╪▓┘К
            search_methods = []
            
            # ╪е╪╢╪з┘Б╪й ╪╖╪▒┘В ╪з┘Д╪и╪н╪л ╪и╪к╪▒╪к┘К╪и ╪з┘Д╪г┘И┘Д┘И┘К╪й
            
            # ╪г┘И┘Д┘И┘К╪й 1: YouTube Search (╪з┘Д╪г┘Г╪л╪▒ ┘Е┘И╪л┘И┘В┘К╪й)
            try:
                if YoutubeSearch:
                    search_methods.append(self.youtube_search_simple(query))
                    LOGGER(__name__).info(f"ЁЯФН ╪е╪╢╪з┘Б╪й YouTube Search ┘Д┘Д╪и╪н╪л")
            except Exception as e:
                LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ┘Б┘К ╪е╪╢╪з┘Б╪й YouTube Search: {e}")
            
            # ╪г┘И┘Д┘И┘К╪й 2: YouTube API (╪е╪░╪з ┘Г╪з┘Ж ┘Е╪к╪з╪н╪з┘Л)
            if API_KEYS_CYCLE:
                search_methods.append(self.youtube_api_search(query))
                LOGGER(__name__).info(f"ЁЯФН ╪е╪╢╪з┘Б╪й YouTube API ┘Д┘Д╪и╪н╪л")
            
            # ╪г┘И┘Д┘И┘К╪й 3: Invidious (┘Г╪и╪п┘К┘Д)
            if INVIDIOUS_CYCLE:
                search_methods.append(self.invidious_search(query))
                LOGGER(__name__).info(f"ЁЯФН ╪е╪╢╪з┘Б╪й Invidious ┘Д┘Д╪и╪н╪л")
            
            if not search_methods:
                LOGGER(__name__).error(f"тЭМ ┘Д╪з ╪к┘И╪м╪п ╪╖╪▒┘В ╪и╪н╪л ┘Е╪к╪з╪н╪й!")
                return None
            
            LOGGER(__name__).info(f"ЁЯЪА ╪и╪п╪б ╪з┘Д╪и╪н╪л ╪и┘А {len(search_methods)} ╪╖╪▒┘К┘В╪й")
            
            # ╪к╪┤╪║┘К┘Д ╪м┘Е┘К╪╣ ╪╣┘Е┘Д┘К╪з╪к ╪з┘Д╪и╪н╪л ╪и╪з┘Д╪к┘И╪з╪▓┘К
            search_tasks = [asyncio.create_task(method) for method in search_methods]
            done, pending = await asyncio.wait(
                search_tasks,
                timeout=REQUEST_TIMEOUT * 1.5,
                return_when=asyncio.FIRST_COMPLETED
            )
            
            # ╪е┘Д╪║╪з╪б ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е╪к╪и┘В┘К╪й
            for task in pending:
                task.cancel()
            
            # ╪г╪о╪░ ╪г┘И┘Д ┘Ж╪к┘К╪м╪й ┘Ж╪з╪м╪н╪й
            video_info = None
            for task in done:
                try:
                    result = task.result()
                    if result:
                        video_info = result
                        LOGGER(__name__).info(f"тЬЕ ┘Ж╪м╪н ╪з┘Д╪и╪н╪л: {result.get('title', 'Unknown')} ┘Е┘Ж {result.get('source', 'Unknown')}")
                        break
                except Exception as e:
                    LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д╪к ╪е╪н╪п┘Й ╪╖╪▒┘В ╪з┘Д╪и╪н╪л: {e}")
            
            if not video_info:
                LOGGER(__name__).error(f"тЭМ ┘Б╪┤┘Д ╪м┘Е┘К╪╣ ╪╖╪▒┘В ╪з┘Д╪и╪н╪л ┘Д┘А: {query}")
                return None
            
            # ╪о╪╖┘И╪й 3: ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪к
            LOGGER(__name__).info(f"ЁЯО╡ ╪и╪п╪б ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪к: {video_info.get('title', 'Unknown')}")
            audio_info = await self.download_with_ytdlp(video_info)
            if not audio_info:
                LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪г╪│╪з╪│┘К╪М ╪м╪з╪▒┘К ╪з┘Д┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪з╪н╪к┘К╪з╪╖┘К╪й...")
                # ┘Е╪н╪з┘И┘Д╪й ┘Ж╪│╪о╪й ╪з╪н╪к┘К╪з╪╖┘К╪й
                audio_info = await self.download_without_cookies(video_info)
                if not audio_info:
                    LOGGER(__name__).error(f"тЭМ ┘Б╪┤┘Д ╪м┘Е┘К╪╣ ╪╖╪▒┘В ╪з┘Д╪к╪н┘Е┘К┘Д ┘Д┘А: {video_info.get('title', 'Unknown')}")
                    return None
                else:
                    LOGGER(__name__).info(f"тЬЕ ┘Ж╪м╪н ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪з╪н╪к┘К╪з╪╖┘К: {audio_info.get('title', 'Unknown')}")
            else:
                LOGGER(__name__).info(f"тЬЕ ┘Ж╪м╪н ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪г╪│╪з╪│┘К: {audio_info.get('title', 'Unknown')}")
            
            # ╪о╪╖┘И╪й 4: ╪н┘Б╪╕ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К (┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й)
            if SMART_CACHE_CHANNEL:
                try:
                    # ╪│┘К╪к┘Е ╪з┘Д╪н┘Б╪╕ ┘Б┘К ╪п╪з┘Д╪й send_audio_file
                    pass
                except Exception as cache_error:
                    LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ╪з┘Д╪к╪о╪▓┘К┘Ж: {cache_error}")
            
            LOGGER(__name__).info(f"тЬЕ ╪к╪н┘Е┘К┘Д ╪м╪п┘К╪п: {query} ({time.time() - start_time:.3f}s)")
            
            return {
                'audio_path': audio_info['audio_path'],
                'title': audio_info['title'],
                'artist': audio_info['artist'],
                'duration': audio_info['duration'],
                'source': audio_info['source'],
                'cached': False
            }
            
        except Exception as e:
            LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪о╪з╪▒┘В: {e}")
            # self.monitor.log_error('hyper_download')
            return None
        finally:
            self.active_tasks.discard(task_id)
    
    async def direct_ytdlp_download(self, video_id: str, title: str = "Unknown") -> Optional[Dict]:
        """╪к╪н┘Е┘К┘Д ┘Е╪и╪з╪┤╪▒ ┘Е╪и╪│╪╖ ╪и╪з╪│╪к╪о╪п╪з┘Е yt-dlp"""
        if not yt_dlp:
            LOGGER(__name__).error("yt-dlp ╪║┘К╪▒ ┘Е╪к╪з╪н")
            return None
            
        start_time = time.time()
        LOGGER(__name__).info(f"ЁЯФД ╪и╪п╪б ╪к╪н┘Е┘К┘Д: {video_id}")
        
        try:
            # ╪е┘Ж╪┤╪з╪б ┘Е╪м┘Д╪п ╪з┘Д╪к╪н┘Е┘К┘Д
            temp_dir = Path(self.downloads_folder)
            temp_dir.mkdir(parents=True, exist_ok=True)
            
            # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪к╪з╪н╪й ┘Е╪╣ ╪з┘Д╪к╪п┘И┘К╪▒ ╪з┘Д╪░┘Г┘К
            cookies_files = get_available_cookies()
            LOGGER(__name__).info(f"ЁЯНк ┘Е╪к╪з╪н: {len(cookies_files)} ┘Е┘Д┘Б ┘Г┘И┘Г┘К╪▓ ┘Д┘Д╪к╪п┘И┘К╪▒")
            
            # ╪е╪╣╪п╪з╪п ┘Е╪н╪з┘И┘Д╪з╪к ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е╪╣ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪о╪к┘Д┘Б╪й
            ydl_configs = []
            
            # ╪е╪╢╪з┘Б╪й ┘Е╪н╪з┘И┘Д╪з╪к ┘Е╪╣ ┘Г┘Д ┘Е┘Д┘Б ┘Г┘И┘Г┘К╪▓ ┘Е╪╣ ╪з┘Д╪к┘И╪▓┘К╪╣ ╪з┘Д╪п┘К┘Ж╪з┘Е┘К┘Г┘К
            distribution = calculate_cookies_distribution(len(cookies_files))
            primary_count = distribution['primary']
            
            LOGGER(__name__).info(f"ЁЯНк ╪з┘Д╪к┘И╪▓┘К╪╣ ╪з┘Д╪п┘К┘Ж╪з┘Е┘К┘Г┘К: ╪г╪│╪з╪│┘К={primary_count}, ╪л╪з┘Ж┘И┘К={distribution['secondary']}, ┘Е╪к╪и┘В┘К={distribution['remaining']}")
            
            for i, cookie_file in enumerate(cookies_files[:primary_count], 1):
                ydl_configs.append({
                    'format': 'bestaudio/best',
                    'outtmpl': str(temp_dir / f'{video_id}_cookie_{i}.%(ext)s'),
                    'quiet': True,
                    'no_warnings': True,
                    'noplaylist': True,
                    'socket_timeout': 15,
                    'retries': 1,
                    'cookiefile': cookie_file,
                    'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    '_cookie_file': cookie_file,  # ╪к╪к╪и╪╣ ┘Е┘Д┘Б ╪з┘Д┘Г┘И┘Г┘К╪▓
                    '_cookie_index': i  # ╪▒┘В┘Е ╪з┘Д┘Г┘И┘Г┘К╪▓
                })
            
            # ╪е╪╢╪з┘Б╪й ┘Е╪н╪з┘И┘Д╪з╪к ╪и╪п┘И┘Ж ┘Г┘И┘Г┘К╪▓ ┘Е╪╣ user agents ┘Е╪о╪к┘Д┘Б╪й
            ydl_configs.extend([
                {
                    'format': 'worstaudio[ext=webm]/worstaudio[ext=m4a]/worstaudio',
                    'outtmpl': str(temp_dir / f'{video_id}_low.%(ext)s'),
                    'quiet': True,
                    'no_warnings': True,
                    'noplaylist': True,
                    'socket_timeout': 10,
                    'retries': 1,
                    'user_agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15',
                    'referer': 'https://m.youtube.com/',
                },
                {
                    'format': 'bestaudio[filesize<50M]/best[filesize<50M]',
                    'outtmpl': str(temp_dir / f'{video_id}_med.%(ext)s'),
                    'quiet': True,
                    'no_warnings': True,
                    'noplaylist': True,
                    'socket_timeout': 15,
                    'retries': 1,
                    'user_agent': 'Mozilla/5.0 (Android 10; Mobile; rv:91.0) Gecko/91.0 Firefox/91.0',
                }
            ])
            
            # ╪м╪▒╪и ┘Г┘Д ╪е╪╣╪п╪з╪п ╪н╪к┘Й ┘К┘Ж╪м╪н ╪г╪н╪п┘З┘Е ┘Е╪╣ ╪к╪к╪и╪╣ ╪з┘Д┘Г┘И┘Г┘К╪▓
            for i, ydl_opts in enumerate(ydl_configs, 1):
                cookie_file = ydl_opts.get('_cookie_file')
                
                try:
                    LOGGER(__name__).info(f"ЁЯФД ┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪к╪н┘Е┘К┘Д #{i}")
                    if cookie_file:
                        LOGGER(__name__).info(f"ЁЯНк ╪з╪│╪к╪о╪п╪з┘Е ┘Г┘И┘Г┘К╪▓: {os.path.basename(cookie_file)}")
                    
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        info = ydl.extract_info(
                            f"https://www.youtube.com/watch?v={video_id}",
                            download=True
                        )
                        
                        if info:
                            # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д
                            LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪и┘Ж╪м╪з╪н ╪и╪з┘Д┘Е╪н╪з┘И┘Д╪й #{i}: {info.get('title', title)}")
                            
                            # ╪к╪к╪и╪╣ ┘Ж╪м╪з╪н ╪з┘Д┘Г┘И┘Г┘К╪▓
                            if cookie_file:
                                track_cookie_usage(cookie_file, success=True)
                            
                            for file_path in temp_dir.glob(f"{video_id}*.*"):
                                if file_path.suffix in ['.m4a', '.mp3', '.webm', '.mp4', '.opus']:
                                    LOGGER(__name__).info(f"ЁЯУБ ┘Е┘Д┘Б ┘Е╪н┘Е┘Д: {file_path}")
                                    return {
                                        'success': True,
                                        'file_path': str(file_path),
                                        'title': info.get('title', title),
                                        'duration': info.get('duration', 0),
                                        'uploader': info.get('uploader', 'Unknown'),
                                        'elapsed': time.time() - start_time
                                    }
                            break
                            
                except Exception as e:
                    error_msg = str(e).lower()
                    LOGGER(__name__).warning(f"тЭМ ┘Б╪┤┘Д╪к ╪з┘Д┘Е╪н╪з┘И┘Д╪й #{i}: {e}")
                    
                    # ╪к╪к╪и╪╣ ┘Б╪┤┘Д ╪з┘Д┘Г┘И┘Г┘К╪▓
                    if cookie_file:
                        track_cookie_usage(cookie_file, success=False)
                    
                    # ┘Б╪н╪╡ ╪г╪о╪╖╪з╪б ╪з┘Д╪н╪╕╪▒ ┘И╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е┘Ж╪к┘З┘К╪й ╪з┘Д╪╡┘Д╪з╪н┘К╪й
                    if cookie_file and any(keyword in error_msg for keyword in [
                        'blocked', 'forbidden', '403', 'unavailable', 'cookies', 'expired',
                        'sign in', 'login', 'authentication', 'token', 'session', 'captcha'
                    ]):
                        mark_cookie_as_blocked(cookie_file, f"╪о╪╖╪г: {str(e)[:50]}")
                        LOGGER(__name__).warning(f"ЁЯЪл ╪к┘Е ╪н╪╕╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪и╪│╪и╪и: {str(e)[:50]}")
                    
                    if i < len(ydl_configs):
                        LOGGER(__name__).info(f"ЁЯФД ╪м╪з╪▒┘К ╪з┘Д┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪к╪з┘Д┘К╪й...")
                        continue
                    else:
                        LOGGER(__name__).error(f"тЭМ ┘Б╪┤┘Д╪к ╪м┘Е┘К╪╣ ┘Е╪н╪з┘И┘Д╪з╪к ╪з┘Д╪к╪н┘Е┘К┘Д")
            
            LOGGER(__name__).error("тЭМ ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Е┘Д┘Б ┘Е╪н┘Е┘Д")
            
            # ┘Е╪н╪з┘И┘Д╪й ╪г╪о┘К╪▒╪й ╪и╪з╪│╪к╪о╪п╪з┘Е pytube
            LOGGER(__name__).info("ЁЯФД ┘Е╪н╪з┘И┘Д╪й ╪г╪о┘К╪▒╪й ╪и╪з╪│╪к╪о╪п╪з┘Е pytube")
            try:
                from pytube import YouTube
                
                yt = YouTube(f"https://www.youtube.com/watch?v={video_id}")
                audio_stream = yt.streams.filter(only_audio=True).first()
                
                if audio_stream:
                    output_file = audio_stream.download(
                        output_path=str(temp_dir),
                        filename=f"{video_id}_pytube.mp4"
                    )
                    
                    if output_file and os.path.exists(output_file):
                        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪и┘Ж╪м╪з╪н ╪и╪з╪│╪к╪о╪п╪з┘Е pytube: {output_file}")
                        return {
                            'success': True,
                            'file_path': output_file,
                            'title': yt.title or title,
                            'duration': yt.length or 0,
                            'uploader': yt.author or 'Unknown',
                            'elapsed': time.time() - start_time
                        }
                        
            except Exception as pytube_error:
                LOGGER(__name__).error(f"тЭМ ┘Б╪┤┘Д pytube ╪г┘К╪╢╪з┘Л: {pytube_error}")
            
            return None
            
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪и╪з╪┤╪▒: {e}")
            return None

    async def download_without_cookies(self, video_info: Dict) -> Optional[Dict]:
        """╪к╪н┘Е┘К┘Д ╪и╪п┘И┘Ж ┘Г┘И┘Г┘К╪▓ - ┘Ж╪│╪о╪й ┘Е╪и╪│╪╖╪й ┘И╪│╪▒┘К╪╣╪й"""
        if not yt_dlp:
            return None
            
        video_id = video_info.get("video_id")
        if not video_id:
            return None
        
        task_id = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
        self.active_tasks.add(task_id)
        start_time = time.time()
        
        try:
            # ╪е╪╣╪п╪з╪п╪з╪к ╪│╪▒┘К╪╣╪й ┘И┘Е┘И╪л┘И┘В╪й
            opts = {
                'format': 'worstaudio[ext=m4a]/worstaudio',
                'outtmpl': f'downloads/{video_id}_fallback.%(ext)s',
                'quiet': True,
                'no_warnings': True,
                'ignoreerrors': True,
                'extract_flat': False,
                'writethumbnail': False,
                'writeinfojson': False,
                'user_agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X)',
                'referer': 'https://www.google.com/',
                'timeout': 15,
                'retries': 1,
                'fragment_retries': 1,
                'skip_unavailable_fragments': True,
                'noprogress': True,
                'socket_timeout': 10,
                'force_generic_extractor': True,
            }
            
            url = f"https://youtu.be/{video_id}"
            
            loop = asyncio.get_running_loop()
            info = await loop.run_in_executor(
                self.conn_manager.executor_pool,
                lambda: yt_dlp.YoutubeDL(opts).extract_info(url, download=True)
            )
            
            if info:
                # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д
                possible_files = [
                    f"downloads/{video_id}_fallback.m4a",
                    f"downloads/{video_id}_fallback.mp3",
                    f"downloads/{video_id}_fallback.webm"
                ]
                
                for audio_path in possible_files:
                    if os.path.exists(audio_path):
                        return {
                            "audio_path": audio_path,
                            "title": info.get("title", video_info.get("title", ""))[:60],
                            "artist": info.get("uploader", video_info.get("artist", "Unknown")),
                            "duration": int(info.get("duration", 0)),
                            "file_size": os.path.getsize(audio_path),
                            "source": "ytdlp_simple_fallback",
                            "elapsed": time.time() - start_time
                        }
                        
        except Exception as e:
            LOGGER(__name__).error(f"┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д ╪и╪п┘И┘Ж ┘Г┘И┘Г┘К╪▓: {e}")
            # self.monitor.log_error('fallback_download')
        finally:
            self.active_tasks.discard(task_id)
            
        return None

# ┘Ж╪╕╪з┘Е ╪к╪к╪и╪╣ ╪н╪з┘Д╪й ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓
COOKIES_STATUS = {}
BLOCKED_COOKIES = set()
COOKIES_USAGE_COUNT = {}
LAST_COOKIE_USED = None

# ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К
PARALLEL_SEARCH_STATS = {
    'database_wins': 0,
    'smart_cache_wins': 0,
    'total_searches': 0,
    'avg_database_time': 0,
    'avg_smart_cache_time': 0,
    'database_times': [],
    'smart_cache_times': []
}

# ┘Ж╪╕╪з┘Е ╪е╪п╪з╪▒╪й ╪з┘Д╪н┘Е┘И┘Д╪й ╪з┘Д╪╣╪з┘Д┘К╪й

# ╪е╪╣╪п╪з╪п╪з╪к ╪з┘Д╪н┘Е┘И┘Д╪й ╪з┘Д╪╣╪з┘Д┘К╪й (┘Е╪н╪│┘Ж╪й ┘Д┘Д╪г╪п╪з╪б)
MAX_CONCURRENT_DOWNLOADS = 20          # ╪н╪п ┘Е╪╣┘В┘И┘Д ┘Д┘Д╪к╪н┘Е┘К┘Д╪з╪к ╪з┘Д┘Е╪к┘И╪з╪▓┘К╪й
MAX_CONCURRENT_SEARCHES = 30           # ╪н╪п ┘Е╪╣┘В┘И┘Д ┘Д┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К
MAX_QUEUE_SIZE = float('inf')          # ┘Д╪з ╪н╪п ╪г┘В╪╡┘Й ┘Д┘Д╪╖╪з╪и┘И╪▒
RATE_LIMIT_WINDOW = 60                  # ┘Ж╪з┘Б╪▓╪й ╪▓┘Е┘Ж┘К╪й ╪и╪з┘Д╪л┘И╪з┘Ж┘К
MAX_REQUESTS_PER_WINDOW = 1000          # ╪н╪п ┘Е╪▒┘Ж ┘Д┘Д╪╖┘Д╪и╪з╪к (┘Е╪╢╪з╪╣┘Б)

# ╪г╪п┘И╪з╪к ╪е╪п╪з╪▒╪й ╪з┘Д┘Е┘И╪з╪▒╪п (╪и╪п┘И┘Ж ╪н╪п┘И╪п)
# download_semaphore = None  # ╪е╪▓╪з┘Д╪й ╪з┘Д╪к╪н╪п┘К╪п
# search_semaphore = None    # ╪е╪▓╪з┘Д╪й ╪з┘Д╪к╪н╪п┘К╪п
thread_pool = ThreadPoolExecutor(max_workers=100)  # ╪▓┘К╪з╪п╪й ╪╣╪п╪п ╪з┘Д╪о┘К┘И╪╖

# ╪к╪к╪и╪╣ ┘Е╪╣╪п┘Д ╪з┘Д╪╖┘Д╪и╪з╪к (┘Е╪▒┘Ж)
request_times = defaultdict(lambda: deque(maxlen=MAX_REQUESTS_PER_WINDOW))
active_downloads = {}
# download_queue = asyncio.Queue()  # ╪╖╪з╪и┘И╪▒ ╪и┘Д╪з ╪н╪п┘И╪п (┘Д┘Ж ┘Ж╪н╪к╪з╪м┘З)

# ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б
PERFORMANCE_STATS = {
    'total_requests': 0,
    'successful_downloads': 0,
    'failed_downloads': 0,
    'cache_hits': 0,
    'avg_response_time': 0,
    'peak_concurrent': 0,
    'current_concurrent': 0,
    'queue_size': 0,
    'rate_limited': 0
}

async def check_rate_limit(user_id: int) -> bool:
    """┘Б╪н╪╡ ┘Е╪╣╪п┘Д ╪з┘Д╪╖┘Д╪и╪з╪к ┘Д┘Д┘Е╪│╪к╪о╪п┘Е (┘Е╪▒┘Ж)"""
    current_time = time.time()
    user_requests = request_times[user_id]
    
    # ╪е╪▓╪з┘Д╪й ╪з┘Д╪╖┘Д╪и╪з╪к ╪з┘Д┘В╪п┘К┘Е╪й
    while user_requests and current_time - user_requests[0] > RATE_LIMIT_WINDOW:
        user_requests.popleft()
    
    # ┘Б╪н╪╡ ┘Е╪▒┘Ж - ╪к╪н╪░┘К╪▒ ┘Б┘В╪╖ ╪╣┘Ж╪п ╪к╪м╪з┘И╪▓ ╪з┘Д╪н╪п ╪з┘Д┘Е┘В╪к╪▒╪н
    if len(user_requests) >= MAX_REQUESTS_PER_WINDOW:
        PERFORMANCE_STATS['rate_limited'] += 1
        # ╪к╪│╪м┘К┘Д ╪к╪н╪░┘К╪▒ ┘Д┘Г┘Ж ╪з┘Д╪│┘Е╪з╪н ╪и╪з┘Д┘Е╪к╪з╪и╪╣╪й
        LOGGER(__name__).warning(f"тЪая╕П ╪з┘Д┘Е╪│╪к╪о╪п┘Е {user_id} ╪к╪м╪з┘И╪▓ ╪з┘Д╪н╪п ╪з┘Д┘Е┘В╪к╪▒╪н: {len(user_requests)} ╪╖┘Д╪и ┘Б┘К {RATE_LIMIT_WINDOW}s")
        
        # ╪з┘Д╪│┘Е╪з╪н ╪и╪з┘Д┘Е╪к╪з╪и╪╣╪й ┘Д┘Д╪н┘Е┘И┘Д╪й ╪з┘Д╪╣╪з┘Д┘К╪й
        # return False  # ┘Е╪╣╪╖┘Д - ┘Д╪з ╪н╪п┘И╪п ╪╡╪з╪▒┘Е╪й
    
    # ╪е╪╢╪з┘Б╪й ╪з┘Д╪╖┘Д╪и ╪з┘Д╪н╪з┘Д┘К
    user_requests.append(current_time)
    return True  # ╪з┘Д╪│┘Е╪з╪н ╪п╪з╪ж┘Е╪з┘Л

async def update_performance_stats(success: bool, response_time: float, from_cache: bool = False):
    """╪к╪н╪п┘К╪л ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б"""
    PERFORMANCE_STATS['total_requests'] += 1
    
    if success:
        PERFORMANCE_STATS['successful_downloads'] += 1
    else:
        PERFORMANCE_STATS['failed_downloads'] += 1
    
    if from_cache:
        PERFORMANCE_STATS['cache_hits'] += 1
    
    # ╪к╪н╪п┘К╪л ┘Е╪к┘И╪│╪╖ ┘И┘В╪к ╪з┘Д╪з╪│╪к╪м╪з╪и╪й
    current_avg = PERFORMANCE_STATS['avg_response_time']
    total_requests = PERFORMANCE_STATS['total_requests']
    PERFORMANCE_STATS['avg_response_time'] = ((current_avg * (total_requests - 1)) + response_time) / total_requests
    
    # ╪к╪н╪п┘К╪л ╪з┘Д╪░╪▒┘И╪й
    current_concurrent = len(active_downloads)
    PERFORMANCE_STATS['current_concurrent'] = current_concurrent
    if current_concurrent > PERFORMANCE_STATS['peak_concurrent']:
        PERFORMANCE_STATS['peak_concurrent'] = current_concurrent
    
    PERFORMANCE_STATS['queue_size'] = 0  # ┘Д╪з ┘К┘И╪м╪п ╪╖╪з╪и┘И╪▒ - ┘Е╪╣╪з┘Д╪м╪й ┘Б┘И╪▒┘К╪й

def log_performance_stats():
    """╪к╪│╪м┘К┘Д ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б"""
    stats = PERFORMANCE_STATS
    success_rate = (stats['successful_downloads'] / max(stats['total_requests'], 1)) * 100
    cache_hit_rate = (stats['cache_hits'] / max(stats['total_requests'], 1)) * 100
    
    LOGGER(__name__).info(
        f"ЁЯУК ╪з┘Д╪г╪п╪з╪б: {stats['total_requests']} ╪╖┘Д╪и | "
        f"┘Ж╪м╪з╪н: {success_rate:.1f}% | "
        f"┘Г╪з╪┤: {cache_hit_rate:.1f}% | "
        f"┘Е╪к┘И╪│╪╖: {stats['avg_response_time']:.2f}s | "
        f"┘Е╪к┘И╪з╪▓┘К: {stats['current_concurrent']}/{stats['peak_concurrent']} | "
        f"╪╖╪з╪и┘И╪▒: {stats['queue_size']}"
    )

async def process_unlimited_download(event, user_id: int, start_time: float):
    """┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Б┘И╪▒┘К"""
    task_id = f"{user_id}_{int(time.time() * 1000000)}"  # ╪п┘В╪й ╪╣╪з┘Д┘К╪й ╪м╪п╪з┘Л
    
    try:
        # ╪к╪│╪м┘К┘Д ╪и╪п╪з┘К╪й ╪з┘Д┘Е┘З┘Е╪й ┘Б┘И╪▒╪з┘Л
        active_downloads[task_id] = {
            'user_id': user_id,
            'start_time': start_time,
            'task_id': task_id,
            'status': 'started'
        }
        
        LOGGER(__name__).info(f"ЁЯЪА ╪и╪п╪б ┘Е╪╣╪з┘Д╪м╪й ┘Б┘И╪▒┘К╪й ┘Д┘Д┘Е╪│╪к╪о╪п┘Е {user_id} | ╪з┘Д┘Е┘З┘Е╪й: {task_id}")
        
        # ╪к┘Ж┘Б┘К╪░ ╪з┘Д┘Е╪╣╪з┘Д╪м╪й ╪з┘Д┘Г╪з┘Е┘Д╪й ┘Б┘К ┘Е┘З┘Е╪й ┘Е┘Ж┘Б╪╡┘Д╪й
        await execute_parallel_download(event, user_id, start_time, task_id)
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К: {e}")
        await update_performance_stats(False, time.time() - start_time)
    finally:
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Е┘З┘Е╪й
        if task_id in active_downloads:
            active_downloads[task_id]['status'] = 'completed'
            del active_downloads[task_id]

async def execute_parallel_download(event, user_id: int, start_time: float, task_id: str):
    """╪к┘Ж┘Б┘К╪░ ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Г╪з┘Е┘Д"""
    try:
        # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е
        match = event.pattern_match
        if not match:
            await event.reply("тЭМ **╪о╪╖╪г ┘Б┘К ╪к╪н┘Д┘К┘Д ╪з┘Д╪╖┘Д╪и**")
            return
        
        query = match.group(2) if match.group(2) else ""
        if not query:
            await event.reply("ЁЯУЭ **╪з┘Д╪з╪│╪к╪о╪п╪з┘Е:** `╪и╪н╪л ╪з╪│┘Е ╪з┘Д╪г╪║┘Ж┘К╪й`")
            await update_performance_stats(False, time.time() - start_time)
            return
        
        # ╪к╪н╪п┘К╪л ╪н╪з┘Д╪й ╪з┘Д┘Е┘З┘Е╪й
        if task_id in active_downloads:
            active_downloads[task_id].update({
                'query': query,
                'status': 'processing'
            })
        
        LOGGER(__name__).info(f"ЁЯО╡ ┘Е╪╣╪з┘Д╪м╪й ┘Е╪к┘И╪з╪▓┘К╪й: {query} | ╪з┘Д┘Е╪│╪к╪о╪п┘Е: {user_id} | ╪з┘Д┘Е┘З┘Е╪й: {task_id}")
        
        # ╪к┘Ж┘Б┘К╪░ ╪з┘Д╪и╪н╪л ┘И╪з┘Д╪к╪н┘Е┘К┘Д ┘Е╪и╪з╪┤╪▒╪й
        await process_normal_download(event, query, user_id, start_time)
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪к┘Ж┘Б┘К╪░ ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К: {e}")
        await event.reply("тЭМ **╪н╪п╪л ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪╖┘Д╪и┘Г**")
        await update_performance_stats(False, time.time() - start_time)

async def process_normal_download(event, query: str, user_id: int, start_time: float):
    """┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪╣╪з╪п┘К ┘Е╪╣ ╪е╪п╪з╪▒╪й ╪з┘Д┘Е┘И╪з╪▒╪п"""
    bot_client = event.client
    
    try:
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪г┘Ж ╪з┘Д┘Е╪▒╪│┘Д ┘Д┘К╪│ ╪и┘И╪к
        if event.sender.bot:
            return
        
        # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е ╪е╪░╪з ┘Д┘Е ┘К┘Г┘Ж ┘Е╪к┘И┘Б╪▒╪з┘Л
        if not query:
            match = event.pattern_match
            if not match:
                return
            
            query = match.group(2) if match.group(2) else ""
            if not query:
                await event.reply("ЁЯУЭ **╪з┘Д╪з╪│╪к╪о╪п╪з┘Е:** `╪и╪н╪л ╪з╪│┘Е ╪з┘Д╪г╪║┘Ж┘К╪й`")
                await update_performance_stats(False, time.time() - start_time)
                return
        
        # ╪е╪▒╪│╪з┘Д ╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й
        status_msg = await event.reply("ЁЯФН **╪м╪з╪▒┘К ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К...**")
        
        # ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪и╪п┘И┘Ж ╪н╪п┘И╪п
        parallel_result = await parallel_search_with_monitoring(query, bot_client)
        
        if parallel_result and parallel_result.get('success'):
            search_source = parallel_result.get('search_source', 'unknown')
            search_time = parallel_result.get('search_time', 0)
            
            # ╪к╪н╪п┘К╪л ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
            await update_performance_stats(True, time.time() - start_time, from_cache=True)
            
            if search_source == 'database':
                await status_msg.edit(f"ЁЯУд **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ({search_time:.2f}s) - ╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                await send_cached_from_database(event, status_msg, parallel_result, bot_client)
                return
            elif search_source == 'smart_cache':
                await status_msg.edit(f"ЁЯУд **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ({search_time:.2f}s) - ╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                await send_cached_audio(event, status_msg, parallel_result, bot_client)
                return
        
        # ╪е╪░╪з ┘Д┘Е ┘К╪м╪п ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж╪М ╪з╪и╪п╪г ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪╣╪з╪п┘К
        await status_msg.edit("ЁЯФН **┘Д┘Е ┘К┘И╪м╪п ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж - ╪м╪з╪▒┘К ╪з┘Д╪и╪н╪л ┘Б┘К ┘К┘И╪к┘К┘И╪и...**")
        
        # ┘З┘Ж╪з ┘К╪к┘Е ╪з╪│╪к╪п╪╣╪з╪б ╪и╪з┘В┘К ┘Е┘Ж╪╖┘В ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪╣╪з╪п┘К ╪з┘Д┘Е┘И╪м┘И╪п
        # (╪│┘К╪к┘Е ╪▒╪и╪╖┘З ┘Е╪╣ ╪з┘Д┘Г┘И╪п ╪з┘Д┘Е┘И╪м┘И╪п)
        
        # ╪к╪н╪п┘К╪л ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
        await update_performance_stats(True, time.time() - start_time)
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪╣╪з╪п┘К╪й: {e}")
        await update_performance_stats(False, time.time() - start_time)
        
        try:
            await status_msg.edit("тЭМ **╪н╪п╪л ╪о╪╖╪г ╪г╪л┘Ж╪з╪б ╪з┘Д┘Е╪╣╪з┘Д╪м╪й**")
        except:
            pass

def get_available_cookies():
    """╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘В╪з╪ж┘Е╪й ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪к╪з╪н╪й ┘Е╪╣ ╪к╪п┘И┘К╪▒ ╪░┘Г┘К"""
    try:
        import glob
        import os
        cookies_pattern = "cookies/cookies*.txt"
        all_cookies_files = glob.glob(cookies_pattern)
        
        # ╪е╪▓╪з┘Д╪й ╪з┘Д┘Е┘Д┘Б╪з╪к ╪з┘Д┘Е╪н╪╕┘И╪▒╪й
        available_cookies = []
        for cookie_file in all_cookies_files:
            if cookie_file not in BLOCKED_COOKIES:
                available_cookies.append(cookie_file)
        
        if not available_cookies:
            LOGGER(__name__).warning("тЪая╕П ╪м┘Е┘К╪╣ ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓ ┘Е╪н╪╕┘И╪▒╪й! ╪м╪з╪▒┘К ╪е╪╣╪з╪п╪й ╪к╪╣┘К┘К┘Ж...")
            BLOCKED_COOKIES.clear()
            available_cookies = all_cookies_files
        
        # ╪к╪▒╪к┘К╪и ╪░┘Г┘К: ╪з┘Д╪г┘В┘Д ╪з╪│╪к╪о╪п╪з┘Е╪з┘Л ╪г┘И┘Д╪з┘Л
        available_cookies.sort(key=lambda x: (
            COOKIES_USAGE_COUNT.get(x, 0),  # ╪╣╪п╪п ┘Е╪▒╪з╪к ╪з┘Д╪з╪│╪к╪о╪п╪з┘Е
            os.path.getmtime(x)  # ╪к╪з╪▒┘К╪о ╪з┘Д╪к╪╣╪п┘К┘Д
        ))
        
        LOGGER(__name__).info(f"ЁЯНк ┘Е╪к╪з╪н: {len(available_cookies)} | ┘Е╪н╪╕┘И╪▒: {len(BLOCKED_COOKIES)} ┘Е┘Д┘Б ┘Г┘И┘Г┘К╪▓")
        return available_cookies
    except Exception as e:
        LOGGER(__name__).warning(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘В╪▒╪з╪б╪й ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓: {e}")
        return []

def mark_cookie_as_blocked(cookie_file: str, reason: str = "╪н╪╕╪▒"):
    """╪к┘Е┘К┘К╪▓ ┘Е┘Д┘Б ┘Г┘И┘Г┘К╪▓ ┘Г┘Е╪н╪╕┘И╪▒ ┘И╪н╪░┘Б┘З"""
    try:
        BLOCKED_COOKIES.add(cookie_file)
        LOGGER(__name__).warning(f"ЁЯЪл ╪к┘Е ╪н╪╕╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓: {os.path.basename(cookie_file)} - {reason}")
        
        # ┘Ж╪│╪о ╪з╪н╪к┘К╪з╪╖┘К ┘В╪и┘Д ╪з┘Д╪н╪░┘Б
        backup_name = f"{cookie_file}.blocked_{int(time.time())}"
        if os.path.exists(cookie_file):
            os.rename(cookie_file, backup_name)
            LOGGER(__name__).info(f"ЁЯТ╛ ╪к┘Е ┘Ж╪│╪о ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪н╪╕┘И╪▒ ╪е┘Д┘Й: {os.path.basename(backup_name)}")
        
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
        if cookie_file in COOKIES_USAGE_COUNT:
            del COOKIES_USAGE_COUNT[cookie_file]
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н╪╕╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓: {e}")

def track_cookie_usage(cookie_file: str, success: bool = True):
    """╪к╪к╪и╪╣ ╪з╪│╪к╪о╪п╪з┘Е ┘Е┘Д┘Б ╪з┘Д┘Г┘И┘Г┘К╪▓"""
    global LAST_COOKIE_USED
    
    COOKIES_USAGE_COUNT[cookie_file] = COOKIES_USAGE_COUNT.get(cookie_file, 0) + 1
    LAST_COOKIE_USED = cookie_file
    
    status = "тЬЕ" if success else "тЭМ"
    usage_count = COOKIES_USAGE_COUNT[cookie_file]
    
    LOGGER(__name__).info(f"{status} ┘Г┘И┘Г┘К╪▓: {os.path.basename(cookie_file)} (╪з╪│╪к╪о╪п╪з┘Е #{usage_count})")

def get_next_cookie_with_rotation():
    """╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е┘Д┘Б ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д╪к╪з┘Д┘К ┘Е╪╣ ╪к╪п┘И┘К╪▒ ╪░┘Г┘К"""
    available_cookies = get_available_cookies()
    
    if not available_cookies:
        return None
    
    # ╪к╪м┘Ж╪и ╪з╪│╪к╪о╪п╪з┘Е ┘Ж┘Б╪│ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪│╪к╪о╪п┘Е ┘Е╪д╪о╪▒╪з┘Л
    if LAST_COOKIE_USED and len(available_cookies) > 1:
        try:
            available_cookies.remove(LAST_COOKIE_USED)
        except ValueError:
            pass
    
    # ╪з╪о╪к┘К╪з╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д╪г┘В┘Д ╪з╪│╪к╪о╪п╪з┘Е╪з┘Л
    next_cookie = available_cookies[0]
    LOGGER(__name__).info(f"ЁЯФД ╪к╪п┘И┘К╪▒ ╪е┘Д┘Й ┘Г┘И┘Г┘К╪▓: {os.path.basename(next_cookie)}")
    
    return next_cookie

def cleanup_blocked_cookies():
    """╪к┘Ж╪╕┘К┘Б ╪п┘И╪▒┘К ┘Д┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪н╪╕┘И╪▒╪й"""
    try:
        import glob
        # ╪е╪░╪з ╪к┘Е ╪н╪╕╪▒ ╪г┘Г╪л╪▒ ┘Е┘Ж 70% ┘Е┘Ж ╪з┘Д┘Г┘И┘Г┘К╪▓╪М ╪з╪╣╪п ╪к╪╣┘К┘К┘Ж ╪з┘Д┘Ж╪╕╪з┘Е
        total_cookies = len(glob.glob("cookies/cookies*.txt"))
        blocked_count = len(BLOCKED_COOKIES)
        
        if total_cookies > 0 and (blocked_count / total_cookies) > 0.7:
            LOGGER(__name__).warning(f"тЪая╕П ╪к┘Е ╪н╪╕╪▒ {blocked_count}/{total_cookies} ┘Г┘И┘Г┘К╪▓ - ╪е╪╣╪з╪п╪й ╪к╪╣┘К┘К┘Ж ╪з┘Д┘Ж╪╕╪з┘Е")
            BLOCKED_COOKIES.clear()
            COOKIES_USAGE_COUNT.clear()
            
        # ╪н╪░┘Б ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д╪з╪н╪к┘К╪з╪╖┘К╪й ╪з┘Д┘В╪п┘К┘Е╪й (╪г┘Г╪л╪▒ ┘Е┘Ж 24 ╪│╪з╪╣╪й)
        import time
        current_time = time.time()
        
        for backup_file in glob.glob("cookies/*.blocked_*"):
            try:
                file_time = os.path.getmtime(backup_file)
                if current_time - file_time > 86400:  # 24 ╪│╪з╪╣╪й
                    os.remove(backup_file)
                    LOGGER(__name__).info(f"ЁЯЧСя╕П ╪к┘Е ╪н╪░┘Б ╪з┘Д┘Ж╪│╪о╪й ╪з┘Д╪з╪н╪к┘К╪з╪╖┘К╪й ╪з┘Д┘В╪п┘К┘Е╪й: {os.path.basename(backup_file)}")
            except Exception as e:
                LOGGER(__name__).warning(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н╪░┘Б ╪з┘Д┘Ж╪│╪о╪й ╪з┘Д╪з╪н╪к┘К╪з╪╖┘К╪й: {e}")
                
        LOGGER(__name__).info(f"ЁЯз╣ ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Г┘И┘Г┘К╪▓: ┘Е╪к╪з╪н={total_cookies-blocked_count} | ┘Е╪н╪╕┘И╪▒={blocked_count}")
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Г┘И┘Г┘К╪▓: {e}")

def calculate_cookies_distribution(total_count: int) -> Dict[str, int]:
    """╪н╪│╪з╪и ╪к┘И╪▓┘К╪╣ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪и╪┤┘Г┘Д ╪п┘К┘Ж╪з┘Е┘К┘Г┘К"""
    if total_count == 0:
        return {'primary': 0, 'secondary': 0, 'remaining': 0}
    
    # ╪к┘И╪▓┘К╪╣ ╪░┘Г┘К ╪н╪│╪и ╪з┘Д╪╣╪п╪п ╪з┘Д╪е╪м┘Е╪з┘Д┘К
    if total_count <= 5:
        # ╪╣╪п╪п ┘В┘Д┘К┘Д: ╪з╪│╪к╪о╪п┘Е ╪з┘Д┘Г┘Д ┘Б┘К ╪з┘Д┘Е╪▒╪н┘Д╪й ╪з┘Д╪г╪│╪з╪│┘К╪й
        return {'primary': total_count, 'secondary': 0, 'remaining': 0}
    
    elif total_count <= 10:
        # ╪╣╪п╪п ┘Е╪к┘И╪│╪╖: ┘В╪│┘Е ╪и┘К┘Ж ╪г╪│╪з╪│┘К ┘И╪л╪з┘Ж┘И┘К
        primary = total_count // 2
        secondary = total_count - primary
        return {'primary': primary, 'secondary': secondary, 'remaining': 0}
    
    elif total_count <= 20:
        # ╪╣╪п╪п ┘Г╪и┘К╪▒: ╪к┘И╪▓┘К╪╣ ┘Е╪к┘И╪з╪▓┘Ж
        primary = max(4, total_count // 3)
        secondary = max(3, total_count // 4)
        remaining = total_count - primary - secondary
        return {'primary': primary, 'secondary': secondary, 'remaining': remaining}
    
    else:
        # ╪╣╪п╪п ┘Г╪и┘К╪▒ ╪м╪п╪з┘Л: ╪к┘И╪▓┘К╪╣ ┘Е╪н╪п┘И╪п ┘Д╪к╪м┘Ж╪и ╪з┘Д╪е┘Б╪▒╪з╪╖
        primary = min(8, max(5, total_count // 4))
        secondary = min(6, max(4, total_count // 5))
        remaining = min(10, total_count - primary - secondary)
        return {'primary': primary, 'secondary': secondary, 'remaining': remaining}

def get_cookies_statistics():
    """╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д┘Г┘И┘Г┘К╪▓ ┘Е╪╣ ╪з┘Д╪к┘И╪▓┘К╪╣ ╪з┘Д╪п┘К┘Ж╪з┘Е┘К┘Г┘К"""
    try:
        import glob
        total_cookies = len(glob.glob("cookies/cookies*.txt"))
        available_cookies = len(get_available_cookies())
        blocked_cookies = len(BLOCKED_COOKIES)
        
        # ╪н╪│╪з╪и ╪з┘Д╪к┘И╪▓┘К╪╣ ╪з┘Д╪п┘К┘Ж╪з┘Е┘К┘Г┘К
        distribution = calculate_cookies_distribution(available_cookies)
        
        # ╪г┘Г╪л╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з╪│╪к╪о╪п╪з┘Е╪з┘Л
        most_used = max(COOKIES_USAGE_COUNT.items(), key=lambda x: x[1]) if COOKIES_USAGE_COUNT else ("┘Д╪з ┘К┘И╪м╪п", 0)
        
        stats = {
            'total': total_cookies,
            'available': available_cookies, 
            'blocked': blocked_cookies,
            'distribution': distribution,
            'most_used_file': os.path.basename(most_used[0]) if most_used[0] != "┘Д╪з ┘К┘И╪м╪п" else "┘Д╪з ┘К┘И╪м╪п",
            'most_used_count': most_used[1],
            'usage_distribution': dict(COOKIES_USAGE_COUNT)
        }
        
        return stats
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓: {e}")
        return {}

async def parallel_search_with_monitoring(query: str, bot_client) -> Optional[Dict]:
    """╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Е╪╣ ┘Е╪▒╪з┘В╪и╪й ╪з┘Д╪г╪п╪з╪б"""
    start_time = time.time()
    
    try:
        LOGGER(__name__).info(f"ЁЯЪА ╪и╪п╪б ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К: {query}")
        
        # ╪е┘Ж╪┤╪з╪б ┘Е┘З╪з┘Е ┘Е╪к┘И╪з╪▓┘К╪й ┘Е╪╣ ╪к╪к╪и╪╣ ╪з┘Д┘И┘В╪к
        db_task = asyncio.create_task(search_in_database_cache(query))
        cache_task = asyncio.create_task(search_in_telegram_cache(query, bot_client))
        
        # ╪к╪│╪м┘К┘Д ╪и╪п╪б ╪з┘Д┘Е┘З╪з┘Е
        db_start = time.time()
        cache_start = time.time()
        
        # ╪з┘Ж╪к╪╕╪з╪▒ ╪г┘И┘Д ┘Ж╪к┘К╪м╪й ┘Ж╪з╪м╪н╪й
        done, pending = await asyncio.wait(
            [db_task, cache_task], 
            return_when=asyncio.FIRST_COMPLETED,
            timeout=10  # ┘Е┘З┘Д╪й ╪▓┘Е┘Ж┘К╪й 10 ╪л┘И╪з┘Ж
        )
        
        # ┘Б╪н╪╡ ╪з┘Д┘Ж╪к╪з╪ж╪м
        for task in done:
            try:
                result = await task
                if result and result.get('success'):
                    elapsed = time.time() - start_time
                    
                    # ╪к╪н╪п┘К╪л ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
                    PARALLEL_SEARCH_STATS['total_searches'] += 1
                    
                    if task == db_task:
                        LOGGER(__name__).info(f"ЁЯПЖ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Б╪з╪▓╪к! ({elapsed:.2f}s)")
                        result['search_source'] = 'database'
                        result['search_time'] = elapsed
                        
                        # ╪к╪н╪п┘К╪л ╪е╪н╪╡╪з╪ж┘К╪з╪к ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
                        PARALLEL_SEARCH_STATS['database_wins'] += 1
                        PARALLEL_SEARCH_STATS['database_times'].append(elapsed)
                        if len(PARALLEL_SEARCH_STATS['database_times']) > 100:
                            PARALLEL_SEARCH_STATS['database_times'].pop(0)
                        PARALLEL_SEARCH_STATS['avg_database_time'] = sum(PARALLEL_SEARCH_STATS['database_times']) / len(PARALLEL_SEARCH_STATS['database_times'])
                        
                    elif task == cache_task:
                        LOGGER(__name__).info(f"ЁЯПЖ ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Б╪з╪▓! ({elapsed:.2f}s)")
                        result['search_source'] = 'smart_cache'
                        result['search_time'] = elapsed
                        
                        # ╪к╪н╪п┘К╪л ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К
                        PARALLEL_SEARCH_STATS['smart_cache_wins'] += 1
                        PARALLEL_SEARCH_STATS['smart_cache_times'].append(elapsed)
                        if len(PARALLEL_SEARCH_STATS['smart_cache_times']) > 100:
                            PARALLEL_SEARCH_STATS['smart_cache_times'].pop(0)
                        PARALLEL_SEARCH_STATS['avg_smart_cache_time'] = sum(PARALLEL_SEARCH_STATS['smart_cache_times']) / len(PARALLEL_SEARCH_STATS['smart_cache_times'])
                    
                    # ╪е┘Д╪║╪з╪б ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е╪к╪и┘В┘К╪й
                    for pending_task in pending:
                        pending_task.cancel()
                    
                    return result
                    
            except Exception as e:
                LOGGER(__name__).warning(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Е┘З┘Е╪й ╪з┘Д╪и╪н╪л: {e}")
        
        # ╪е╪░╪з ┘Д┘Е ╪к┘Ж╪м╪н ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е┘Г╪к┘Е┘Д╪й╪М ╪з┘Ж╪к╪╕╪▒ ╪з┘Д╪и╪з┘В┘К
        if pending:
            LOGGER(__name__).info("тП│ ╪з┘Ж╪к╪╕╪з╪▒ ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е╪к╪и┘В┘К╪й...")
            try:
                remaining_results = await asyncio.gather(*pending, return_exceptions=True)
                
                for i, result in enumerate(remaining_results):
                    if isinstance(result, Exception):
                        continue
                        
                    if result and result.get('success'):
                        elapsed = time.time() - start_time
                        remaining_tasks = list(pending)
                        
                        if remaining_tasks[i] == db_task:
                            LOGGER(__name__).info(f"тЬЕ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Ж╪м╪н╪к (┘Е╪к╪г╪о╪▒╪й: {elapsed:.2f}s)")
                            result['search_source'] = 'database'
                        elif remaining_tasks[i] == cache_task:
                            LOGGER(__name__).info(f"тЬЕ ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Ж╪м╪н (┘Е╪к╪г╪о╪▒: {elapsed:.2f}s)")
                            result['search_source'] = 'smart_cache'
                        
                        result['search_time'] = elapsed
                        return result
                        
            except asyncio.TimeoutError:
                LOGGER(__name__).warning("тП░ ╪з┘Ж╪к┘З╪к ┘Е┘З┘Д╪й ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К")
        
        total_time = time.time() - start_time
        LOGGER(__name__).info(f"тЭМ ┘Б╪┤┘Д ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ({total_time:.2f}s)")
        return None
        
    except Exception as e:
        total_time = time.time() - start_time
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ({total_time:.2f}s): {e}")
        return None

# === ┘Ж╪╕╪з┘Е ╪з┘Д╪и╪н╪л ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д╪░┘Г┘К╪й ===

async def search_in_database_cache(query: str) -> Optional[Dict]:
    """╪з┘Д╪и╪н╪л ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д╪░┘Г┘К╪й (╪з┘Д┘Г╪з╪┤)"""
    try:
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Ж╪╡ ┘Д┘Д╪и╪н╪л
        normalized_query = normalize_search_text(query)
        search_keywords = normalized_query.split()
        
        LOGGER(__name__).info(f"ЁЯЧДя╕П ╪з┘Д╪и╪н╪л ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: '{normalized_query}' (┘Г┘Д┘Е╪з╪к: {search_keywords})")
        
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        
        # ╪з┘Д╪и╪н╪л ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪н╪│┘Ж ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪з╪о╪к┘Д╪з┘Б╪з╪к ┘Б┘К ╪з┘Д┘Г╪к╪з╪и╪й ╪з┘Д╪╣╪▒╪и┘К╪й
        search_conditions = []
        search_params = []
        
        # ╪е╪╢╪з┘Б╪й ╪з┘Д╪и╪н╪л ╪з┘Д╪п┘В┘К┘В ╪г┘И┘Д╪з┘Л
        search_conditions.append("(title_normalized LIKE ? OR artist_normalized LIKE ?)")
        search_params.extend([f"%{normalized_query}%", f"%{normalized_query}%"])
        
        # ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪з╪о╪к┘Д╪з┘Б╪з╪к ╪з┘Д╪┤╪з╪ж╪╣╪й ┘Б┘К ╪з┘Д┘Г╪к╪з╪и╪й ╪з┘Д╪╣╪▒╪и┘К╪й
        arabic_variants = {
            '┘И╪н╪┤╪к┘Ж┘К': ['┘И╪н╪┤╪к┘Ж┘К', '┘И╪н╪┤╪к┘К┘Ж┘К', '┘И╪н╪┤┘Ж┘К', '┘И╪н╪┤╪к┘Ж┘Й'],
            '╪з╪н╪и┘Г': ['╪з╪н╪и┘Г', '╪г╪н╪и┘Г', '╪з╪н╪и┘С┘Г', '╪г╪н╪и┘С┘Г'],
            '╪н╪и┘К╪и┘К': ['╪н╪и┘К╪и┘К', '╪н╪и┘К╪и┘Й'],
            '╪╣┘Д┘К┘Г': ['╪╣┘Д┘К┘Г', '╪╣┘Д┘К┘Г┘К'],
            '╪з┘Ж╪к': ['╪з┘Ж╪к', '╪г┘Ж╪к', '╪е┘Ж╪к']
        }
        
        # ╪з┘Д╪и╪н╪л ╪и╪з┘Д┘Е╪к╪║┘К╪▒╪з╪к ╪з┘Д╪╣╪▒╪и┘К╪й
        for original_word in search_keywords:
            if len(original_word) > 2:
                variants = arabic_variants.get(original_word, [original_word])
                for variant in variants:
                    search_conditions.append("(title_normalized LIKE ? OR artist_normalized LIKE ? OR keywords_vector LIKE ?)")
                    search_params.extend([f"%{variant}%", f"%{variant}%", f"%{variant}%"])
        
        # ╪з┘Д╪и╪н╪л ╪з┘Д╪╣╪з┘Е ╪и╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Е┘Б╪▒╪п╪й (╪з╪н╪к┘К╪з╪╖┘К)
        for keyword in search_keywords:
            if len(keyword) > 2:
                search_conditions.append("(title_normalized LIKE ? OR artist_normalized LIKE ? OR keywords_vector LIKE ?)")
                search_params.extend([f"%{keyword}%", f"%{keyword}%", f"%{keyword}%"])
        
        # ╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д╪и╪н╪л ┘Е╪╣ ╪к╪▒╪к┘К╪и ╪н╪│╪и ╪з┘Д╪┤╪╣╪и┘К╪й ┘И╪в╪о╪▒ ┘И╪╡┘И┘Д
        query_sql = f"""
        SELECT message_id, file_id, file_unique_id, original_title, original_artist, 
               duration, file_size, access_count, last_accessed, popularity_rank,
               title_normalized, artist_normalized
        FROM channel_index 
        WHERE ({' OR '.join(search_conditions)})
        ORDER BY popularity_rank DESC, access_count DESC, last_accessed DESC
        LIMIT 5
        """
        
        cursor.execute(query_sql, search_params)
        results = cursor.fetchall()
        
        LOGGER(__name__).info(f"ЁЯФН ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й {len(results)} ┘Ж╪к┘К╪м╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
        
        if results:
            # ╪з╪о╪к┘К╪з╪▒ ╪г┘Б╪╢┘Д ┘Ж╪к┘К╪м╪й
            best_result = results[0]
            
            # ╪к╪н╪п┘К╪л ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘И╪╡┘И┘Д
            cursor.execute("""
                UPDATE channel_index 
                SET access_count = access_count + 1, 
                    last_accessed = CURRENT_TIMESTAMP,
                    popularity_rank = popularity_rank + 0.1
                WHERE message_id = ?
            """, (best_result[0],))
            
            conn.commit()
            conn.close()
            
            # ╪н╪│╪з╪и ┘Ж╪│╪и╪й ╪з┘Д╪к╪╖╪з╪и┘В
            title_words = set(best_result[10].split())  # title_normalized
            artist_words = set(best_result[11].split())  # artist_normalized
            query_words = set(search_keywords)
            
            all_content_words = title_words | artist_words
            match_ratio = len(query_words & all_content_words) / len(query_words) if query_words else 0
            
            # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪з┘Д╪н╪п ╪з┘Д╪г╪п┘Ж┘Й ┘Д┘Д╪к╪╖╪з╪и┘В (80% ╪╣┘Д┘Й ╪з┘Д╪г┘В┘Д)
            MIN_MATCH_RATIO = 0.8
            if match_ratio < MIN_MATCH_RATIO:
                LOGGER(__name__).info(f"тЭМ ┘Ж╪│╪и╪й ╪з┘Д╪к╪╖╪з╪и┘В ┘Е┘Ж╪о┘Б╪╢╪й ╪м╪п╪з┘Л: {match_ratio:.1%} (╪з┘Д╪н╪п ╪з┘Д╪г╪п┘Ж┘Й: {MIN_MATCH_RATIO:.1%})")
                conn.close()
                return None
            
            LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Е╪╖╪з╪и┘В╪й ┘В┘И┘К╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {match_ratio:.1%}")
            
            return {
                'success': True,
                'cached': True,
                'from_database': True,
                'message_id': best_result[0],
                'file_id': best_result[1],
                'file_unique_id': best_result[2],
                'title': best_result[3],  # original_title
                'uploader': best_result[4],  # original_artist
                'duration': best_result[5],
                'file_size': best_result[6],
                'access_count': best_result[7] + 1,
                'match_ratio': match_ratio
            }
        
        conn.close()
        LOGGER(__name__).info("тЭМ ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Е╪╖╪з╪и┘В╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {e}")
        return None

async def send_cached_from_database(event, status_msg, db_result: Dict, bot_client):
    """╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪и╪з╪│╪к╪о╪п╪з┘Е file_id"""
    try:
        import config
        
        LOGGER(__name__).info(f"ЁЯУд ┘Е╪н╪з┘И┘Д╪й ╪е╪▒╪│╪з┘Д ┘Е┘Ж ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {db_result.get('title', 'Unknown')}")
        await status_msg.edit("ЁЯУд **╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К...**")
        
        # ╪к╪н╪╢┘К╪▒ ╪з┘Д╪к╪│┘Е┘К╪й ╪з┘Д╪к┘И╪╢┘К╪н┘К╪й
        duration = db_result.get('duration', 0)
        duration_str = f"{duration//60}:{duration%60:02d}" if duration > 0 else "╪║┘К╪▒ ┘Е╪╣╪▒┘И┘Б"
        
        user_caption = f"тЬж @{config.BOT_USERNAME}"
        
        # ┘Е╪н╪з┘И┘Д╪й ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ╪е╪░╪з ┘Г╪з┘Ж╪к ┘Е╪к╪з╪н╪й
        thumb_path = None
        try:
            title = db_result.get('title', 'Unknown')
            # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
            if 'message_id' in db_result and bot_client:
                try:
                    if hasattr(config, 'CACHE_CHANNEL_ID') and config.CACHE_CHANNEL_ID:
                        # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪▒╪│╪з┘Д╪й ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Д┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                        channel_msg = await bot_client.get_messages(config.CACHE_CHANNEL_ID, ids=db_result['message_id'])
                        if channel_msg and channel_msg.media and hasattr(channel_msg.media, 'document'):
                            # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Е┘Ж ╪з┘Д┘Е┘Д┘Б
                            if hasattr(channel_msg.media.document, 'thumbs') and channel_msg.media.document.thumbs:
                                thumb_path = channel_msg.media.document.thumbs[0]
                                LOGGER(__name__).info(f"ЁЯУ╕ ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж")
                except Exception as thumb_error:
                    LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {thumb_error}")
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {e}")
        
        LOGGER(__name__).info(f"ЁЯУЛ ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д╪е╪▒╪│╪з┘Д: file_id={db_result['file_id'][:20]}..., duration={duration}")
        
        # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Г╪▒╪п ╪╣┘Д┘Й ╪▒╪│╪з┘Д╪й ╪з┘Д┘Е╪│╪к╪о╪п┘Е
        sent_message = await event.reply(
            user_caption,
            file=db_result['file_id'],
            thumb=thumb_path,
            attributes=[
                DocumentAttributeAudio(
                    duration=duration,
                    title=db_result.get('title', 'Unknown')[:60],
                    performer=db_result.get('uploader', 'Unknown')[:40]
                )
            ]
        )
        
        await status_msg.delete()
        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Г╪▒╪п ╪и┘Ж╪м╪з╪н: {sent_message.id}")
        return True
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {e}")
        # ╪е╪▓╪з┘Д╪й ╪з┘Д╪▒╪│╪з┘Д╪й ╪з┘Д┘Е╪▓╪╣╪м╪й - ╪з┘Д╪з┘Ж╪к┘В╪з┘Д ┘Е╪и╪з╪┤╪▒╪й ┘Д┘Д╪к╪н┘Е┘К┘Д
        return False

async def send_cached_from_telegram(event, status_msg, cache_result: Dict, bot_client):
    """╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К (┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж)"""
    try:
        import config
        
        LOGGER(__name__).info(f"ЁЯУд ┘Е╪н╪з┘И┘Д╪й ╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К: {cache_result.get('title', 'Unknown')}")
        await status_msg.edit("ЁЯУд **╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К...**")
        
        # ╪к╪н╪╢┘К╪▒ ╪з┘Д╪к╪│┘Е┘К╪й ╪з┘Д╪к┘И╪╢┘К╪н┘К╪й
        duration = cache_result.get('duration', 0)
        user_caption = f"тЬж @{config.BOT_USERNAME}"
        
        # ┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
        thumb_path = None
        try:
            if 'message_id' in cache_result and bot_client:
                try:
                    if hasattr(config, 'CACHE_CHANNEL_ID') and config.CACHE_CHANNEL_ID:
                        # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪▒╪│╪з┘Д╪й ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Д┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                        channel_msg = await bot_client.get_messages(config.CACHE_CHANNEL_ID, ids=cache_result['message_id'])
                        if channel_msg and channel_msg.media and hasattr(channel_msg.media, 'document'):
                            # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Е┘Ж ╪з┘Д┘Е┘Д┘Б
                            if hasattr(channel_msg.media.document, 'thumbs') and channel_msg.media.document.thumbs:
                                thumb_path = channel_msg.media.document.thumbs[0]
                                LOGGER(__name__).info(f"ЁЯУ╕ ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж")
                except Exception as thumb_error:
                    LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {thumb_error}")
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {e}")
        
        LOGGER(__name__).info(f"ЁЯУЛ ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д╪е╪▒╪│╪з┘Д: file_id={cache_result['file_id'][:20]}..., duration={duration}")
        
        # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Г╪▒╪п ╪╣┘Д┘Й ╪▒╪│╪з┘Д╪й ╪з┘Д┘Е╪│╪к╪о╪п┘Е
        sent_message = await event.reply(
            user_caption,
            file=cache_result['file_id'],
            thumb=thumb_path,
            attributes=[
                DocumentAttributeAudio(
                    duration=duration,
                    title=cache_result.get('title', 'Unknown')[:60],
                    performer=cache_result.get('uploader', 'Unknown')[:40]
                )
            ]
        )
        
        await status_msg.delete()
        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Г╪▒╪п ╪и┘Ж╪м╪з╪н: {sent_message.id}")
        return True
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К: {e}")
        # ╪е╪▓╪з┘Д╪й ╪з┘Д╪▒╪│╪з┘Д╪й ╪з┘Д┘Е╪▓╪╣╪м╪й - ╪з┘Д╪з┘Ж╪к┘В╪з┘Д ┘Е╪и╪з╪┤╪▒╪й ┘Д┘Д╪к╪н┘Е┘К┘Д
        return False

async def save_to_database_cache(file_id: str, file_unique_id: str, message_id: int, result: Dict, query: str) -> bool:
    """╪н┘Б╪╕ ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Е┘Д┘Б ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д╪░┘Г┘К╪й"""
    try:
        # ╪к┘Ж╪╕┘К┘Б ┘И╪к╪╖╪и┘К╪╣ ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        title = result.get('title', 'Unknown')
        artist = result.get('uploader', 'Unknown')
        duration = result.get('duration', 0)
        file_size = result.get('file_size', 0)
        
        title_normalized = normalize_search_text(title)
        artist_normalized = normalize_search_text(artist)
        
        # ╪е┘Ж╪┤╪з╪б vector ╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Е┘Б╪к╪з╪н┘К╪й
        keywords_vector = f"{title_normalized} {artist_normalized} {normalize_search_text(query)}"
        
        # ╪е┘Ж╪┤╪з╪б ┘З╪з╪┤ ╪з┘Д╪и╪н╪л
        search_hash = hashlib.md5((title_normalized + artist_normalized).encode()).hexdigest()
        
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        
        # ╪е╪п╪о╪з┘Д ╪з┘Д╪и┘К╪з┘Ж╪з╪к (╪г┘И ╪к╪н╪п┘К╪л┘З╪з ╪е╪░╪з ┘Г╪з┘Ж╪к ┘Е┘И╪м┘И╪п╪й)
        cursor.execute("""
            INSERT OR REPLACE INTO channel_index 
            (message_id, file_id, file_unique_id, search_hash, title_normalized, 
             artist_normalized, keywords_vector, original_title, original_artist, 
             duration, file_size, access_count, popularity_rank)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 1, 1.0)
        """, (
            message_id, file_id, file_unique_id, search_hash,
            title_normalized, artist_normalized, keywords_vector,
            title, artist, duration, file_size
        ))
        
        conn.commit()
        conn.close()
        
        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪н┘Б╪╕ ╪з┘Д┘Е┘Д┘Б ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {title[:30]}")
        return True
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {e}")
        return False

# === ┘Ж╪╕╪з┘Е ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к┘К┘Д┘К╪м╪▒╪з┘Е ===

async def search_in_telegram_cache(query: str, bot_client) -> Optional[Dict]:
    """╪з┘Д╪и╪н╪л ╪з┘Д╪░┘Г┘К ╪з┘Д╪о╪з╪▒┘В ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Е╪╣ ┘Б┘З╪▒╪│╪й ┘Е╪к┘В╪п┘Е╪й"""
    try:
        import config
        
        if not hasattr(config, 'CACHE_CHANNEL_ID') or not config.CACHE_CHANNEL_ID:
            LOGGER(__name__).warning("тЭМ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪║┘К╪▒ ┘Е╪н╪п╪п╪й")
            return None
        
        cache_channel = config.CACHE_CHANNEL_ID
        LOGGER(__name__).info(f"ЁЯФН ╪з┘Д╪и╪н╪л ╪з┘Д╪░┘Г┘К ╪з┘Д╪о╪з╪▒┘В ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж: {cache_channel}")
        
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Ж╪╡ ┘Д┘Д╪и╪н╪л
        normalized_query = normalize_search_text(query)
        search_keywords = normalized_query.split()
        
        # ╪з┘Д╪о╪╖┘И╪й 1: ╪з┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣ ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪г┘И┘Д╪з┘Л (╪г╪│╪▒╪╣)
        try:
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            
            # ╪и╪н╪л ┘Е╪к┘В╪п┘Е ╪и╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Е┘Б╪к╪з╪н┘К╪й ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪з╪о╪к┘Д╪з┘Б╪з╪к ╪з┘Д╪╣╪▒╪и┘К╪й
            search_conditions = []
            search_params = []
            
            # ╪е╪╢╪з┘Б╪й ╪з┘Д╪и╪н╪л ╪з┘Д╪п┘В┘К┘В ╪г┘И┘Д╪з┘Л
            search_conditions.append("(title_normalized LIKE ? OR artist_normalized LIKE ?)")
            search_params.extend([f"%{normalized_query}%", f"%{normalized_query}%"])
            
            # ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪з╪о╪к┘Д╪з┘Б╪з╪к ╪з┘Д╪┤╪з╪ж╪╣╪й ┘Б┘К ╪з┘Д┘Г╪к╪з╪и╪й ╪з┘Д╪╣╪▒╪и┘К╪й
            arabic_variants = {
                '┘И╪н╪┤╪к┘Ж┘К': ['┘И╪н╪┤╪к┘Ж┘К', '┘И╪н╪┤╪к┘К┘Ж┘К', '┘И╪н╪┤┘Ж┘К', '┘И╪н╪┤╪к┘Ж┘Й'],
                '╪з╪н╪и┘Г': ['╪з╪н╪и┘Г', '╪г╪н╪и┘Г', '╪з╪н╪и┘С┘Г', '╪г╪н╪и┘С┘Г'],
                '╪н╪и┘К╪и┘К': ['╪н╪и┘К╪и┘К', '╪н╪и┘К╪и┘Й'],
                '╪╣┘Д┘К┘Г': ['╪╣┘Д┘К┘Г', '╪╣┘Д┘К┘Г┘К'],
                '╪з┘Ж╪к': ['╪з┘Ж╪к', '╪г┘Ж╪к', '╪е┘Ж╪к']
            }
            
            # ╪з┘Д╪и╪н╪л ╪и╪з┘Д┘Е╪к╪║┘К╪▒╪з╪к ╪з┘Д╪╣╪▒╪и┘К╪й
            for original_word in search_keywords:
                if len(original_word) > 2:
                    variants = arabic_variants.get(original_word, [original_word])
                    for variant in variants:
                        search_conditions.append("(title_normalized LIKE ? OR artist_normalized LIKE ? OR keywords_vector LIKE ?)")
                        search_params.extend([f"%{variant}%", f"%{variant}%", f"%{variant}%"])
            
            # ╪з╪│╪к╪╣┘Д╪з┘Е ┘Е╪н╪│┘Ж ┘Е╪╣ ╪к╪▒╪к┘К╪и ╪░┘Г┘К
            query_sql = f"""
            SELECT message_id, file_id, file_unique_id, original_title, original_artist, 
                   duration, file_size, access_count, last_accessed, popularity_rank,
                   title_normalized, artist_normalized, keywords_vector
            FROM channel_index 
            WHERE ({' OR '.join(search_conditions)})
            ORDER BY 
                -- ╪г┘И┘Д┘И┘К╪й ┘Д┘Д┘Е╪╖╪з╪и┘В╪й ╪з┘Д┘Г╪з┘Е┘Д╪й
                CASE WHEN title_normalized LIKE '%{normalized_query}%' THEN 1 ELSE 2 END,
                -- ╪л┘Е ╪н╪│╪и ╪з┘Д╪┤╪╣╪и┘К╪й
                popularity_rank DESC, 
                access_count DESC, 
                last_accessed DESC
            LIMIT 10
            """
            
            cursor.execute(query_sql, search_params)
            db_results = cursor.fetchall()
            
            if db_results:
                # ╪н╪│╪з╪и ┘Ж╪│╪и╪й ╪з┘Д╪к╪╖╪з╪и┘В ┘Д┘Г┘Д ┘Ж╪к┘К╪м╪й
                best_match = None
                best_score = 0
                
                for result in db_results:
                    # ╪н╪│╪з╪и ╪п╪▒╪м╪й ╪з┘Д╪к╪╖╪з╪и┘В ╪з┘Д┘Е╪к┘В╪п┘Е╪й
                    title_words = set(result[10].split())  # title_normalized
                    artist_words = set(result[11].split())  # artist_normalized
                    keywords_words = set(result[12].split())  # keywords_vector
                    query_words = set(search_keywords)
                    
                    # ╪н╪│╪з╪и ╪з┘Д╪к╪╖╪з╪и┘В ╪з┘Д┘Е╪к╪╣╪п╪п ╪з┘Д┘Е╪│╪к┘И┘К╪з╪к
                    title_match = len(query_words & title_words) / len(query_words) if query_words else 0
                    artist_match = len(query_words & artist_words) / len(query_words) if query_words else 0
                    keywords_match = len(query_words & keywords_words) / len(query_words) if query_words else 0
                    
                    # ╪п╪▒╪м╪й ┘Е╪▒┘Г╪и╪й ┘Е╪╣ ╪г┘И╪▓╪з┘Ж
                    composite_score = (
                        title_match * 0.5 +      # ┘И╪▓┘Ж ╪з┘Д╪╣┘Ж┘И╪з┘Ж 50%
                        artist_match * 0.3 +     # ┘И╪▓┘Ж ╪з┘Д┘Б┘Ж╪з┘Ж 30%
                        keywords_match * 0.2     # ┘И╪▓┘Ж ╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Е┘Б╪к╪з╪н┘К╪й 20%
                    )
                    
                    # ╪е╪╢╪з┘Б╪й ╪и┘И┘Ж╪╡ ┘Д┘Д╪┤╪╣╪и┘К╪й
                    popularity_bonus = min(result[9] / 10, 0.1)  # ╪г┘В╪╡┘Й ╪и┘И┘Ж╪╡ 10%
                    composite_score += popularity_bonus
                    
                    if composite_score > best_score and composite_score > 0.8:  # ╪н╪п ╪г╪п┘Ж┘Й 80%
                        best_score = composite_score
                        best_match = result
                
                if best_match:
                    # ╪к╪н╪п┘К╪л ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘И╪╡┘И┘Д
                    cursor.execute("""
                        UPDATE channel_index 
                        SET access_count = access_count + 1, 
                            last_accessed = CURRENT_TIMESTAMP,
                            popularity_rank = popularity_rank + 0.1
                        WHERE message_id = ?
                    """, (best_match[0],))
                    conn.commit()
                    
                    LOGGER(__name__).info(f"тЬЕ ┘Е╪╖╪з╪и┘В╪й ┘В┘И┘К╪й ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К: {best_score:.1%}")
                    
                    conn.close()
                    return {
                        'success': True,
                        'cached': True,
                        'from_database': True,
                        'message_id': best_match[0],
                        'file_id': best_match[1],
                        'file_unique_id': best_match[2],
                        'title': best_match[3],
                        'uploader': best_match[4],
                        'duration': best_match[5],
                        'file_size': best_match[6],
                        'access_count': best_match[7] + 1,
                        'match_ratio': best_score
                    }
            
            conn.close()
            
            # ╪е╪░╪з ┘Д┘Е ┘Ж╪м╪п ┘Е╪╖╪з╪и┘В╪й ┘В┘И┘К╪й
            if not best_match:
                LOGGER(__name__).info("тЭМ ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Е╪╖╪з╪и┘В╪й ┘В┘И┘К╪й ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К (╪з┘Д╪н╪п ╪з┘Д╪г╪п┘Ж┘Й: 80%)")
            
        except Exception as db_error:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {db_error}")
        
        # ╪з┘Д╪о╪╖┘И╪й 2: ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘В╪п┘Е ┘Б┘К ╪▒╪│╪з╪ж┘Д ╪з┘Д┘В┘Ж╪з╪й ┘Е╪╣╪╖┘Д (┘В┘К┘И╪п API ┘Д┘Д╪и┘И╪к╪з╪к)
        LOGGER(__name__).info("тЪая╕П ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Е╪╣╪╖┘Д ┘Е╪д┘В╪к╪з┘Л (┘В┘К┘И╪п API ┘Д┘Д╪и┘И╪к╪з╪к)")
        return None  # ╪к╪╣╪╖┘К┘Д ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К
        
        # ╪▓┘К╪з╪п╪й ╪╣╪п╪п ╪з┘Д╪▒╪│╪з╪ж┘Д ╪з┘Д┘Е┘Б╪н┘И╪╡╪й ╪е┘Д┘Й 500 ╪▒╪│╪з┘Д╪й ┘Е╪╣ ╪к╪н╪│┘К┘Ж ╪з┘Д╪г╪п╪з╪б
        search_limit = 500
        batch_size = 50  # ┘Е╪╣╪з┘Д╪м╪й ╪╣┘Д┘Й ╪п┘Б╪╣╪з╪к ┘Д╪к╪н╪│┘К┘Ж ╪з┘Д╪г╪п╪з╪б
        
        best_matches = []
        processed_count = 0
        
        # ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪▒╪│╪з╪ж┘Д ╪╣┘Д┘Й ╪п┘Б╪╣╪з╪к
        async for message in bot_client.iter_messages(cache_channel, limit=search_limit):
            if not (message.text and message.file):
                continue
                
            processed_count += 1
            
            # ╪к╪н┘Д┘К┘Д ╪з┘Д┘Ж╪╡ ╪з┘Д┘Е╪к┘В╪п┘Е
            message_text = message.text.lower()
            
            # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е┘Ж ╪з┘Д┘Ж╪╡
            title = extract_title_from_cache_text(message.text)
            uploader = extract_uploader_from_cache_text(message.text)
            duration = extract_duration_from_cache_text(message.text)
            
            # ╪к╪╖╪и┘К╪╣ ╪з┘Д┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Е╪│╪к╪о╪▒╪м╪й
            title_normalized = normalize_search_text(title)
            uploader_normalized = normalize_search_text(uploader)
            
            # ╪н╪│╪з╪и ╪з┘Д╪к╪╖╪з╪и┘В ╪з┘Д┘Е╪к┘В╪п┘Е
            title_words = set(title_normalized.split())
            uploader_words = set(uploader_normalized.split())
            message_words = set(normalize_search_text(message_text).split())
            query_words = set(search_keywords)
            
            # ╪н╪│╪з╪и ╪п╪▒╪м╪з╪к ╪з┘Д╪к╪╖╪з╪и┘В
            title_match = len(query_words & title_words) / len(query_words) if query_words else 0
            uploader_match = len(query_words & uploader_words) / len(query_words) if query_words else 0
            message_match = len(query_words & message_words) / len(query_words) if query_words else 0
            
            # ╪п╪▒╪м╪й ┘Е╪▒┘Г╪и╪й ┘Е╪н╪│┘Ж╪й
            composite_score = (
                title_match * 0.4 +        # ┘И╪▓┘Ж ╪з┘Д╪╣┘Ж┘И╪з┘Ж 40%
                uploader_match * 0.3 +     # ┘И╪▓┘Ж ╪з┘Д┘Б┘Ж╪з┘Ж 30%
                message_match * 0.3        # ┘И╪▓┘Ж ╪з┘Д┘Ж╪╡ ╪з┘Д┘Г╪з┘Е┘Д 30%
            )
            
            # ╪е╪╢╪з┘Б╪й ╪и┘И┘Ж╪╡ ┘Д┘Д╪▒╪│╪з╪ж┘Д ╪з┘Д╪н╪п┘К╪л╪й
            age_bonus = min((search_limit - processed_count) / search_limit * 0.1, 0.1)
            composite_score += age_bonus
            
            if composite_score > 0.5:  # ╪н╪п ╪г╪п┘Ж┘Й 50% ┘Д┘Д╪к╪╖╪з╪и┘В
                best_matches.append({
                    'score': composite_score,
                    'message': message,
                    'title': title,
                    'uploader': uploader,
                    'duration': duration,
                    'message_id': message.id,
                    'file_id': message.file.id
                })
            
            # ┘Е╪╣╪з┘Д╪м╪й ╪╣┘Д┘Й ╪п┘Б╪╣╪з╪к ┘Д╪к╪н╪│┘К┘Ж ╪з┘Д╪г╪п╪з╪б
            if processed_count % batch_size == 0:
                # ╪к╪▒╪к┘К╪и ╪г┘Б╪╢┘Д ╪з┘Д┘Ж╪к╪з╪ж╪м ╪н╪к┘Й ╪з┘Д╪в┘Ж
                best_matches = sorted(best_matches, key=lambda x: x['score'], reverse=True)[:5]
                LOGGER(__name__).info(f"ЁЯФД ╪к┘Е ┘Е╪╣╪з┘Д╪м╪й {processed_count} ╪▒╪│╪з┘Д╪й╪М ╪г┘Б╪╢┘Д ╪к╪╖╪з╪и┘В: {best_matches[0]['score']:.1%}" if best_matches else f"ЁЯФД ╪к┘Е ┘Е╪╣╪з┘Д╪м╪й {processed_count} ╪▒╪│╪з┘Д╪й")
        
        # ╪з╪о╪к┘К╪з╪▒ ╪г┘Б╪╢┘Д ┘Ж╪к┘К╪м╪й
        if best_matches:
            best_matches = sorted(best_matches, key=lambda x: x['score'], reverse=True)
            best_result = best_matches[0]
            
            LOGGER(__name__).info(f"тЬЕ ╪г┘Б╪╢┘Д ┘Е╪╖╪з╪и┘В╪й ┘Б┘К ╪з┘Д┘В┘Ж╪з╪й: {best_result['score']:.1%} ┘Е┘Ж {processed_count} ╪▒╪│╪з┘Д╪й")
            
            # ╪н┘Б╪╕ ╪з┘Д┘Ж╪к┘К╪м╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Д┘Д┘Е╪▒╪з╪к ╪з┘Д┘В╪з╪п┘Е╪й
            try:
                file_info = {
                    'title': best_result['title'],
                    'uploader': best_result['uploader'],
                    'duration': best_result['duration'],
                    'file_size': best_result['message'].file.size if best_result['message'].file.size else 0
                }
                
                await save_to_database_cache(
                    best_result['file_id'],
                    best_result['message'].file.unique_id,
                    best_result['message_id'],
                    file_info,
                    query
                )
                LOGGER(__name__).info("ЁЯТ╛ ╪к┘Е ╪н┘Б╪╕ ╪з┘Д┘Ж╪к┘К╪м╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Д┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣ ┘Е╪│╪к┘В╪и┘Д╪з┘Л")
                
            except Exception as save_error:
                LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ╪з┘Д┘Ж╪к┘К╪м╪й: {save_error}")
            
            return {
                'success': True,
                'cached': True,
                'message_id': best_result['message_id'],
                'file_id': best_result['file_id'],
                'title': best_result['title'],
                'duration': best_result['duration'],
                'uploader': best_result['uploader'],
                'match_ratio': best_result['score'],
                'original_message': best_result['message'],
                'processed_messages': processed_count
            }
        
        LOGGER(__name__).info(f"тЭМ ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Е╪╖╪з╪и┘В╪й ┘Е┘Ж╪з╪│╪и╪й ┘Е┘Ж {processed_count} ╪▒╪│╪з┘Д╪й")
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д╪░┘Г┘К ╪и╪з┘Д╪к╪о╪▓┘К┘Ж: {e}")
        return None

# ╪к┘Е ╪п┘Е╪м ┘З╪░┘З ╪з┘Д╪п╪з┘Д╪й ┘Е╪╣ normalize_arabic_text
normalize_search_text = normalize_arabic_text  # ╪к┘И╪н┘К╪п ╪з┘Д╪п┘И╪з┘Д

def extract_title_from_cache_text(text: str) -> str:
    """╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪╣┘Ж┘И╪з┘Ж ┘Е┘Ж ┘Ж╪╡ ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    try:
        import re
        
        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д╪╣┘Ж┘И╪з┘Ж ╪и╪╣╪п ЁЯО╡
        title_match = re.search(r'ЁЯО╡\s*\*\*(.+?)\*\*', text)
        if title_match:
            return title_match.group(1).strip()
        
        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д╪╣┘Ж┘И╪з┘Ж ╪и╪╣╪п "╪з┘Д╪╣┘Ж┘И╪з┘Ж:"
        title_match = re.search(r'╪з┘Д╪╣┘Ж┘И╪з┘Ж:\s*(.+?)(?:\n|$)', text)
        if title_match:
            return title_match.group(1).strip()
        
        return "Unknown Title"
    except:
        return "Unknown Title"

def extract_duration_from_cache_text(text: str) -> int:
    """╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д┘Е╪п╪й ┘Е┘Ж ┘Ж╪╡ ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    try:
        import re
        
        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е╪п╪й ╪и╪╡┘К╪║╪й mm:ss
        duration_match = re.search(r'тП▒я╕П\s*\*\*(\d+):(\d+)\*\*', text)
        if duration_match:
            minutes = int(duration_match.group(1))
            seconds = int(duration_match.group(2))
            return minutes * 60 + seconds
        
        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е╪п╪й ╪и╪з┘Д╪л┘И╪з┘Ж┘К
        duration_match = re.search(r'╪з┘Д┘Е╪п╪й:\s*(\d+)', text)
        if duration_match:
            return int(duration_match.group(1))
        
        return 0
    except:
        return 0

def extract_uploader_from_cache_text(text: str) -> str:
    """╪з╪│╪к╪о╪▒╪з╪м ╪з╪│┘Е ╪з┘Д╪▒╪з┘Б╪╣ ┘Е┘Ж ┘Ж╪╡ ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    try:
        import re
        
        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Б┘Ж╪з┘Ж ╪и╪╣╪п ЁЯОд
        uploader_match = re.search(r'ЁЯОд\s*\*\*(.+?)\*\*', text)
        if uploader_match:
            return uploader_match.group(1).strip()
        
        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Б┘Ж╪з┘Ж ╪и╪╣╪п "╪з┘Д┘Б┘Ж╪з┘Ж:"
        uploader_match = re.search(r'╪з┘Д┘Б┘Ж╪з┘Ж:\s*(.+?)(?:\n|$)', text)
        if uploader_match:
            return uploader_match.group(1).strip()
        
        return "Unknown Artist"
    except:
        return "Unknown Artist"

async def save_to_smart_cache(bot_client, file_path: str, result: Dict, query: str, thumb_path: str = None) -> bool:
    """╪н┘Б╪╕ ╪з┘Д┘Е┘Д┘Б ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ┘Е╪╣ ┘Б┘З╪▒╪│╪й ┘Е╪к┘В╪п┘Е╪й ┘И╪к┘Б╪╡┘К┘Д ╪┤╪з┘Е┘Д"""
    try:
        import config
        import os
        from pathlib import Path
        
        if not hasattr(config, 'CACHE_CHANNEL_ID') or not config.CACHE_CHANNEL_ID:
            LOGGER(__name__).warning("тЭМ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪║┘К╪▒ ┘Е╪н╪п╪п╪й - ╪к╪о╪╖┘К ╪з┘Д╪к╪о╪▓┘К┘Ж")
            return False
        
        cache_channel = config.CACHE_CHANNEL_ID
        
        # ╪к╪н╪╢┘К╪▒ ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е┘Б╪╡┘Д╪й
        title = result.get('title', 'Unknown')
        uploader = result.get('uploader', 'Unknown')
        duration = result.get('duration', 0)
        file_size = result.get('file_size', 0)
        source = result.get('source', 'Unknown')
        elapsed_time = result.get('elapsed', 0)
        
        # ╪к┘Ж╪│┘К┘В ╪з┘Д┘Е╪п╪й
        duration_str = f"{duration//60}:{duration%60:02d}" if duration > 0 else "╪║┘К╪▒ ┘Е╪╣╪▒┘И┘Б"
        
        # ╪к┘Ж╪│┘К┘В ╪н╪м┘Е ╪з┘Д┘Е┘Д┘Б
        if file_size > 0:
            if file_size >= 1024*1024:
                size_str = f"{file_size/(1024*1024):.1f} MB"
            else:
                size_str = f"{file_size/1024:.1f} KB"
        else:
            size_str = "╪║┘К╪▒ ┘Е╪╣╪▒┘И┘Б"
        
        # ╪е┘Ж╪┤╪з╪б ┘З╪з╪┤ ┘Е╪к┘В╪п┘Е ┘Д┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣
        title_normalized = normalize_search_text(title)
        uploader_normalized = normalize_search_text(uploader)
        query_normalized = normalize_search_text(query)
        
        # ┘З╪з╪┤ ┘Е╪▒┘Г╪и ┘Д┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣
        search_data = f"{title_normalized}|{uploader_normalized}|{query_normalized}"
        search_hash = hashlib.md5(search_data.encode()).hexdigest()[:12]
        
        # ╪е┘Ж╪┤╪з╪б ┘Г┘Д┘Е╪з╪к ┘Е┘Б╪к╪з╪н┘К╪й ╪┤╪з┘Е┘Д╪й
        all_keywords = set()
        all_keywords.update(title_normalized.split())
        all_keywords.update(uploader_normalized.split())
        all_keywords.update(query_normalized.split())
        
        # ╪е╪╢╪з┘Б╪й ┘Г┘Д┘Е╪з╪к ┘Е┘Б╪к╪з╪н┘К╪й ╪е╪╢╪з┘Б┘К╪й ╪░┘Г┘К╪й
        if '╪н╪и┘К╪и╪к┘К' in query_normalized or '╪н╪и┘К╪и┘К' in query_normalized:
            all_keywords.add('╪н╪и')
            all_keywords.add('╪▒┘И┘Е╪з┘Ж╪│┘К')
        if '╪з╪║┘Ж┘К╪й' in query_normalized or '╪г╪║┘Ж┘К╪й' in query_normalized:
            all_keywords.add('┘Е┘И╪│┘К┘В┘Й')
            all_keywords.add('╪║┘Ж╪з╪б')
        
        keywords_vector = ' '.join(sorted(all_keywords))
        
        # ╪з┘Д┘Ж╪╡ ╪з┘Д┘Е┘Б╪╡┘Д ┘И╪з┘Д╪░┘Г┘К ┘Д┘Д╪к╪о╪▓┘К┘Ж
        cache_text = f"""ЁЯО╡ **{title[:80]}**
ЁЯОд **{uploader[:50]}**
тП▒я╕П **{duration_str}** ({duration}s) | ЁЯУК **{size_str}**

ЁЯФН **╪з┘Д╪и╪н╪л ╪з┘Д╪г╪╡┘Д┘К:** `{query[:100]}`
ЁЯП╖я╕П **╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Е┘Б╪к╪з╪н┘К╪й:** `{keywords_vector[:200]}`
ЁЯФЧ **╪з┘Д┘Е╪╡╪п╪▒:** {source}
тЪб **┘И┘В╪к ╪з┘Д╪к╪н┘Е┘К┘Д:** {elapsed_time:.1f}s

ЁЯУК **┘З╪з╪┤ ╪з┘Д╪и╪н╪л:** `{search_hash}`
ЁЯУЕ **╪к╪з╪▒┘К╪о ╪з┘Д╪к╪о╪▓┘К┘Ж:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ЁЯЖФ **┘Е╪╣╪▒┘Б ╪з┘Д┘Е┘Д┘Б:** `{os.path.basename(file_path)}`

ЁЯдЦ **╪и┘И╪з╪│╪╖╪й:** ZeMusic Smart Cache System V2
ЁЯФД **┘Д┘Д╪и╪н╪л ╪з┘Д╪│╪▒┘К╪╣:** ╪з╪│╪к╪о╪п┘Е ╪г┘К ┘Е┘Ж ╪з┘Д┘Г┘Д┘Е╪з╪к ╪г╪╣┘Д╪з┘З

#╪к╪о╪▓┘К┘Ж_╪░┘Г┘К #┘Е┘И╪│┘К┘В┘Й #┘Б┘З╪▒╪│╪й_┘Е╪к┘В╪п┘Е╪й
#{title_normalized.replace(' ', '_')[:30]} #{uploader_normalized.replace(' ', '_')[:20]}
#{query_normalized.replace(' ', '_')[:30]} #┘З╪з╪┤_{search_hash}"""
        
        try:
            # ╪▒┘Б╪╣ ╪з┘Д┘Е┘Д┘Б ┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й ┘Д╪к╪н╪│┘К┘Ж ╪з┘Д╪│╪▒╪╣╪й
            import asyncio
            
            async def upload_to_storage():
                try:
                    sent_message = await bot_client.send_file(
                        cache_channel,
                        file_path,
                        caption=cache_text,
                        thumb=thumb_path,
                        attributes=[
                            DocumentAttributeAudio(
                                duration=duration,
                                title=title[:64],
                                performer=uploader[:64]
                            )
                        ],
                        supports_streaming=True,
                        force_document=False
                    )
                    return sent_message
                except Exception as e:
                    LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ╪▒┘Б╪╣ ╪з┘Д┘Е┘Д┘Б ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {e}")
                    return None
            
            # ╪к╪┤╪║┘К┘Д ╪з┘Д╪▒┘Б╪╣ ┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й
            upload_task = asyncio.create_task(upload_to_storage())
            sent_message = await upload_task
            
            if thumb_path:
                LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪▒┘Б╪╣ ╪з┘Д┘Е┘Д┘Б ┘Е╪╣ ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {title[:30]}")
            else:
                LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪▒┘Б╪╣ ╪з┘Д┘Е┘Д┘Б ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {title[:30]}")
            
            # ╪н┘Б╪╕ ┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е┘Б╪╡┘Д╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
            if sent_message and sent_message.file:
                # ╪е╪╣╪п╪з╪п ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н╪│┘Ж╪й ┘Д┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
                enhanced_info = {
                    'title': title,
                    'uploader': uploader,
                    'duration': duration,
                    'file_size': sent_message.file.size or file_size,
                    'source': source,
                    'search_hash': search_hash,
                    'keywords_vector': keywords_vector,
                    'original_query': query,
                    'upload_time': datetime.now().isoformat()
                }
                
                # ╪н┘Б╪╕ ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й ┘Д╪к╪н╪│┘К┘Ж ╪з┘Д╪│╪▒╪╣╪й
                async def save_to_db():
                    try:
                        success = await save_to_database_cache_enhanced(
                            sent_message.file.id,
                            getattr(sent_message.file, 'unique_id', None),
                            sent_message.id,
                            enhanced_info,
                            query
                        )
                        if success:
                            LOGGER(__name__).info(f"ЁЯТ╛ ╪к┘Е ╪н┘Б╪╕ ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н╪│┘Ж╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
                        else:
                            LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ╪н┘Б╪╕ ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
                    except Exception as e:
                        LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {e}")
                
                # ╪к╪┤╪║┘К┘Д ╪з┘Д╪н┘Б╪╕ ┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й
                asyncio.create_task(save_to_db())
            
            LOGGER(__name__).info(f"ЁЯОп ╪к┘Е ╪н┘Б╪╕ ╪з┘Д┘Е┘Д┘Б ╪и┘Ж╪м╪з╪н ┘Е╪╣ ┘Б┘З╪▒╪│╪й ╪┤╪з┘Е┘Д╪й: {os.path.basename(file_path)}")
            return True
            
        except Exception as upload_error:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪▒┘Б╪╣ ╪з┘Д┘Е┘Д┘Б: {upload_error}")
            return False
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪н╪│┘Ж: {e}")
        return False

async def save_to_database_cache_enhanced(file_id: str, file_unique_id: str, message_id: int, enhanced_info: Dict, query: str) -> bool:
    """╪н┘Б╪╕ ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н╪│┘Ж╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д╪░┘Г┘К╪й"""
    try:
        # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н╪│┘Ж╪й
        title = enhanced_info.get('title', 'Unknown')
        artist = enhanced_info.get('uploader', 'Unknown')
        duration = enhanced_info.get('duration', 0)
        file_size = enhanced_info.get('file_size', 0)
        source = enhanced_info.get('source', 'Unknown')
        search_hash = enhanced_info.get('search_hash', '')
        keywords_vector = enhanced_info.get('keywords_vector', '')
        original_query = enhanced_info.get('original_query', query)
        
        # ╪к╪╖╪и┘К╪╣ ╪з┘Д┘Ж╪╡┘И╪╡
        title_normalized = normalize_search_text(title)
        artist_normalized = normalize_search_text(artist)
        
        # ╪е┘Ж╪┤╪з╪б ┘З╪з╪┤ ╪и╪н╪л ╪е╪╢╪з┘Б┘К
        combined_hash = hashlib.md5((title_normalized + artist_normalized + original_query).encode()).hexdigest()[:16]
        
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п ╪з┘Д╪│╪м┘Д ╪г┘И┘Д╪з┘Л
        cursor.execute("SELECT id FROM channel_index WHERE message_id = ? OR search_hash = ?", 
                      (message_id, search_hash))
        existing = cursor.fetchone()
        
        if existing:
            # ╪к╪н╪п┘К╪л ╪з┘Д╪│╪м┘Д ╪з┘Д┘Е┘И╪м┘И╪п
            cursor.execute("""
                UPDATE channel_index 
                SET file_id = ?, file_unique_id = ?, title_normalized = ?, 
                    artist_normalized = ?, keywords_vector = ?, original_title = ?, 
                    original_artist = ?, duration = ?, file_size = ?, 
                    access_count = access_count + 1, popularity_rank = popularity_rank + 0.5,
                    last_accessed = CURRENT_TIMESTAMP
                WHERE message_id = ? OR search_hash = ?
            """, (
                file_id, file_unique_id, title_normalized, artist_normalized, 
                keywords_vector, title, artist, duration, file_size, 
                message_id, search_hash
            ))
            LOGGER(__name__).info(f"ЁЯФД ╪к┘Е ╪к╪н╪п┘К╪л ╪з┘Д╪│╪м┘Д ╪з┘Д┘Е┘И╪м┘И╪п ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
        else:
            # ╪е╪п╪о╪з┘Д ╪│╪м┘Д ╪м╪п┘К╪п
            cursor.execute("""
                INSERT INTO channel_index 
                (message_id, file_id, file_unique_id, search_hash, title_normalized, 
                 artist_normalized, keywords_vector, original_title, original_artist, 
                 duration, file_size, access_count, popularity_rank, phonetic_hash, partial_matches)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 1, 1.0, ?, ?)
            """, (
                message_id, file_id, file_unique_id, search_hash,
                title_normalized, artist_normalized, keywords_vector,
                title, artist, duration, file_size, combined_hash, original_query
            ))
            LOGGER(__name__).info(f"тЮХ ╪к┘Е ╪е╪╢╪з┘Б╪й ╪│╪м┘Д ╪м╪п┘К╪п ┘Д┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
        
        conn.commit()
        conn.close()
        
        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪н┘Б╪╕ ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н╪│┘Ж╪й: {title[:30]}")
        return True
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н╪│┘Ж╪й: {e}")
        return False

async def send_cached_audio(event, status_msg, cache_result: Dict, bot_client):
    """╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪╡┘И╪к┘К ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К"""
    try:
        await status_msg.edit("ЁЯУд **╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К...**")
        
        original_message = cache_result['original_message']
        
        # ╪к╪н╪╢┘К╪▒ ╪з┘Д╪к╪│┘Е┘К╪й ╪з┘Д╪к┘И╪╢┘К╪н┘К╪й ┘Д┘Д┘Е╪│╪к╪о╪п┘Е
        duration = cache_result.get('duration', 0)
        duration_str = f"{duration//60}:{duration%60:02d}" if duration > 0 else "╪║┘К╪▒ ┘Е╪╣╪▒┘И┘Б"
        
        user_caption = f"тЬж @{config.BOT_USERNAME}"
        
        # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Д┘Д┘Е╪│╪к╪о╪п┘Е
        await event.respond(
            user_caption,
            file=original_message.file,
            attributes=[
                DocumentAttributeAudio(
                    duration=duration,
                    title=cache_result.get('title', 'Unknown')[:60],
                    performer=cache_result.get('uploader', 'Unknown')[:40]
                )
            ]
        )
        
        await status_msg.delete()
        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К")
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪о╪▓┘Ж: {e}")
        await status_msg.edit("тЭМ **╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж**")

async def try_youtube_api_download(video_id: str, title: str) -> Optional[Dict]:
    """┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪и╪з╪│╪к╪о╪п╪з┘Е YouTube Data API"""
    try:
        import config
        import requests
        
        if not hasattr(config, 'YT_API_KEYS') or not config.YT_API_KEYS:
            LOGGER(__name__).warning("тЭМ ┘Д╪з ╪к┘И╪м╪п ┘Е┘Б╪з╪к┘К╪н YouTube API")
            return None
        
        LOGGER(__name__).info("ЁЯФС ┘Е╪н╪з┘И┘Д╪й ╪з╪│╪к╪о╪п╪з┘Е YouTube Data API")
        
        for api_key in config.YT_API_KEYS:
            try:
                # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Б┘К╪п┘К┘И
                api_url = f"https://www.googleapis.com/youtube/v3/videos"
                params = {
                    'part': 'snippet,contentDetails',
                    'id': video_id,
                    'key': api_key
                }
                
                response = requests.get(api_url, params=params, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if data.get('items'):
                        video_info = data['items'][0]
                        snippet = video_info['snippet']
                        
                        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Б┘К╪п┘К┘И ┘Е┘Ж API")
                        
                        # ╪з┘Д╪в┘Ж ┘Ж╪н╪з┘И┘Д ╪к╪н┘Е┘К┘Д ╪з┘Д┘Б┘К╪п┘К┘И ╪и╪з╪│╪к╪о╪п╪з┘Е ┘Е╪╣┘Д┘И┘Е╪з╪к API
                        return await download_with_api_info(video_id, snippet, title)
                        
            except Exception as e:
                LOGGER(__name__).warning(f"тЭМ ┘Б╪┤┘Д API key: {e}")
                continue
        
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К YouTube API: {e}")
        return None

async def download_with_api_info(video_id: str, snippet: dict, fallback_title: str) -> Optional[Dict]:
    """╪к╪н┘Е┘К┘Д ╪и╪з╪│╪к╪о╪п╪з┘Е ┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е┘Ж YouTube API"""
    try:
        title = snippet.get('title', fallback_title)
        
        # ┘Е╪н╪з┘И┘Д╪й ╪к╪н┘Е┘К┘Д ╪и╪з╪│╪к╪о╪п╪з┘Е yt-dlp ┘Е╪╣ ┘Е╪╣┘Д┘И┘Е╪з╪к API
        downloads_dir = Path("downloads")
        downloads_dir.mkdir(exist_ok=True)
        
        # ╪з╪│╪к╪о╪п╪з┘Е ╪г┘Б╪╢┘Д ┘Е┘Д┘Б ┘Г┘И┘Г┘К╪▓ ┘Е╪к╪з╪н
        cookies_files = get_available_cookies()
        best_cookie = cookies_files[0] if cookies_files else None
        
        ydl_opts = {
            'format': 'bestaudio[filesize<30M]/best[filesize<30M]',  # ╪н╪п ╪г┘В╪╡┘Й ┘Д┘Д╪н╪м┘Е
            'outtmpl': str(downloads_dir / f'{video_id}_api.%(ext)s'),
            'quiet': True,
            'no_warnings': True,
            'noplaylist': True,
            'socket_timeout': 20,  # ┘И┘В╪к ┘Е╪╣┘В┘И┘Д ┘Д┘Д╪з╪│╪к┘В╪▒╪з╪▒
            'retries': 2,  # ┘Е╪н╪з┘И┘Д╪з╪к ┘Е╪╣┘В┘И┘Д╪й
            'concurrent_fragment_downloads': 2,  # ╪к╪н┘Е┘К┘Д ┘Е╪к┘И╪з╪▓┘К ┘Е╪╣╪к╪п┘Д
            'http_chunk_size': 5242880,  # 5MB chunks ┘Д┘Д╪з╪│╪к┘В╪▒╪з╪▒
            'prefer_ffmpeg': True,  # ╪з╪│╪к╪о╪п╪з┘Е ffmpeg ┘Д┘Д╪│╪▒╪╣╪й
        }
        
        if best_cookie:
            ydl_opts['cookiefile'] = best_cookie
            LOGGER(__name__).info(f"ЁЯНк ╪з╪│╪к╪о╪п╪з┘Е ┘Г┘И┘Г┘К╪▓: {os.path.basename(best_cookie)}")
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(
                f"https://www.youtube.com/watch?v={video_id}",
                download=True
            )
            
            if info:
                # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д
                for file_path in downloads_dir.glob(f"{video_id}_api.*"):
                    if file_path.suffix in ['.m4a', '.mp3', '.webm', '.mp4', '.opus']:
                        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪и┘Ж╪м╪з╪н ╪╣╪и╪▒ API")
                        return {
                            'success': True,
                            'file_path': str(file_path),
                            'title': title,
                            'duration': info.get('duration', 0),
                            'uploader': snippet.get('channelTitle', 'Unknown'),
                            'elapsed': 0
                        }
        
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е╪╣ API: {e}")
        return None

# ╪е┘Ж╪┤╪з╪б ┘Е╪п┘К╪▒ ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪╣╪з┘Д┘Е┘К
downloader = HyperSpeedDownloader()

async def simple_download(video_url: str, title: str) -> Optional[Dict]:
    """╪п╪з┘Д╪й ╪к╪н┘Е┘К┘Д ╪и╪п┘К┘Д╪й ╪и╪│┘К╪╖╪й"""
    try:
        LOGGER(__name__).info(f"ЁЯФД ╪к╪н┘Е┘К┘Д ╪и╪п┘К┘Д: {video_url}")
        
        downloads_dir = Path("downloads")
        downloads_dir.mkdir(exist_ok=True)
        
        # ╪з╪│╪к╪о╪▒╪з╪м video_id ┘Е┘Ж ╪з┘Д╪▒╪з╪и╪╖
        video_id = video_url.split('=')[-1] if '=' in video_url else 'unknown'
        
        # ┘Е╪н╪з┘И┘Д╪й 1: ╪к╪н┘Е┘К┘Д ┘Е╪и╪з╪┤╪▒ ╪и╪з╪│╪к╪о╪п╪з┘Е youtube-dl ╪и╪│┘К╪╖
        try:
            import subprocess
            import json
            
            LOGGER(__name__).info("ЁЯФД ┘Е╪н╪з┘И┘Д╪й youtube-dl ┘Е╪и╪з╪┤╪▒")
            
            # ╪з╪│╪к╪о╪п╪з┘Е youtube-dl ┘Д┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪▒╪з╪и╪╖ ┘Е╪и╪з╪┤╪▒
            cmd = ['youtube-dl', '-j', '--no-playlist', f'https://www.youtube.com/watch?v={video_id}']
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                video_data = json.loads(result.stdout)
                
                # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪▒╪з╪и╪╖ ╪╡┘И╪к┘К ┘Е╪и╪з╪┤╪▒
                formats = video_data.get('formats', [])
                audio_formats = [f for f in formats if f.get('acodec') != 'none' and f.get('vcodec') == 'none']
                
                if audio_formats:
                    # ╪з╪о╪к┘К╪з╪▒ ╪г┘Б╪╢┘Д ╪м┘И╪п╪й ╪╡┘И╪к┘К╪й
                    best_audio = sorted(audio_formats, key=lambda x: x.get('abr', 0), reverse=True)[0]
                    audio_url = best_audio['url']
                    
                    # ╪к╪н┘Е┘К┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪╡┘И╪к┘К
                    import requests
                    response = requests.get(audio_url, timeout=60, stream=True)
                    
                    if response.status_code == 200:
                        file_path = downloads_dir / f"{video_id}_direct.{best_audio.get('ext', 'm4a')}"
                        
                        with open(file_path, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                        
                        if file_path.exists() and file_path.stat().st_size > 1000:  # ╪╣┘Д┘Й ╪з┘Д╪г┘В┘Д 1KB
                            LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪и╪з╪┤╪▒ ╪и┘Ж╪м╪з╪н")
                            return {
                                'audio_path': str(file_path),
                                'title': video_data.get('title', title),
                                'duration': video_data.get('duration', 0),
                                'artist': video_data.get('uploader', 'Unknown'),
                                'source': 'Direct Download'
                            }
                            
        except Exception as e:
            LOGGER(__name__).warning(f"тЭМ ┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪и╪з╪┤╪▒: {e}")
        
        # ┘Е╪н╪з┘И┘Д╪й 2: ╪з╪│╪к╪о╪п╪з┘Е invidious ┘Г╪и╪п┘К┘Д
        try:
            import requests
            
            # ┘В╪з╪ж┘Е╪й ╪о┘И╪з╪п┘Е invidious
            invidious_instances = [
                'https://invidious.io',
                'https://invidious.snopyta.org',
                'https://yewtu.be',
                'https://invidious.kavin.rocks'
            ]
            
            for instance in invidious_instances:
                try:
                    LOGGER(__name__).info(f"ЁЯФД ┘Е╪н╪з┘И┘Д╪й {instance}")
                    
                    # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Б┘К╪п┘К┘И
                    api_url = f"{instance}/api/v1/videos/{video_id}"
                    response = requests.get(api_url, timeout=10)
                    
                    if response.status_code == 200:
                        video_data = response.json()
                        
                        # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪▒╪з╪и╪╖ ╪╡┘И╪к┘К
                        audio_formats = [f for f in video_data.get('adaptiveFormats', []) if 'audio' in f.get('type', '')]
                        
                        if audio_formats:
                            audio_url = audio_formats[0]['url']
                            
                            # ╪к╪н┘Е┘К┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪╡┘И╪к┘К
                            audio_response = requests.get(audio_url, timeout=30, stream=True)
                            
                            if audio_response.status_code == 200:
                                file_path = downloads_dir / f"{video_id}_invidious.m4a"
                                
                                with open(file_path, 'wb') as f:
                                    for chunk in audio_response.iter_content(chunk_size=8192):
                                        f.write(chunk)
                                
                                if file_path.exists():
                                    LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е┘Ж {instance}")
                                    return {
                                        'audio_path': str(file_path),
                                        'title': video_data.get('title', title),
                                        'duration': video_data.get('lengthSeconds', 0),
                                        'artist': video_data.get('author', 'Unknown'),
                                        'source': 'Invidious'
                                    }
                        break
                        
                except Exception as e:
                    LOGGER(__name__).warning(f"тЭМ ┘Б╪┤┘Д {instance}: {e}")
                    continue
                    
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К Invidious: {e}")
        
        # ╪е╪░╪з ┘Б╪┤┘Д ┘Г┘Д ╪┤┘К╪б╪М ┘Д╪з ┘Ж┘Ж╪┤╪ж ┘Е┘Д┘Б TXT
        LOGGER(__name__).error("тЭМ ┘Б╪┤┘Д ╪м┘Е┘К╪╣ ╪╖╪▒┘В ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪и╪п┘К┘Д╪й")
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪и╪п┘К┘Д: {e}")
        return None

async def send_audio_file(event, status_msg, audio_file: str, result: dict, query: str = "", bot_client=None):
    """╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪╡┘И╪к┘К ┘Д┘Д┘Е╪│╪к╪о╪п┘Е ┘И╪н┘Б╪╕┘З ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К"""
    try:
        await status_msg.edit("ЁЯУд **╪м╪з╪▒┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б...**")
        
        # ╪е╪╣╪п╪з╪п ╪з┘Д╪к╪│┘Е┘К╪й ╪з┘Д╪к┘И╪╢┘К╪н┘К╪й
        duration = result.get('duration', 0)
        duration_str = f"{duration//60}:{duration%60:02d}" if duration > 0 else "╪║┘К╪▒ ┘Е╪╣╪▒┘И┘Б"
        
        caption = f"тЬж @{config.BOT_USERNAME}"
        
        # ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ╪е╪░╪з ┘Г╪з┘Ж╪к ┘Е╪к╪з╪н╪й
        thumb_path = None
        try:
            if 'thumbnail' in result and result['thumbnail']:
                thumb_path = await download_thumbnail(
                    result['thumbnail'], 
                    result.get('title', 'Unknown'), 
                    result.get('id', None)
                )
        except Exception as thumb_error:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {thumb_error}")
        
        # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪╡┘И╪к┘К
        await event.respond(
            caption,
            file=audio_file,
            thumb=thumb_path,
            attributes=[
                DocumentAttributeAudio(
                    duration=duration,
                    title=result.get('title', 'Unknown')[:60],
                    performer=result.get('uploader', 'Unknown')[:40]
                )
            ]
        )
        
        # ╪н┘Б╪╕ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К (┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й)
        if query and bot_client:
            try:
                LOGGER(__name__).info(f"ЁЯТ╛ ╪м╪з╪▒┘К ╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж...")
                saved = await save_to_smart_cache(bot_client, audio_file, result, query, thumb_path)
                if saved:
                    LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К")
                else:
                    LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К")
            except Exception as cache_error:
                LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К: {cache_error}")
        
        await status_msg.delete()
        
        # ╪н╪░┘Б ╪з┘Д┘Е┘Д┘Б╪з╪к ╪з┘Д┘Е╪д┘В╪к╪й
        await remove_temp_files(audio_file)
        
        # ╪н╪░┘Б ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
        if thumb_path and os.path.exists(thumb_path):
            try:
                os.remove(thumb_path)
                LOGGER(__name__).debug(f"ЁЯЧСя╕П ╪к┘Е ╪н╪░┘Б ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {os.path.basename(thumb_path)}")
            except Exception as e:
                LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ╪н╪░┘Б ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {e}")
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б: {e}")

async def try_alternative_downloads(video_id: str, title: str) -> Optional[Dict]:
    """┘Е╪н╪з┘И┘Д╪й ╪╖╪▒┘В ╪к╪н┘Е┘К┘Д ╪и╪п┘К┘Д╪й"""
    try:
        # ┘Е╪н╪з┘И┘Д╪й 1: YouTube API
        api_result = await try_youtube_api_download(video_id, title)
        if api_result and api_result.get('success'):
            return api_result
        
        # ┘Е╪н╪з┘И┘Д╪й 2: ╪к╪п┘И┘К╪▒ ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д╪░┘Г┘К (╪з┘Д╪п┘Б╪╣╪й ╪з┘Д╪л╪з┘Ж┘К╪й)
        cookies_files = get_available_cookies()
        
        # ╪н╪│╪з╪и ╪з┘Д╪к┘И╪▓┘К╪╣ ╪з┘Д╪п┘К┘Ж╪з┘Е┘К┘Г┘К
        distribution = calculate_cookies_distribution(len(cookies_files))
        primary_count = distribution['primary']
        secondary_count = distribution['secondary']
        
        if secondary_count == 0:
            LOGGER(__name__).info("тЪая╕П ┘Д╪з ╪к┘И╪м╪п ┘Г┘И┘Г┘К╪▓ ╪л╪з┘Ж┘И┘К╪й - ╪к╪о╪╖┘К ┘З╪░┘З ╪з┘Д┘Е╪▒╪н┘Д╪й")
            return None
        
        start_index = primary_count
        end_index = primary_count + secondary_count
        
        LOGGER(__name__).info(f"ЁЯФД ╪з╪│╪к╪о╪п╪з┘Е {secondary_count} ┘Г┘И┘Г┘К╪▓ ╪л╪з┘Ж┘И┘К ┘Е┘Ж ╪з┘Д┘Е╪д╪┤╪▒ {start_index} ╪е┘Д┘Й {end_index}")
        
        for i, cookie_file in enumerate(cookies_files[start_index:end_index], start_index + 1):
            try:
                LOGGER(__name__).info(f"ЁЯНк ┘Е╪н╪з┘И┘Д╪й ┘Г┘И┘Г┘К╪▓ ╪и╪п┘К┘Д #{i}: {os.path.basename(cookie_file)}")
                
                downloads_dir = Path("downloads")
                ydl_opts = {
                    'format': 'bestaudio[filesize<25M]/best[filesize<25M]',
                    'outtmpl': str(downloads_dir / f'{video_id}_alt_{i}.%(ext)s'),
                    'quiet': True,
                    'no_warnings': True,
                    'noplaylist': True,
                    'cookiefile': cookie_file,
                    'socket_timeout': 18,  # ┘И┘В╪к ┘Е╪╣┘В┘И┘Д ┘Д┘Д╪з╪│╪к┘В╪▒╪з╪▒
                    'retries': 2,
                    'concurrent_fragment_downloads': 2,
                    'http_chunk_size': 4194304,  # 4MB chunks
                }
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(
                        f"https://www.youtube.com/watch?v={video_id}",
                        download=True
                    )
                    
                    if info:
                        # ╪к╪к╪и╪╣ ┘Ж╪м╪з╪н ╪з┘Д┘Г┘И┘Г┘К╪▓
                        track_cookie_usage(cookie_file, success=True)
                        
                        for file_path in downloads_dir.glob(f"{video_id}_alt_{i}.*"):
                            if file_path.suffix in ['.m4a', '.mp3', '.webm', '.mp4', '.opus']:
                                return {
                                    'success': True,
                                    'file_path': str(file_path),
                                    'title': info.get('title', title),
                                    'duration': info.get('duration', 0),
                                    'uploader': info.get('uploader', 'Unknown'),
                                    'elapsed': 0
                                }
                                
            except Exception as e:
                error_msg = str(e).lower()
                LOGGER(__name__).warning(f"тЭМ ┘Б╪┤┘Д ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д╪и╪п┘К┘Д #{i}: {e}")
                
                # ╪к╪к╪и╪╣ ┘Б╪┤┘Д ╪з┘Д┘Г┘И┘Г┘К╪▓ ┘И╪н╪╕╪▒ ╪з┘Д┘Е╪┤┘Г┘И┘Г ┘Б┘К┘З╪з
                track_cookie_usage(cookie_file, success=False)
                
                if any(keyword in error_msg for keyword in [
                    'blocked', 'forbidden', '403', 'unavailable', 'cookies', 'expired',
                    'sign in', 'login', 'authentication', 'token', 'session', 'captcha'
                ]):
                    mark_cookie_as_blocked(cookie_file, f"╪и╪п┘К┘Д: {str(e)[:50]}")
                
                continue
        
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д┘Е╪н╪з┘И┘Д╪з╪к ╪з┘Д╪и╪п┘К┘Д╪й: {e}")
        return None

async def force_download_any_way(video_id: str, title: str) -> Optional[Dict]:
    """┘Е╪н╪з┘И┘Д╪й ╪к╪н┘Е┘К┘Д ┘В╪│╪▒┘К ╪и╪м┘Е┘К╪╣ ╪з┘Д╪╖╪▒┘В ╪з┘Д┘Е╪к╪з╪н╪й"""
    try:
        # ┘Е╪н╪з┘И┘Д╪й ╪м┘Е┘К╪╣ ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪к╪и┘В┘К╪й (╪з┘Д╪п┘Б╪╣╪й ╪з┘Д╪г╪о┘К╪▒╪й)
        cookies_files = get_available_cookies()
        
        # ╪н╪│╪з╪и ╪з┘Д╪к┘И╪▓┘К╪╣ ╪з┘Д╪п┘К┘Ж╪з┘Е┘К┘Г┘К
        distribution = calculate_cookies_distribution(len(cookies_files))
        primary_count = distribution['primary']
        secondary_count = distribution['secondary']
        remaining_count = distribution['remaining']
        
        if remaining_count == 0:
            LOGGER(__name__).info("тЪая╕П ┘Д╪з ╪к┘И╪м╪п ┘Г┘И┘Г┘К╪▓ ┘Е╪к╪и┘В┘К╪й ┘Д┘Д┘Е╪н╪з┘И┘Д╪й ╪з┘Д┘В╪│╪▒┘К╪й")
            return None
        
        start_index = primary_count + secondary_count
        end_index = start_index + remaining_count
        remaining_files = cookies_files[start_index:end_index]
        
        LOGGER(__name__).info(f"ЁЯЪА ┘Е╪н╪з┘И┘Д╪й ┘В╪│╪▒┘К╪й ┘Е╪╣ {len(remaining_files)} ┘Е┘Д┘Б ┘Г┘И┘Г┘К╪▓ ┘Е╪к╪и┘В┘К (┘Е┘Ж {start_index} ╪е┘Д┘Й {end_index})")
        
        for i, cookie_file in enumerate(remaining_files, start_index + 1):
            try:
                LOGGER(__name__).info(f"ЁЯЪА ┘Е╪н╪з┘И┘Д╪й ┘В╪│╪▒┘К╪й #{i}: {os.path.basename(cookie_file)}")
                
                downloads_dir = Path("downloads")
                ydl_opts = {
                    'format': 'bestaudio[filesize<25M]/best[filesize<25M]',  # ╪н╪п ╪г┘В╪╡┘Й ┘Д┘Д╪н╪м┘Е
                    'outtmpl': str(downloads_dir / f'{video_id}_force_{i}.%(ext)s'),
                    'quiet': True,
                    'no_warnings': True,
                    'noplaylist': True,
                    'cookiefile': cookie_file,
                    'socket_timeout': 18,  # ┘И┘В╪к ┘Е╪╣┘В┘И┘Д
                    'retries': 2,  # ┘Е╪н╪з┘И┘Д╪з╪к ┘Е╪╣┘В┘И┘Д╪й
                    'ignore_errors': True,
                    'concurrent_fragment_downloads': 2,
                    'http_chunk_size': 4194304,  # 4MB chunks
                }
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(
                        f"https://www.youtube.com/watch?v={video_id}",
                        download=True
                    )
                    
                    if info:
                        # ╪к╪к╪и╪╣ ┘Ж╪м╪з╪н ╪з┘Д┘Г┘И┘Г┘К╪▓ ┘Б┘К ╪з┘Д┘Е╪н╪з┘И┘Д╪й ╪з┘Д┘В╪│╪▒┘К╪й
                        track_cookie_usage(cookie_file, success=True)
                        
                        for file_path in downloads_dir.glob(f"{video_id}_force_{i}.*"):
                            if file_path.exists() and file_path.stat().st_size > 1000:
                                LOGGER(__name__).info(f"ЁЯОЙ ┘Ж╪м╪н ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘В╪│╪▒┘К ╪и╪з┘Д┘Г┘И┘Г┘К╪▓: {os.path.basename(cookie_file)}")
                                return {
                                    'success': True,
                                    'file_path': str(file_path),
                                    'title': info.get('title', title),
                                    'duration': info.get('duration', 0),
                                    'uploader': info.get('uploader', 'Unknown'),
                                    'elapsed': 0
                                }
                                
            except Exception as e:
                error_msg = str(e).lower()
                LOGGER(__name__).warning(f"тЭМ ┘Б╪┤┘Д ╪з┘Д┘В╪│╪▒┘К #{i}: {e}")
                
                # ╪к╪к╪и╪╣ ┘Б╪┤┘Д ╪з┘Д┘Г┘И┘Г┘К╪▓ ┘И╪н╪╕╪▒ ╪з┘Д╪к╪з┘Д┘Б╪й ┘Ж┘З╪з╪ж┘К╪з┘Л
                track_cookie_usage(cookie_file, success=False)
                
                if any(keyword in error_msg for keyword in [
                    'blocked', 'forbidden', '403', 'unavailable', 'cookies', 'expired',
                    'sign in', 'login', 'authentication', 'token', 'session', 'captcha',
                    'invalid', 'corrupt'
                ]):
                    mark_cookie_as_blocked(cookie_file, f"┘В╪│╪▒┘К: {str(e)[:50]}")
                    LOGGER(__name__).error(f"ЁЯТА ┘Г┘И┘Г┘К╪▓ ╪к╪з┘Д┘Б ┘Ж┘З╪з╪ж┘К╪з┘Л: {os.path.basename(cookie_file)}")
                
                continue
        
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘В╪│╪▒┘К: {e}")
        return None

async def remove_temp_files(*paths):
    """╪н╪░┘Б ╪з┘Д┘Е┘Д┘Б╪з╪к ╪з┘Д┘Е╪д┘В╪к╪й ╪и╪┤┘Г┘Д ╪в┘Е┘Ж"""
    for path in paths:
        if path and os.path.exists(path):
            try:
                os.remove(path)
                LOGGER(__name__).debug(f"╪к┘Е ╪н╪░┘Б ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪д┘В╪к: {path}")
            except Exception as e:
                LOGGER(__name__).warning(f"┘Б╪┤┘Д ╪н╪░┘Б {path}: {e}")

async def download_thumbnail(url: str, title: str, video_id: str = None) -> Optional[str]:
    """╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й ╪и╪┤┘Г┘Д ╪║┘К╪▒ ┘Е╪к╪▓╪з┘Е┘Ж"""
    if not url:
        return None
    
    try:
        # ╪з╪│╪к╪о╪п╪з┘Е video_id ╪е╪░╪з ┘Г╪з┘Ж ┘Е╪к╪з╪н╪з┘Л╪М ┘И╪е┘Д╪з ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д╪╣┘Ж┘И╪з┘Ж ╪з┘Д┘Е┘Ж╪╕┘Б
        if video_id:
            thumb_path = f"downloads/thumb_{video_id}.jpg"
        else:
            title_clean = re.sub(r'[\\/*?:"<>|]', "", title)
            thumb_path = f"downloads/thumb_{title_clean[:20]}.jpg"
        
        # ╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п ╪з┘Д╪╡┘И╪▒╪й ┘Е╪│╪и┘В╪з┘Л
        if os.path.exists(thumb_path):
            return thumb_path
        
        LOGGER(__name__).info(f"ЁЯУ╕ ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {os.path.basename(thumb_path)}")
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                if resp.status == 200:
                    async with aiofiles.open(thumb_path, mode='wb') as f:
                        await f.write(await resp.read())
                    LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {os.path.basename(thumb_path)}")
                    return thumb_path
                else:
                    LOGGER(__name__).warning(f"тЪая╕П ┘Б╪┤┘Д ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й: HTTP {resp.status}")
    except Exception as e:
        LOGGER(__name__).warning(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {e}")
    
    return None

async def process_unlimited_download_enhanced(event, user_id: int, start_time: float):
    """┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Е╪н╪│┘Ж ┘Е╪╣ ╪░┘Г╪з╪б ╪з╪╡╪╖┘Ж╪з╪╣┘К"""
    task_id = f"{user_id}_{int(time.time() * 1000000)}"  # ╪п┘В╪й ╪╣╪з┘Д┘К╪й ╪м╪п╪з┘Л
    
    try:
        # ╪к╪│╪м┘К┘Д ╪и╪п╪з┘К╪й ╪з┘Д┘Е┘З┘Е╪й ┘Б┘И╪▒╪з┘Л ┘Е╪╣ ┘Е╪╣┘Д┘И┘Е╪з╪к ╪е╪╢╪з┘Б┘К╪й
        active_downloads[task_id] = {
            'user_id': user_id,
            'start_time': start_time,
            'task_id': task_id,
            'status': 'started_enhanced',
            'phase': 'initialization'
        }
        
        LOGGER(__name__).info(f"ЁЯЪА ╪и╪п╪б ┘Е╪╣╪з┘Д╪м╪й ┘Б┘И╪▒┘К╪й ┘Е╪н╪│┘Ж╪й ┘Д┘Д┘Е╪│╪к╪о╪п┘Е {user_id} | ╪з┘Д┘Е┘З┘Е╪й: {task_id}")
        
        # ╪к┘Ж┘Б┘К╪░ ╪з┘Д┘Е╪╣╪з┘Д╪м╪й ╪з┘Д┘Г╪з┘Е┘Д╪й ╪з┘Д┘Е╪н╪│┘Ж╪й ┘Б┘К ┘Е┘З┘Е╪й ┘Е┘Ж┘Б╪╡┘Д╪й - ╪и╪п┘И┘Ж ╪з┘Ж╪к╪╕╪з╪▒
        asyncio.create_task(execute_parallel_download_enhanced(event, user_id, start_time, task_id))
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Е╪н╪│┘Ж: {e}")
        await update_performance_stats(False, time.time() - start_time)
    finally:
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Е┘З┘Е╪й
        if task_id in active_downloads:
            del active_downloads[task_id]
            LOGGER(__name__).info(f"ЁЯз╣ ╪к┘Е ╪к┘Ж╪╕┘К┘Б ╪з┘Д╪╣┘Е┘Д┘К╪й ╪з┘Д┘Е┘Г╪к┘Е┘Д╪й: {task_id} - ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {len(active_downloads)}")

async def execute_parallel_download_enhanced(event, user_id: int, start_time: float, task_id: str):
    """╪к┘Ж┘Б┘К╪░ ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Г╪з┘Е┘Д ┘Е╪╣ ╪з┘Д╪к╪н╪│┘К┘Ж╪з╪к ╪з┘Д╪░┘Г┘К╪й"""
    try:
        # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е
        match = event.pattern_match
        if not match:
            await event.reply("тЭМ **╪о╪╖╪г ┘Б┘К ╪к╪н┘Д┘К┘Д ╪з┘Д╪╖┘Д╪и**")
            return
        
        query = match.group(2) if match.group(2) else ""
        if not query:
            await event.reply("ЁЯУЭ **╪з┘Д╪з╪│╪к╪о╪п╪з┘Е:** `╪и╪н╪л ╪з╪│┘Е ╪з┘Д╪г╪║┘Ж┘К╪й`")
            await update_performance_stats(False, time.time() - start_time)
            return
        
        # ╪к╪н╪п┘К╪л ╪н╪з┘Д╪й ╪з┘Д┘Е┘З┘Е╪й
        if task_id in active_downloads:
            active_downloads[task_id].update({
                'query': query,
                'status': 'processing_enhanced',
                'phase': 'search_preparation'
            })
        
        LOGGER(__name__).info(f"ЁЯО╡ ┘Е╪╣╪з┘Д╪м╪й ┘Е╪к┘И╪з╪▓┘К╪й ┘Е╪н╪│┘Ж╪й: {query} | ╪з┘Д┘Е╪│╪к╪о╪п┘Е: {user_id} | ╪з┘Д┘Е┘З┘Е╪й: {task_id}")
        
        # ╪к╪н╪п┘К╪л ╪з┘Д┘Е╪▒╪н┘Д╪й
        if task_id in active_downloads:
            active_downloads[task_id]['phase'] = 'intelligent_search'
        
        # ┘Е╪к╪║┘К╪▒ ┘Д╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й (╪│┘К╪к┘Е ╪е┘Ж╪┤╪з╪д┘З ┘Д╪з╪н┘В╪з┘Л ╪╣┘Ж╪п ╪з┘Д╪н╪з╪м╪й)
        status_msg = None
        
        # ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪и╪╡┘Е╪к - ╪и╪п┘И┘Ж ╪▒╪│╪з╪ж┘Д ┘Е╪▓╪╣╪м╪й
        # status_msg ╪│┘К╪к┘Е ╪е┘Ж╪┤╪з╪д┘З ╪╣┘Ж╪п ╪з┘Д╪н╪з╪м╪й ┘Б┘В╪╖
        
        # ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Е╪н╪│┘Ж ╪и╪п┘И┘Ж ╪н╪п┘И╪п
        try:
            parallel_result = await parallel_search_with_monitoring(query, event.client)
            
            if parallel_result and parallel_result.get('success'):
                search_source = parallel_result.get('search_source', 'unknown')
                search_time = parallel_result.get('search_time', 0)
                processed_msgs = parallel_result.get('processed_messages', 0)
                
                # ╪к╪н╪п┘К╪л ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
                await update_performance_stats(True, time.time() - start_time, from_cache=True)
                
                if search_source == 'database':
                    if not status_msg:
                        status_msg = await event.reply(f"тЬЕ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К ({search_time:.2f}s)**\n\nЁЯУд **╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                    else:
                        await status_msg.edit(f"тЬЕ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К ({search_time:.2f}s)**\n\nЁЯУд **╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                    success = await send_cached_from_database(event, status_msg, parallel_result, event.client)
                    if success:
                        return  # ┘Ж╪м╪н ╪з┘Д╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д┘Г╪з╪┤
                    else:
                        LOGGER(__name__).warning("тЪая╕П ┘Б╪┤┘Д ╪з┘Д╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д┘Г╪з╪┤ - ╪│┘К╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е┘Ж ┘К┘И╪к┘К┘И╪и")
                elif search_source == 'smart_cache':
                    if not status_msg:
                        status_msg = await event.reply(f"тЬЕ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ({search_time:.2f}s)**\n\nЁЯУд **╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                    else:
                        await status_msg.edit(f"тЬЕ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ({search_time:.2f}s)**\n\nЁЯУд **╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                    success = await send_cached_from_telegram(event, status_msg, parallel_result, event.client)
                    if success:
                        return  # ┘Ж╪м╪н ╪з┘Д╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К
                    else:
                        LOGGER(__name__).warning("тЪая╕П ┘Б╪┤┘Д ╪з┘Д╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К - ╪│┘К╪к┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е┘Ж ┘К┘И╪к┘К┘И╪и")
            else:
                # ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤ - ╪з┘Д╪з┘Ж╪к┘В╪з┘Д ┘Е╪и╪з╪┤╪▒╪й ┘Д┘Д╪к╪н┘Е┘К┘Д ╪и╪п┘И┘Ж ╪е╪▓╪╣╪з╪м
                pass
                
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К: {e}")
            # ╪е╪▓╪з┘Д╪й ╪з┘Д╪▒╪│╪з┘Д╪й ╪з┘Д┘Е╪▓╪╣╪м╪й - ╪з┘Д╪з┘Ж╪к┘В╪з┘Д ┘Е╪и╪з╪┤╪▒╪й ┘Д┘Д╪к╪н┘Е┘К┘Д
            
        # ╪з┘Д╪и╪п┘К┘Д: ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪╖┘И╪▒
        try:
            LOGGER(__name__).info(f"ЁЯФД ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪╖┘И╪▒ ┘Г╪и╪п┘К┘Д: {query}")
            await download_song_smart(event, query)
            return
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ┘Б╪┤┘Д ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪╖┘И╪▒: {e}")
        
        # ╪е╪░╪з ┘Д┘Е ┘К╪м╪п ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж╪М ╪з╪и╪п╪г ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К
        if not status_msg:
            status_msg = await event.reply("ЁЯФН **╪м╪з╪▒┘К ╪з┘Д╪и╪н╪л ┘И╪з┘Д╪к╪н┘Е┘К┘Д ┘Е┘Ж ┘К┘И╪к┘К┘И╪и...**")
        else:
            await status_msg.edit("ЁЯФН **╪м╪з╪▒┘К ╪з┘Д╪и╪н╪л ┘И╪з┘Д╪к╪н┘Е┘К┘Д ┘Е┘Ж ┘К┘И╪к┘К┘И╪и...**")
        
        # ╪к╪н╪п┘К╪л ╪з┘Д┘Е╪▒╪н┘Д╪й
        if task_id in active_downloads:
            active_downloads[task_id]['phase'] = 'youtube_download'
        
        # ╪к┘Ж┘Б┘К╪░ ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪н╪│┘Ж
        await process_smart_youtube_download(event, status_msg, query, user_id, start_time, task_id)
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д┘Е╪╣╪з┘Д╪м╪й ╪з┘Д┘Е╪н╪│┘Ж╪й: {e}")
        await update_performance_stats(False, time.time() - start_time)
        
        try:
            await event.reply("тЭМ **╪н╪п╪л ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪╖┘Д╪и┘Г ╪з┘Д┘Е╪н╪│┘Ж**")
        except:
            pass

async def process_smart_youtube_download(event, status_msg, query: str, user_id: int, start_time: float, task_id: str):
    """┘Е╪╣╪з┘Д╪м╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ┘Е┘Ж ┘К┘И╪к┘К┘И╪и ┘Е╪╣ ╪м┘Е┘К╪╣ ╪з┘Д╪к╪н╪│┘К┘Ж╪з╪к"""
    try:
        # ╪к╪н╪п┘К╪л ╪з┘Д┘Е╪▒╪н┘Д╪й
        if task_id in active_downloads:
            active_downloads[task_id]['phase'] = 'youtube_search'
        
        # ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘В╪п┘Е ┘Б┘К ┘К┘И╪к┘К┘И╪и
        await status_msg.edit("ЁЯФН **╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘В╪п┘Е ┘Б┘К ┘К┘И╪к┘К┘И╪и...**")
        
        # ┘Е╪н╪з┘И┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖ ╪г┘И┘Д╪з┘Л (API + yt-dlp)
        try:
            from ZeMusic.plugins.play.youtube_api_downloader import search_and_download_hybrid
            hybrid_result = await search_and_download_hybrid(query)
            
            if hybrid_result and hybrid_result.get('success'):
                LOGGER(__name__).info(f"тЬЕ ┘Ж╪м╪н ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪о╪к┘Д╪╖: {hybrid_result['title']}")
                result = {
                    'audio_path': hybrid_result['file_path'],
                    'title': hybrid_result['title'],
                    'duration': hybrid_result['duration'],
                    'uploader': hybrid_result['uploader'],
                    'video_id': hybrid_result['video_id'],
                    'method': 'hybrid_api_ytdlp'
                }
            else:
                LOGGER(__name__).info("тЪая╕П ┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪о╪к┘Д╪╖╪М ╪з┘Д╪к╪и╪п┘К┘Д ┘Д┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪к┘В┘Д┘К╪п┘К")
                # ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е┘И╪м┘И╪п ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к
                result = await downloader.hyper_download(query)
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖: {e}")
            # ╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е┘И╪м┘И╪п ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к
            result = await downloader.hyper_download(query)
        
        if result:
            # ╪к╪н╪п┘К╪л ╪з┘Д┘Е╪▒╪н┘Д╪й
            if task_id in active_downloads:
                active_downloads[task_id]['phase'] = 'sending_file'
            
            # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е╪╣ ╪н┘Б╪╕ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К
            await send_audio_file(event, status_msg, result['audio_path'], result, query, event.client)
            
            # ╪к╪н╪п┘К╪л ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
            await update_performance_stats(True, time.time() - start_time)
            
            LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е┘Г┘Е╪з┘Д ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪н╪│┘Ж: {query}")
        else:
            await status_msg.edit("тЭМ **╪╣╪░╪▒╪з┘Л╪М ┘Д┘Е ╪г╪к┘Е┘Г┘Ж ┘Е┘Ж ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д╪г╪║┘Ж┘К╪й**\n\nЁЯТб **╪м╪▒╪и:**\nтАв ┘Г┘Д┘Е╪з╪к ┘Е╪о╪к┘Д┘Б╪й\nтАв ╪з╪│┘Е ╪з┘Д┘Б┘Ж╪з┘Ж\nтАв ╪м╪▓╪б ┘Е┘Ж ┘Г┘Д┘Е╪з╪к ╪з┘Д╪г╪║┘Ж┘К╪й")
            await update_performance_stats(False, time.time() - start_time)
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К: {e}")
        await status_msg.edit("тЭМ **╪н╪п╪л ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д**")
        await update_performance_stats(False, time.time() - start_time)

# --- ╪г┘И╪з┘Е╪▒ ╪з┘Д┘Е╪╖┘И╪▒ ┘Е╪╣ Telethon ---
async def cache_stats_handler(event):
    """╪╣╪▒╪╢ ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        async with downloader.conn_manager.db_connection() as conn:
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM channel_index")
            total_cached = cursor.fetchone()[0]
            
            cursor.execute("SELECT SUM(access_count) FROM channel_index")
            total_hits = cursor.fetchone()[0] or 0
            
            cursor.execute("SELECT original_title, access_count FROM channel_index ORDER BY access_count DESC LIMIT 5")
            top_songs = cursor.fetchall()
            
            # ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е
            mem_usage = psutil.virtual_memory().percent
            cpu_usage = psutil.cpu_percent()
            active_tasks = len(downloader.active_tasks)
            cache_hit_rate = downloader.cache_hits / max(1, downloader.cache_hits + downloader.cache_misses) * 100
            
            stats_text = f"""ЁЯУК **╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪к┘В╪п┘Е╪й**

ЁЯТ╛ **╪з┘Д┘Е╪н┘Б┘И╪╕:** {total_cached} ┘Е┘Д┘Б
тЪб **┘Е╪▒╪з╪к ╪з┘Д╪з╪│╪к╪о╪п╪з┘Е:** {total_hits}
ЁЯУИ **┘Ж╪│╪и╪й ╪з┘Д┘Г╪з╪┤:** {cache_hit_rate:.1f}%
ЁЯУ║ **┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж:** {SMART_CACHE_CHANNEL or "╪║┘К╪▒ ┘Е┘П╪╣╪п╪й"}

ЁЯза **╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е:**
тАв ╪з┘Д╪░╪з┘Г╪▒╪й: {mem_usage}%
тАв ╪з┘Д┘Е╪╣╪з┘Д╪м: {cpu_usage}%
тАв ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Ж╪┤╪╖╪й: {active_tasks}

ЁЯО╡ **╪з┘Д╪г┘Г╪л╪▒ ╪╖┘Д╪и╪з┘Л:**"""
            
            for i, row in enumerate(top_songs, 1):
                stats_text += f"\n{i}. {row[0][:30]}... ({row[1]})"
            
            await event.reply(stats_text)
            
    except Exception as e:
        await event.reply(f"тЭМ ╪о╪╖╪г: {e}")

async def clear_cache_handler(event):
    """┘Е╪│╪н ┘Г╪з╪┤ ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        async with downloader.conn_manager.db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM channel_index")
            total_before = cursor.fetchone()[0]
            cursor.execute("DELETE FROM channel_index")
            conn.commit()
        
        downloader.cache_hits = 0
        downloader.cache_misses = 0
        
        await event.reply(f"""ЁЯз╣ **╪к┘Е ┘Е╪│╪н ┘Г╪з╪┤ ╪з┘Д╪к╪о╪▓┘К┘Ж!**

ЁЯУК **╪з┘Д┘Е╪н╪░┘И┘Б:** {total_before} ┘Е┘Д┘Б
ЁЯТ╜ **┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к:** ╪к┘Е ╪к┘Ж╪╕┘К┘Б┘З╪з
ЁЯФД **╪з┘Д┘Г╪з╪┤:** ╪к┘Е ╪е╪╣╪з╪п╪й ╪к╪╣┘К┘К┘Ж┘З

тЪб ╪│┘К╪к┘Е ╪е╪╣╪з╪п╪й ╪и┘Ж╪з╪б ╪з┘Д┘Г╪з╪┤ ╪к┘Д┘В╪з╪ж┘К╪з┘Л ┘Е╪╣ ╪з┘Д╪з╪│╪к╪о╪п╪з┘Е""")
        
    except Exception as e:
        await event.reply(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Е╪│╪н ╪з┘Д┘Г╪з╪┤: {e}")

async def system_stats_handler(event):
    """╪╣╪▒╪╢ ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪к┘В╪п┘Е╪й"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        # ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б
        mem = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        load_avg = os.getloadavg()
        
        stats_text = f"""ЁЯУб **╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪к┘В╪п┘Е╪й**

ЁЯза **╪з┘Д╪░╪з┘Г╪▒╪й:**
тАв ╪з┘Д╪е╪м┘Е╪з┘Д┘К: {mem.total // (1024**3)} GB
тАв ╪з┘Д┘Е╪│╪к╪о╪п┘Е: {mem.used // (1024**3)} GB
тАв ╪з┘Д╪н╪▒: {mem.free // (1024**3)} GB
тАв ╪з┘Д┘Ж╪│╪и╪й: {mem.percent}%

ЁЯТ╛ **╪з┘Д╪к╪о╪▓┘К┘Ж:**
тАв ╪з┘Д╪е╪м┘Е╪з┘Д┘К: {disk.total // (1024**3)} GB
тАв ╪з┘Д┘Е╪│╪к╪о╪п┘Е: {disk.used // (1024**3)} GB
тАв ╪з┘Д┘Ж╪│╪и╪й: {disk.percent}%

тЪЩя╕П **╪з┘Д┘Е╪╣╪з┘Д╪м:**
тАв ╪з┘Д┘Ж┘И┘Й: {psutil.cpu_count()}
тАв ╪з┘Д╪з╪│╪к╪о╪п╪з┘Е: {psutil.cpu_percent()}%
тАв ┘Е╪к┘И╪│╪╖ ╪з┘Д╪к╪н┘Е┘К┘Д (1/5/15 ╪п): {load_avg[0]:.2f}/{load_avg[1]:.2f}/{load_avg[2]:.2f}

ЁЯУ╢ **╪з┘Д╪┤╪и┘Г╪й:**
тАв ╪з┘Д╪з╪к╪╡╪з┘Д╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {len(psutil.net_connections())}
"""
        await event.reply(stats_text)
        
    except Exception as e:
        await event.reply(f"тЭМ ╪о╪╖╪г: {e}")

# --- ╪е╪п╪з╪▒╪й ╪е╪║┘Д╪з┘В ╪з┘Д┘Ж╪╕╪з┘Е ---
async def shutdown_system():
    """╪е╪║┘Д╪з┘В ╪м┘Е┘К╪╣ ┘Е┘И╪з╪▒╪п ╪з┘Д┘Ж╪╕╪з┘Е ╪и╪┤┘Г┘Д ╪в┘Е┘Ж"""
    try:
        LOGGER(__name__).info("ЁЯФ┤ ╪и╪п╪б ╪е┘К┘В╪з┘Б ╪з┘Д┘Ж╪╕╪з┘Е...")
        if hasattr(downloader, 'conn_manager') and downloader.conn_manager:
            await downloader.conn_manager.close()
        LOGGER(__name__).info("тЬЕ ╪к┘Е ╪е┘К┘В╪з┘Б ╪м┘Е┘К╪╣ ╪з┘Д┘Е┘И╪з╪▒╪п")
    except Exception as e:
        LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪е┘К┘В╪з┘Б ╪з┘Д┘Ж╪╕╪з┘Е: {e}")

# ╪к╪│╪м┘К┘Д ┘Е╪╣╪з┘Д╪м ╪з┘Д╪е╪║┘Д╪з┘В
atexit.register(lambda: asyncio.run(shutdown_system()))

# ╪п╪з┘Д╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Е╪╖┘И╪▒
async def download_song_smart(message, query: str):
    """
    ╪п╪з┘Д╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ╪з┘Д╪▒╪ж┘К╪│┘К╪й ┘Е╪╣ ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К
    
    ╪з┘Д┘Е╪▒╪з╪н┘Д:
    1. ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Б┘К ╪з┘Д┘Г╪з╪┤ ┘И┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
    2. ╪е╪▒╪│╪з┘Д ┘Б┘И╪▒┘К ╪е╪░╪з ┘И┘П╪м╪п ╪з┘Д┘Е┘В╪╖╪╣
    3. ╪з┘Ж╪к┘В╪з┘Д ┘Е╪к╪│┘Д╪│┘Д ┘Д┘Д╪╖╪▒┘В ╪з┘Д╪г╪о╪▒┘Й ╪е╪░╪з ┘Д┘Е ┘К┘И╪м╪п
    """
    try:
        # ┘Е╪к╪║┘К╪▒ ┘Д╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й (╪│┘К╪к┘Е ╪е┘Ж╪┤╪з╪д┘З ╪╣┘Ж╪п ╪з┘Д╪н╪з╪м╪й)
        status_msg = None
        
        LOGGER(__name__).info(f"ЁЯО╡ ╪и╪п╪б ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Д┘Д╪з╪│╪к╪╣┘Д╪з┘Е: {query}")
        
        # ╪з┘Д┘Е╪▒╪н┘Д╪й 1: ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Б┘К ╪з┘Д┘Г╪з╪┤ ┘И┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
        cache_result, telegram_result = await parallel_cache_search(query, message.client)
        
        # ┘Б╪н╪╡ ╪з┘Д┘Ж╪к╪з╪ж╪м ╪з┘Д┘Е╪к┘И╪з╪▓┘К╪й
        if cache_result:
            LOGGER(__name__).info("тЬЕ ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К")
            if not status_msg:
                status_msg = await message.reply("ЁЯУБ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤!**\nЁЯУд ╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...")
            else:
                await status_msg.edit("ЁЯУБ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤!**\nЁЯУд ╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...")
            
            success = await send_local_cached_audio(message, cache_result, status_msg)
            if success:
                return
                
        elif telegram_result:
            LOGGER(__name__).info("тЬЕ ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж")
            if not status_msg:
                status_msg = await message.reply("ЁЯУ║ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж!**\nЁЯУд ╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...")
            else:
                await status_msg.edit("ЁЯУ║ **╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж!**\nЁЯУд ╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...")
            
            success = await send_telegram_cached_audio(message, telegram_result, status_msg)
            if success:
                return
        
        # ╪з┘Д┘Е╪▒╪н┘Д╪й 2: ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д┘Е┘В╪╖╪╣ - ╪з┘Д╪з┘Ж╪к┘В╪з┘Д ┘Д┘Д╪и╪н╪л ╪з┘Д╪о╪з╪▒╪м┘К
        LOGGER(__name__).info("ЁЯФН ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤ - ╪и╪п╪б ╪з┘Д╪и╪н╪л ╪з┘Д╪о╪з╪▒╪м┘К")
        if not status_msg:
            status_msg = await message.reply("ЁЯФН **╪м╪з╪▒┘К ╪з┘Д╪и╪н╪л ┘Б┘К YouTube...**")
        else:
            await status_msg.edit("ЁЯФН **╪м╪з╪▒┘К ╪з┘Д╪и╪н╪л ┘Б┘К YouTube...**")
        
        # ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к╪│┘Д╪│┘Д ┘Б┘К ╪з┘Д╪╖╪▒┘В ╪з┘Д╪о╪з╪▒╪м┘К╪й
        video_info = await sequential_external_search(query)
        
        if not video_info:
            if not status_msg:
                status_msg = await message.reply(
                    "тЭМ **┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Ж╪к╪з╪ж╪м**\n\n"
                    "ЁЯТб **╪м╪▒╪и:**\n"
                    "тАв ┘Г┘Д┘Е╪з╪к ┘Е╪о╪к┘Д┘Б╪й\n"
                    "тАв ╪з╪│┘Е ╪з┘Д┘Б┘Ж╪з┘Ж\n"
                    "тАв ╪м╪▓╪б ┘Е┘Ж ┘Г┘Д┘Е╪з╪к ╪з┘Д╪г╪║┘Ж┘К╪й"
                )
            else:
                await status_msg.edit(
                    "тЭМ **┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Ж╪к╪з╪ж╪м**\n\n"
                    "ЁЯТб **╪м╪▒╪и:**\n"
                    "тАв ┘Г┘Д┘Е╪з╪к ┘Е╪о╪к┘Д┘Б╪й\n"
                    "тАв ╪з╪│┘Е ╪з┘Д┘Б┘Ж╪з┘Ж\n"
                    "тАв ╪м╪▓╪б ┘Е┘Ж ┘Г┘Д┘Е╪з╪к ╪з┘Д╪г╪║┘Ж┘К╪й"
                )
            return
        
        # ╪з┘Д┘Е╪▒╪н┘Д╪й 3: ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ┘Е╪╣ cookies
        LOGGER(__name__).info(f"тмЗя╕П ╪и╪п╪б ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К: {video_info.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
        success = await smart_download_and_send(message, video_info, status_msg)
        
        if not success:
            if not status_msg:
                status_msg = await message.reply(
                    "тЭМ **┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д**\n\n"
                    "╪н╪п╪л ╪о╪╖╪г ╪г╪л┘Ж╪з╪б ╪к╪н┘Е┘К┘Д ╪з┘Д┘Е┘В╪╖╪╣\n"
                    "┘К╪▒╪м┘Й ╪з┘Д┘Е╪н╪з┘И┘Д╪й ┘Е╪▒╪й ╪г╪о╪▒┘Й ┘Д╪з╪н┘В╪з┘Л"
                )
            else:
                await status_msg.edit(
                    "тЭМ **┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д**\n\n"
                    "╪н╪п╪л ╪о╪╖╪г ╪г╪л┘Ж╪з╪б ╪к╪н┘Е┘К┘Д ╪з┘Д┘Е┘В╪╖╪╣\n"
                    "┘К╪▒╪м┘Й ╪з┘Д┘Е╪н╪з┘И┘Д╪й ┘Е╪▒╪й ╪г╪о╪▒┘Й ┘Д╪з╪н┘В╪з┘Л"
                )
        
    except Exception as e:
        LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К download_song_smart: {e}")
        try:
            await message.reply(
                "тЭМ **╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л**\n\n"
                "╪н╪п╪л ╪о╪╖╪г ╪г╪л┘Ж╪з╪б ┘Е╪╣╪з┘Д╪м╪й ╪╖┘Д╪и┘Г\n"
                "┘К╪▒╪м┘Й ╪з┘Д┘Е╪н╪з┘И┘Д╪й ┘Е╪▒╪й ╪г╪о╪▒┘Й"
            )
        except:
            pass

# === ┘Ж╪╕╪з┘Е ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ╪з┘Д┘Е╪╖┘И╪▒ ===

async def parallel_cache_search(query: str, bot_client) -> Tuple[Optional[Dict], Optional[Dict]]:
    """╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К ┘И┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ╪п┘В┘К┘В╪й"""
    start_time = time.time()
    
    try:
        LOGGER(__name__).info(f"ЁЯФН ╪и╪п╪б ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К: {query}")
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪╡╪н╪й ╪з┘Д┘Е╪п╪о┘Д╪з╪к
        if not query or not query.strip():
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д╪и╪н╪л ┘Б╪з╪▒╪║")
            return None, None
            
        if not bot_client:
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ╪╣┘Е┘К┘Д ╪з┘Д╪и┘И╪к ╪║┘К╪▒ ┘Е╪к╪з╪н")
            return None, None
        
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е
        cleaned_query = query.strip()
        LOGGER(__name__).debug(f"ЁЯз╣ ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д┘Е┘Ж╪╕┘Б: {cleaned_query}")
        
        # ╪е┘Ж╪┤╪з╪б ┘Е┘З╪з┘Е ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ┘Б╪▒╪п┘К╪й
        cache_task = None
        telegram_task = None
        
        try:
            cache_task = asyncio.create_task(search_local_cache(cleaned_query))
            LOGGER(__name__).debug("тЬЕ ╪к┘Е ╪е┘Ж╪┤╪з╪б ┘Е┘З┘Е╪й ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К")
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е┘Ж╪┤╪з╪б ┘Е┘З┘Е╪й ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К: {e}")
            
        try:
            telegram_task = asyncio.create_task(search_in_telegram_cache(cleaned_query, bot_client))
            LOGGER(__name__).debug("тЬЕ ╪к┘Е ╪е┘Ж╪┤╪з╪б ┘Е┘З┘Е╪й ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е")
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е┘Ж╪┤╪з╪б ┘Е┘З┘Е╪й ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е: {e}")
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘Ж╪м╪з╪н ╪е┘Ж╪┤╪з╪б ╪з┘Д┘Е┘З╪з┘Е
        if not cache_task and not telegram_task:
            LOGGER(__name__).error("тЭМ ┘Б╪┤┘Д ┘Б┘К ╪е┘Ж╪┤╪з╪б ╪г┘К ┘Е┘Ж ┘Е┘З╪з┘Е ╪з┘Д╪и╪н╪л")
            return None, None
        
        # ╪з┘Ж╪к╪╕╪з╪▒ ╪з┘Д┘Ж╪к╪з╪ж╪м ┘Е╪╣ timeout ┘И┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ┘Е╪к┘В╪п┘Е╪й
        cache_result = None
        telegram_result = None
        
        try:
            # ╪к┘Ж┘Б┘К╪░ ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е╪к╪з╪н╪й ┘Б┘В╪╖
            tasks = []
            if cache_task:
                tasks.append(cache_task)
            if telegram_task:
                tasks.append(telegram_task)
            
            LOGGER(__name__).info(f"тП│ ╪з┘Ж╪к╪╕╪з╪▒ {len(tasks)} ┘Е┘З┘Е╪й ╪и╪н╪л ┘Е╪╣ ┘Е┘З┘Д╪й 10 ╪л┘И╪з┘Ж...")
            
            results = await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=10.0
            )
            
            # ╪к╪н┘Д┘К┘Д ╪з┘Д┘Ж╪к╪з╪ж╪м
            result_index = 0
            if cache_task:
                cache_result = results[result_index]
                result_index += 1
                
                if isinstance(cache_result, Exception):
                    LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪н┘Д┘К: {cache_result}")
                    cache_result = None
                elif cache_result:
                    LOGGER(__name__).info(f"тЬЕ ┘Ж╪м╪н ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪н┘Д┘К: {cache_result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
                else:
                    LOGGER(__name__).debug("ЁЯФН ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Ж╪к╪з╪ж╪м ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К")
                    
            if telegram_task:
                telegram_result = results[result_index]
                
                if isinstance(telegram_result, Exception):
                    LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е: {telegram_result}")
                    telegram_result = None
                elif telegram_result:
                    LOGGER(__name__).info(f"тЬЕ ┘Ж╪м╪н ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е: {telegram_result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
                else:
                    LOGGER(__name__).debug("ЁЯФН ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Ж╪к╪з╪ж╪м ┘Б┘К ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е")
            
        except asyncio.TimeoutError:
            LOGGER(__name__).warning("тП░ ╪з┘Ж╪к┘З╪к ┘Е┘З┘Д╪й ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К (10 ╪л┘И╪з┘Ж)")
            
            # ╪е┘Д╪║╪з╪б ╪з┘Д┘Е┘З╪з┘Е ╪з┘Д┘Е╪╣┘Д┘В╪й
            if cache_task and not cache_task.done():
                cache_task.cancel()
                LOGGER(__name__).debug("ЁЯЪл ╪к┘Е ╪е┘Д╪║╪з╪б ┘Е┘З┘Е╪й ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪н┘Д┘К")
                
            if telegram_task and not telegram_task.done():
                telegram_task.cancel()
                LOGGER(__name__).debug("ЁЯЪл ╪к┘Е ╪е┘Д╪║╪з╪б ┘Е┘З┘Е╪й ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е")
                
        except Exception as gather_error:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪к╪м┘Е┘К╪╣ ┘Ж╪к╪з╪ж╪м ╪з┘Д╪и╪н╪л: {gather_error}")
            import traceback
            LOGGER(__name__).error(f"ЁЯУЛ ╪к┘Б╪з╪╡┘К┘Д ╪з┘Д╪о╪╖╪г: {traceback.format_exc()}")
        
        # ╪к╪│╪м┘К┘Д ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к
        elapsed_time = time.time() - start_time
        LOGGER(__name__).info(
            f"ЁЯУК ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К:\n"
            f"   тП▒я╕П ╪з┘Д┘И┘В╪к ╪з┘Д┘Е╪│╪к╪║╪▒┘В: {elapsed_time:.2f} ╪л╪з┘Ж┘К╪й\n"
            f"   ЁЯУБ ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К: {'тЬЕ ┘Ж╪м╪н' if cache_result else 'тЭМ ┘Б╪┤┘Д/┘Б╪з╪▒╪║'}\n"
            f"   ЁЯУ║ ╪з┘Д╪к┘Д┘К╪м╪▒╪з┘Е: {'тЬЕ ┘Ж╪м╪н' if telegram_result else 'тЭМ ┘Б╪┤┘Д/┘Б╪з╪▒╪║'}"
        )
        
        return cache_result, telegram_result
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        LOGGER(__name__).error(
            f"тЭМ ╪о╪╖╪г ╪╣╪з┘Е ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘И╪з╪▓┘К:\n"
            f"   ЁЯФН ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е: {query}\n"
            f"   тП▒я╕П ╪з┘Д┘И┘В╪к: {elapsed_time:.2f} ╪л╪з┘Ж┘К╪й\n"
            f"   ЁЯУЛ ╪з┘Д╪о╪╖╪г: {str(e)}"
        )
        import traceback
        LOGGER(__name__).error(f"ЁЯУЛ ╪к┘Б╪з╪╡┘К┘Д ╪з┘Д╪о╪╖╪г ╪з┘Д┘Г╪з┘Е┘Д╪й: {traceback.format_exc()}")
        return None, None

async def search_local_cache(query: str) -> Optional[Dict]:
    """╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К (┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к) ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ╪п┘В┘К┘В╪й"""
    start_time = time.time()
    conn = None
    
    try:
        LOGGER(__name__).info(f"ЁЯУБ ╪и╪п╪б ╪з┘Д╪и╪н╪л ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К: {query}")
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪╡╪н╪й ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е
        if not query or not query.strip():
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д╪и╪н╪л ┘Б╪з╪▒╪║ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К")
            return None
        
        # ╪к┘Ж╪╕┘К┘Б ╪з┘Д┘Ж╪╡ ┘Д┘Д╪и╪н╪л
        try:
            normalized_query = normalize_arabic_text(query)
            LOGGER(__name__).debug(f"ЁЯз╣ ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д┘Е┘Ж╪╕┘Б: '{normalized_query}'")
            
            if not normalized_query:
                LOGGER(__name__).warning("тЪая╕П ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д┘Е┘Ж╪╕┘Б ┘Б╪з╪▒╪║")
                return None
                
            search_keywords = normalized_query.split()
            LOGGER(__name__).debug(f"ЁЯФС ┘Г┘Д┘Е╪з╪к ╪з┘Д╪и╪н╪л: {search_keywords}")
            
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪к┘Ж╪╕┘К┘Б ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е: {e}")
            return None
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        if not os.path.exists(DATABASE_PATH):
            LOGGER(__name__).warning(f"тЪая╕П ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪║┘К╪▒ ┘Е┘И╪м┘И╪п╪й: {DATABASE_PATH}")
            return None
        
        # ╪з┘Д╪з╪к╪╡╪з┘Д ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        try:
            conn = sqlite3.connect(DATABASE_PATH, timeout=5.0)
            cursor = conn.cursor()
            LOGGER(__name__).debug("тЬЕ ╪к┘Е ╪з┘Д╪з╪к╪╡╪з┘Д ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
            
        except sqlite3.Error as db_error:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪з╪к╪╡╪з┘Д ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {db_error}")
            return None
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п ╪з┘Д╪м╪п┘И┘Д
        try:
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='cached_audio'")
            table_exists = cursor.fetchone()
            
            if not table_exists:
                LOGGER(__name__).warning("тЪая╕П ╪м╪п┘И┘Д cached_audio ╪║┘К╪▒ ┘Е┘И╪м┘И╪п")
                return None
                
            LOGGER(__name__).debug("тЬЕ ╪м╪п┘И┘Д cached_audio ┘Е┘И╪м┘И╪п")
            
        except sqlite3.Error as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Б╪н╪╡ ╪з┘Д╪м╪п┘И┘Д: {e}")
            return None
        
        # ╪и┘Ж╪з╪б ╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к┘В╪п┘Е
        search_conditions = []
        search_params = []
        
        try:
            for keyword in search_keywords:
                if keyword.strip():  # ╪к╪м╪з┘З┘Д ╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Б╪з╪▒╪║╪й
                    search_conditions.append(
                        "(LOWER(title) LIKE ? OR LOWER(artist) LIKE ? OR LOWER(keywords) LIKE ?)"
                    )
                    keyword_lower = keyword.lower()
                    search_params.extend([f"%{keyword_lower}%", f"%{keyword_lower}%", f"%{keyword_lower}%"])
            
            if not search_conditions:
                LOGGER(__name__).warning("тЪая╕П ┘Д╪з ╪к┘И╪м╪п ╪┤╪▒┘И╪╖ ╪и╪н╪л ╪╡╪з┘Д╪н╪й")
                return None
                
            where_clause = " AND ".join(search_conditions)
            query_sql = f"""
            SELECT video_id, title, artist, duration, file_path, thumb, message_id, keywords, created_at
            FROM cached_audio 
            WHERE {where_clause}
            ORDER BY created_at DESC LIMIT 1
            """
            
            LOGGER(__name__).debug(f"ЁЯУЛ ╪з╪│╪к╪╣┘Д╪з┘Е SQL: {query_sql}")
            LOGGER(__name__).debug(f"ЁЯУЛ ┘Е╪╣╪з┘Е┘Д╪з╪к ╪з┘Д╪и╪н╪л: {len(search_params)} ┘Е╪╣╪з┘Е┘Д")
            
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪и┘Ж╪з╪б ╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д╪и╪н╪л: {e}")
            return None
        
        # ╪к┘Ж┘Б┘К╪░ ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е
        try:
            cursor.execute(query_sql, search_params)
            result = cursor.fetchone()
            
            if result:
                # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪╡╪н╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪│╪к╪▒╪м╪╣╪й
                try:
                    result_dict = {
                        "video_id": result[0] if result[0] else "unknown",
                        "title": result[1] if result[1] else "╪╣┘Ж┘И╪з┘Ж ╪║┘К╪▒ ┘Е╪н╪п╪п",
                        "artist": result[2] if result[2] else "┘Б┘Ж╪з┘Ж ╪║┘К╪▒ ┘Е╪н╪п╪п",
                        "duration": int(result[3]) if result[3] and str(result[3]).isdigit() else 0,
                        "file_path": result[4] if result[4] else None,
                        "thumb": result[5] if result[5] else None,
                        "message_id": int(result[6]) if result[6] and str(result[6]).isdigit() else None,
                        "keywords": result[7] if result[7] else "",
                        "source": "local_cache",
                        "created_at": result[8] if result[8] else "╪║┘К╪▒ ┘Е╪н╪п╪п"
                    }
                    
                    # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п ╪з┘Д┘Е┘Д┘Б ╪е╪░╪з ┘Г╪з┘Ж ┘Е╪н╪п╪п╪з┘Л
                    if result_dict["file_path"] and not os.path.exists(result_dict["file_path"]):
                        LOGGER(__name__).warning(f"тЪая╕П ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Б┘И╪╕ ╪║┘К╪▒ ┘Е┘И╪м┘И╪п: {result_dict['file_path']}")
                        result_dict["file_path"] = None
                    
                    elapsed_time = time.time() - start_time
                    LOGGER(__name__).info(
                        f"тЬЕ ╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К:\n"
                        f"   ЁЯО╡ ╪з┘Д╪╣┘Ж┘И╪з┘Ж: {result_dict['title']}\n"
                        f"   ЁЯСд ╪з┘Д┘Б┘Ж╪з┘Ж: {result_dict['artist']}\n"
                        f"   ЁЯУБ ╪з┘Д┘Е┘Д┘Б: {'тЬЕ ┘Е┘И╪м┘И╪п' if result_dict['file_path'] else 'тЭМ ╪║┘К╪▒ ┘Е┘И╪м┘И╪п'}\n"
                        f"   тП▒я╕П ╪з┘Д┘И┘В╪к: {elapsed_time:.2f} ╪л╪з┘Ж┘К╪й"
                    )
                    
                    return result_dict
                    
                except Exception as e:
                    LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ┘Ж╪к┘К╪м╪й ╪з┘Д╪и╪н╪л: {e}")
                    return None
            else:
                elapsed_time = time.time() - start_time
                LOGGER(__name__).info(f"ЁЯФН ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ┘Ж╪к╪з╪ж╪м ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К (тП▒я╕П {elapsed_time:.2f}s)")
                return None
                
        except sqlite3.Error as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪к┘Ж┘Б┘К╪░ ╪з╪│╪к╪╣┘Д╪з┘Е ╪з┘Д╪и╪н╪л: {e}")
            return None
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        LOGGER(__name__).error(
            f"тЭМ ╪о╪╖╪г ╪╣╪з┘Е ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪н┘Д┘К:\n"
            f"   ЁЯФН ╪з┘Д╪з╪│╪к╪╣┘Д╪з┘Е: {query}\n"
            f"   тП▒я╕П ╪з┘Д┘И┘В╪к: {elapsed_time:.2f} ╪л╪з┘Ж┘К╪й\n"
            f"   ЁЯУЛ ╪з┘Д╪о╪╖╪г: {str(e)}"
        )
        import traceback
        LOGGER(__name__).error(f"ЁЯУЛ ╪к┘Б╪з╪╡┘К┘Д ╪з┘Д╪о╪╖╪г ╪з┘Д┘Г╪з┘Е┘Д╪й: {traceback.format_exc()}")
        return None
        
    finally:
        # ╪е╪║┘Д╪з┘В ╪з┘Д╪з╪к╪╡╪з┘Д ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        if conn:
            try:
                conn.close()
                LOGGER(__name__).debug("ЁЯФТ ╪к┘Е ╪е╪║┘Д╪з┘В ╪з┘Д╪з╪к╪╡╪з┘Д ╪и┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к")
            except Exception as e:
                LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪е╪║┘Д╪з┘В ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {e}")

async def sequential_external_search(query: str) -> Optional[Dict]:
    """╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪к╪│┘Д╪│┘Д ┘Б┘К ╪з┘Д┘Е╪╡╪з╪п╪▒ ╪з┘Д╪о╪з╪▒╪м┘К╪й"""
    try:
        LOGGER(__name__).info(f"ЁЯМР ╪и╪п╪б ╪з┘Д╪и╪н╪л ╪з┘Д╪о╪з╪▒╪м┘К ╪з┘Д┘Е╪к╪│┘Д╪│┘Д: {query}")
        
        # ╪з┘Д╪╖╪▒┘К┘В╪й 1: YouTube Search
        try:
            LOGGER(__name__).info("ЁЯФН ┘Е╪н╪з┘И┘Д╪й YouTube Search...")
            if YOUTUBE_SEARCH_AVAILABLE:
                search = YoutubeSearch(query, max_results=1)
                results = search.to_dict()
                
                if results:
                    result = results[0]
                    video_id = result.get('id', '')
                    
                    if video_id:
                        LOGGER(__name__).info(f"тЬЕ YouTube Search ┘Ж╪м╪н: {result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
                        return {
                            'id': video_id,
                            'title': result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п'),
                            'channel': result.get('channel', '╪║┘К╪▒ ┘Е╪н╪п╪п'),
                            'duration': result.get('duration', '0:00'),
                            'views': result.get('views', '╪║┘К╪▒ ┘Е╪н╪п╪п'),
                            'source': 'youtube_search'
                        }
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П YouTube Search ┘Б╪┤┘Д: {e}")
        
        # ╪з┘Д╪╖╪▒┘К┘В╪й 2: ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖ (YouTube API + yt-dlp)
        try:
            LOGGER(__name__).info("ЁЯФН ┘Е╪н╪з┘И┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖ (YouTube API + yt-dlp)...")
            from .youtube_api_downloader import download_youtube_hybrid
            
            success, result = await download_youtube_hybrid(query, "downloads")
            if success and result:
                LOGGER(__name__).info(f"тЬЕ ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖ ┘Ж╪м╪н: {result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
                return {
                    'id': result['video_id'],
                    'title': result['title'],
                    'channel': result.get('channel', '╪║┘К╪▒ ┘Е╪н╪п╪п'),
                    'duration': '0:00',  # ╪│┘К╪к┘Е ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘К┘З╪з ┘Е┘Ж ╪з┘Д┘Е┘Д┘Б
                    'views': '╪║┘К╪▒ ┘Е╪н╪п╪п',
                    'source': 'hybrid_api_ytdlp',
                    'file_path': result['file_path'],
                    'thumbnail': result.get('thumbnail', ''),
                    'url': result['url']
                }
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖ ┘Б╪┤┘Д: {e}")
        
        # ╪з┘Д╪╖╪▒┘К┘В╪й 3: YouTube API ╪з┘Д╪к┘В┘Д┘К╪п┘К (╪е╪░╪з ┘Г╪з┘Ж ┘Е╪к╪з╪н╪з┘Л)
        try:
            LOGGER(__name__).info("ЁЯФН ┘Е╪н╪з┘И┘Д╪й YouTube API ╪з┘Д╪к┘В┘Д┘К╪п┘К...")
            import config
            
            if hasattr(config, 'YOUTUBE_API_KEY') and config.YOUTUBE_API_KEY:
                # ┘К┘Е┘Г┘Ж ╪е╪╢╪з┘Б╪й YouTube API ╪з┘Д╪к┘В┘Д┘К╪п┘К ┘З┘Ж╪з ┘Д╪з╪н┘В╪з┘Л
                pass
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П YouTube API ┘Б╪┤┘Д: {e}")
        
        # ╪з┘Д╪╖╪▒┘К┘В╪й 3: Invidious (╪е╪░╪з ┘Г╪з┘Ж ┘Е╪к╪з╪н╪з┘Л)
        try:
            LOGGER(__name__).info("ЁЯФН ┘Е╪н╪з┘И┘Д╪й Invidious...")
            # ┘К┘Е┘Г┘Ж ╪е╪╢╪з┘Б╪й Invidious ┘З┘Ж╪з ┘Д╪з╪н┘В╪з┘Л
            pass
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П Invidious ┘Б╪┤┘Д: {e}")
        
        LOGGER(__name__).warning("тЭМ ┘Б╪┤┘Д ╪м┘Е┘К╪╣ ╪╖╪▒┘В ╪з┘Д╪и╪н╪л ╪з┘Д╪о╪з╪▒╪м┘К")
        return None
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪и╪н╪л ╪з┘Д╪о╪з╪▒╪м┘К: {e}")
        return None

async def send_local_cached_audio(message, cache_result: Dict, status_msg) -> bool:
    """╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘В╪╖╪╣ ╪з┘Д╪╡┘И╪к┘К ┘Е┘Ж ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К"""
    try:
        LOGGER(__name__).info(f"ЁЯУд ╪е╪▒╪│╪з┘Д ┘Е┘Ж ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К: {cache_result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
        
        file_path = cache_result.get('file_path')
        
        if file_path and os.path.exists(file_path):
            # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е┘И╪м┘И╪п
            await message.reply(
                file=file_path,
                message=f"тЬж @{config.BOT_USERNAME}",
                attributes=[
                    DocumentAttributeAudio(
                        duration=cache_result.get('duration', 0),
                        title=cache_result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п'),
                        performer=cache_result.get('artist', 'ZeMusic Bot')
                    )
                ]
            )
            
            await status_msg.delete()
            LOGGER(__name__).info("тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘В╪╖╪╣ ┘Е┘Ж ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К ╪и┘Ж╪м╪з╪н")
            return True
            
        else:
            LOGGER(__name__).warning("тЪая╕П ┘Е┘Д┘Б ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К ╪║┘К╪▒ ┘Е┘И╪м┘И╪п")
            return False
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К: {e}")
        return False

async def send_telegram_cached_audio(message, telegram_result: Dict, status_msg) -> bool:
    """╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘В╪╖╪╣ ╪з┘Д╪╡┘И╪к┘К ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    try:
        LOGGER(__name__).info(f"ЁЯУд ╪е╪▒╪│╪з┘Д ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {telegram_result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п')}")
        
        message_id = telegram_result.get('message_id')
        file_id = telegram_result.get('file_id')
        
        if file_id:
            # ╪е╪▒╪│╪з┘Д ╪и┘А file_id
            await message.reply(
                file=file_id,
                message=f"тЬж @{config.BOT_USERNAME}",
                attributes=[
                    DocumentAttributeAudio(
                        duration=telegram_result.get('duration', 0),
                        title=telegram_result.get('title', '╪║┘К╪▒ ┘Е╪н╪п╪п'),
                        performer=telegram_result.get('artist', 'ZeMusic Bot')
                    )
                ]
            )
            
            await status_msg.delete()
            LOGGER(__name__).info("тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘В╪╖╪╣ ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪и┘Ж╪м╪з╪н")
            return True
            
        elif message_id:
            # ╪е╪╣╪з╪п╪й ╪к┘И╪м┘К┘З ╪з┘Д╪▒╪│╪з┘Д╪й
            import config
            cache_channel = config.CACHE_CHANNEL_ID
            
            await message.client.forward_messages(
                entity=message.chat_id,
                messages=message_id,
                from_peer=cache_channel
            )
            
            await status_msg.delete()
            LOGGER(__name__).info("тЬЕ ╪к┘Е ╪е╪╣╪з╪п╪й ╪к┘И╪м┘К┘З ╪з┘Д┘Е┘В╪╖╪╣ ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪и┘Ж╪м╪з╪н")
            return True
            
        else:
            LOGGER(__name__).warning("тЪая╕П ┘Д╪з ┘К┘И╪м╪п file_id ╪г┘И message_id ╪╡╪з┘Д╪н")
            return False
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ┘Е┘Ж ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {e}")
        return False

async def smart_download_and_send(message, video_info: Dict, status_msg) -> bool:
    """╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ┘Е╪╣ cookies ┘И╪н┘Б╪╕ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ╪п┘В┘К┘В╪й"""
    start_time = time.time()
    downloaded_file = None
    
    try:
        LOGGER(__name__).info(f"тмЗя╕П ╪и╪п╪б ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ┘Е╪к┘В╪п┘Е╪й")
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п ┘Е┘Д┘Б ┘Е╪н┘Е┘Д ┘Е┘Ж ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖
        if video_info.get('source') == 'hybrid_api_ytdlp' and video_info.get('file_path'):
            hybrid_file_path = video_info.get('file_path')
            if os.path.exists(hybrid_file_path):
                LOGGER(__name__).info(f"тЬЕ ╪з╪│╪к╪о╪п╪з┘Е ┘Е┘Д┘Б ┘Е╪н┘Е┘Д ┘Е┘Ж ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖: {hybrid_file_path}")
                try:
                    # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е╪и╪з╪┤╪▒╪й
                    await status_msg.edit("ЁЯУд **╪м╪з╪▒┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д...**")
                    
                    # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Е┘Д┘Б
                    file_size = os.path.getsize(hybrid_file_path)
                    duration = get_audio_duration(hybrid_file_path) if os.path.exists(hybrid_file_path) else 0
                    
                    # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б
                    sent_message = await message.reply_audio(
                        audio=hybrid_file_path,
                        caption=f"ЁЯО╡ **{video_info.get('title', '╪г╪║┘Ж┘К╪й')}**\nЁЯСд **{video_info.get('channel', '┘В┘Ж╪з╪й')}**",
                        duration=duration,
                        title=video_info.get('title', '╪г╪║┘Ж┘К╪й'),
                        performer=video_info.get('channel', '┘В┘Ж╪з╪й')
                    )
                    
                    if sent_message:
                        # ╪н┘Б╪╕ ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
                        await save_to_database_enhanced(
                            video_info.get('title', '╪г╪║┘Ж┘К╪й'),
                            video_info.get('id', ''),
                            sent_message.audio.file_id,
                            duration,
                            video_info.get('channel', '┘В┘Ж╪з╪й'),
                            video_info.get('thumbnail', ''),
                            hybrid_file_path
                        )
                        
                        await status_msg.delete()
                        LOGGER(__name__).info("тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ┘Е┘Ж ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д┘Е╪о╪к┘Д╪╖ ╪и┘Ж╪м╪з╪н")
                        return True
                        
                except Exception as e:
                    LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪о╪к┘Д╪╖: {e}")
                    # ╪з┘Д┘Е╪к╪з╪и╪╣╪й ┘Д┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪к┘В┘Д┘К╪п┘К
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪╡╪н╪й ╪з┘Д┘Е╪п╪о┘Д╪з╪к
        if not video_info or not isinstance(video_info, dict):
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Б┘К╪п┘К┘И ╪║┘К╪▒ ╪╡╪н┘К╪н╪й")
            return False
            
        if not message:
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ┘Г╪з╪ж┘Ж ╪з┘Д╪▒╪│╪з┘Д╪й ╪║┘К╪▒ ┘Е╪к╪з╪н")
            return False
            
        if not status_msg:
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й ╪║┘К╪▒ ┘Е╪к╪з╪н╪й")
            return False
        
        # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е╪╣ ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪з┘Д╪╡╪н╪й
        title = video_info.get('title', '╪г╪║┘Ж┘К╪й ╪║┘К╪▒ ┘Е╪н╪п╪п╪й').strip()
        video_id = video_info.get('id', '').strip()
        duration_text = video_info.get('duration', '0:00').strip()
        channel = video_info.get('channel', '┘В┘Ж╪з╪й ╪║┘К╪▒ ┘Е╪н╪п╪п╪й').strip()
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ┘И╪м┘И╪п video_id
        if not video_id:
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ┘Е╪╣╪▒┘Б ╪з┘Д┘Б┘К╪п┘К┘И ┘Е┘Б┘В┘И╪п")
            return False
        
        LOGGER(__name__).info(
            f"ЁЯУЛ ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д╪к╪н┘Е┘К┘Д:\n"
            f"   ЁЯО╡ ╪з┘Д╪╣┘Ж┘И╪з┘Ж: {title}\n"
            f"   ЁЯЖФ ╪з┘Д┘Е╪╣╪▒┘Б: {video_id}\n"
            f"   ЁЯСд ╪з┘Д┘В┘Ж╪з╪й: {channel}\n"
            f"   тП▒я╕П ╪з┘Д┘Е╪п╪й: {duration_text}"
        )
        
        # ╪к╪н┘И┘К┘Д ╪з┘Д┘Е╪п╪й ╪е┘Д┘Й ╪л┘И╪з┘Ж ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б
        duration = 0
        try:
            if ':' in duration_text:
                parts = duration_text.split(':')
                if len(parts) == 2:
                    duration = int(parts[0]) * 60 + int(parts[1])
                elif len(parts) == 3:
                    duration = int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
                    
                LOGGER(__name__).debug(f"тП▒я╕П ╪к┘Е ╪к╪н┘И┘К┘Д ╪з┘Д┘Е╪п╪й: {duration_text} тЖТ {duration} ╪л╪з┘Ж┘К╪й")
                
        except (ValueError, IndexError) as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к╪н┘И┘К┘Д ╪з┘Д┘Е╪п╪й '{duration_text}': {e}")
            duration = 0
        
        # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪к┘И┘Б╪▒ yt-dlp
        if not yt_dlp:
            LOGGER(__name__).error("тЭМ ╪о╪╖╪г: ┘Е┘Г╪к╪и╪й yt-dlp ╪║┘К╪▒ ┘Е╪к╪з╪н╪й")
            return False
        
        # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е┘Д┘Б cookies ┘Е╪╣ ┘Е╪╣╪з┘Д╪м╪й ╪г╪о╪╖╪з╪б ╪п┘В┘К┘В╪й
        cookie_file = None
        try:
            await status_msg.edit("ЁЯНк **╪м╪з╪▒┘К ╪к╪н╪╢┘К╪▒ ╪з┘Д╪к╪н┘Е┘К┘Д...**")
            LOGGER(__name__).debug("ЁЯНк ┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е┘Д┘Б cookies")
            
            # ╪з┘Д╪и╪н╪л ╪з┘Д┘Е╪и╪з╪┤╪▒ ╪╣┘Ж ┘Е┘Д┘Б╪з╪к cookies
            cookies_dir = Path("cookies")
            if cookies_dir.exists():
                cookie_files = list(cookies_dir.glob("*.txt"))
                if cookie_files:
                    # ╪з╪о╪к┘К╪з╪▒ ┘Е┘Д┘Б ╪╣╪┤┘И╪з╪ж┘К
                    cookie_file = str(cookie_files[0])  # ╪г┘И┘Д ┘Е┘Д┘Б ┘Е╪к╪з╪н
                    
                    if os.path.exists(cookie_file):
                        file_size = os.path.getsize(cookie_file)
                        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е┘Д┘Б cookies: {cookie_file} ({file_size} bytes)")
                    else:
                        LOGGER(__name__).warning("тЪая╕П ┘Е┘Д┘Б cookies ╪║┘К╪▒ ┘Е┘И╪м┘И╪п")
                        cookie_file = None
                else:
                    LOGGER(__name__).warning("тЪая╕П ┘Д╪з ╪к┘И╪м╪п ┘Е┘Д┘Б╪з╪к cookies ┘Б┘К ╪з┘Д┘Е╪м┘Д╪п")
                    cookie_file = None
            else:
                LOGGER(__name__).warning("тЪая╕П ┘Е╪м┘Д╪п cookies ╪║┘К╪▒ ┘Е┘И╪м┘И╪п")
                cookie_file = None
            
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й cookies: {e}")
            cookie_file = None
        
        # ╪е╪╣╪п╪з╪п ┘Е╪м┘Д╪п ╪з┘Д╪к╪н┘Е┘К┘Д╪з╪к ┘Е╪╣ ╪з┘Д╪к╪н┘В┘В
        try:
            downloads_dir = Path("downloads")
            downloads_dir.mkdir(exist_ok=True)
            LOGGER(__name__).debug(f"ЁЯУБ ┘Е╪м┘Д╪п ╪з┘Д╪к╪н┘Е┘К┘Д╪з╪к ╪м╪з┘З╪▓: {downloads_dir.absolute()}")
            
            # ╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪з┘Д╪╡┘Д╪з╪н┘К╪з╪к
            if not os.access(downloads_dir, os.W_OK):
                LOGGER(__name__).error("тЭМ ┘Д╪з ╪к┘И╪м╪п ╪╡┘Д╪з╪н┘К╪й ┘Г╪к╪з╪и╪й ┘Б┘К ┘Е╪м┘Д╪п ╪з┘Д╪к╪н┘Е┘К┘Д╪з╪к")
                return False
                
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪╣╪п╪з╪п ┘Е╪м┘Д╪п ╪з┘Д╪к╪н┘Е┘К┘Д╪з╪к: {e}")
            return False
        
        # ╪е╪╣╪п╪з╪п╪з╪к ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Е╪н╪│┘Ж╪й ┘Е╪╣ ╪к╪н┘И┘К┘Д ╪е┘Д┘Й MP3
        try:
            ydl_opts = get_ytdlp_opts(cookie_file)
            ydl_opts['outtmpl'] = f'downloads/{video_id}.%(ext)s'
            
            # ╪е╪╢╪з┘Б╪й cookies ╪е╪░╪з ┘Г╪з┘Ж ┘Е╪к╪з╪н╪з┘Л
            if cookie_file and os.path.exists(cookie_file):
                ydl_opts['cookiefile'] = cookie_file
                LOGGER(__name__).info("ЁЯНк ╪к┘Е ╪е╪╢╪з┘Б╪й ┘Е┘Д┘Б cookies ┘Д╪е╪╣╪п╪з╪п╪з╪к ╪з┘Д╪к╪н┘Е┘К┘Д")
            else:
                LOGGER(__name__).info("ЁЯЪл ╪з┘Д╪к╪н┘Е┘К┘Д ╪и╪п┘И┘Ж cookies")
            
            LOGGER(__name__).debug(f"тЪЩя╕П ╪е╪╣╪п╪з╪п╪з╪к yt-dlp: {ydl_opts}")
            
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪╣╪п╪з╪п ╪о┘К╪з╪▒╪з╪к ╪з┘Д╪к╪н┘Е┘К┘Д: {e}")
            return False
        
        # ╪к╪н╪п┘К╪л ╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й
        try:
            await status_msg.edit("ЁЯУе **╪м╪з╪▒┘К ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е┘Ж YouTube...**")
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к╪н╪п┘К╪л ╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й: {e}")
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                video_url = f"https://www.youtube.com/watch?v={video_id}"
                info = ydl.extract_info(video_url, download=True)
                
                # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д
                downloaded_file = None
                for ext in ['mp3', 'webm', 'm4a', 'ogg', 'opus']:
                    file_path = f'downloads/{video_id}.{ext}'
                    if os.path.exists(file_path):
                        downloaded_file = file_path
                        break
                
                if not downloaded_file:
                    LOGGER(__name__).error("тЭМ ┘Д┘Е ┘К╪к┘Е ╪з┘Д╪╣╪л┘И╪▒ ╪╣┘Д┘Й ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д")
                    return False
                
                # ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                thumb_path = None
                try:
                    if info and 'thumbnail' in info and info['thumbnail']:
                        thumb_path = await download_thumbnail(info['thumbnail'], title, video_id)
                    elif info and 'thumbnails' in info and info['thumbnails']:
                        # ╪г╪о╪░ ╪г┘Б╪╢┘Д ╪м┘И╪п╪й ┘Е╪к╪з╪н╪й
                        best_thumb = None
                        for thumb in info['thumbnails']:
                            if thumb.get('url'):
                                best_thumb = thumb['url']
                        if best_thumb:
                            thumb_path = await download_thumbnail(best_thumb, title, video_id)
                except Exception as thumb_error:
                    LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {thumb_error}")
                
                # ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б
                await status_msg.edit("ЁЯУд **╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                
                try:
                    LOGGER(__name__).info(f"ЁЯУд ┘Е╪н╪з┘И┘Д╪й ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б: {downloaded_file}")
                    audio_message = await message.reply(
                        file=downloaded_file,
                        message=f"тЬж @{config.BOT_USERNAME}",
                        thumb=thumb_path,
                        attributes=[
                            DocumentAttributeAudio(
                                duration=duration,
                                title=title,
                                performer=channel
                            )
                        ]
                    )
                    LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б ╪и┘Ж╪м╪з╪н: {audio_message.id}")
                except Exception as send_error:
                    LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪е╪▒╪│╪з┘Д ╪з┘Д┘Е┘Д┘Б: {send_error}")
                    raise send_error
                
                # ╪н┘Б╪╕ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ┘Д┘Д╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д┘Е╪│╪к┘В╪и┘Д┘К
                await save_to_cache(video_id, title, channel, duration, downloaded_file, audio_message, thumb_path)
                
                # ╪н╪░┘Б ╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й
                try:
                    await status_msg.delete()
                except:
                    pass
                
                # ╪н╪░┘Б ╪з┘Д┘Е┘Д┘Б╪з╪к ╪з┘Д┘Е╪д┘В╪к╪й
                try:
                    os.remove(downloaded_file)
                except:
                    pass
                
                # ╪н╪░┘Б ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                if thumb_path and os.path.exists(thumb_path):
                    try:
                        os.remove(thumb_path)
                    except:
                        pass
                
                LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ┘И╪н┘Б╪╕ ╪з┘Д╪г╪║┘Ж┘К╪й: {title}")
                return True
                
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ┘Е╪╣ cookies: {e}")
            
            # ┘Е╪н╪з┘И┘Д╪й ╪и╪п┘И┘Ж cookies
            LOGGER(__name__).info("ЁЯФД ┘Е╪н╪з┘И┘Д╪й ╪з┘Д╪к╪н┘Е┘К┘Д ╪и╪п┘И┘Ж cookies...")
            await status_msg.edit("ЁЯФД **┘Е╪н╪з┘И┘Д╪й ╪и╪п┘К┘Д╪й...**")
            
            try:
                ydl_opts_no_cookies = get_ytdlp_opts()
                ydl_opts_no_cookies['outtmpl'] = f'downloads/{video_id}_nocookies.%(ext)s'
                
                with yt_dlp.YoutubeDL(ydl_opts_no_cookies) as ydl:
                    video_url = f"https://www.youtube.com/watch?v={video_id}"
                    info = ydl.extract_info(video_url, download=True)
                    
                    # ╪з┘Д╪и╪н╪л ╪╣┘Ж ╪з┘Д┘Е┘Д┘Б ╪з┘Д┘Е╪н┘Е┘Д
                    downloaded_file = None
                    for ext in ['mp3', 'webm', 'm4a', 'ogg', 'opus']:
                        file_path = f'downloads/{video_id}_nocookies.{ext}'
                        if os.path.exists(file_path):
                            downloaded_file = file_path
                            break
                    
                    if downloaded_file:
                        # ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                        thumb_path = None
                        try:
                            if info and 'thumbnail' in info and info['thumbnail']:
                                thumb_path = await download_thumbnail(info['thumbnail'], title, video_id)
                            elif info and 'thumbnails' in info and info['thumbnails']:
                                # ╪г╪о╪░ ╪г┘Б╪╢┘Д ╪м┘И╪п╪й ┘Е╪к╪з╪н╪й
                                best_thumb = None
                                for thumb in info['thumbnails']:
                                    if thumb.get('url'):
                                        best_thumb = thumb['url']
                                if best_thumb:
                                    thumb_path = await download_thumbnail(best_thumb, title, video_id)
                        except Exception as thumb_error:
                            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к╪н┘Е┘К┘Д ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й: {thumb_error}")
                        
                        await status_msg.edit("ЁЯУд **╪м╪з╪▒┘К ╪з┘Д╪е╪▒╪│╪з┘Д...**")
                        
                        audio_message = await message.reply(
                            file=downloaded_file,
                            message=f"тЬж @{config.BOT_USERNAME}",
                            thumb=thumb_path,
                            attributes=[
                                DocumentAttributeAudio(
                                    duration=duration,
                                    title=title,
                                    performer=channel
                                )
                            ]
                        )
                        
                        # ╪н┘Б╪╕ ┘Б┘К ╪з┘Д┘Г╪з╪┤
                        await save_to_cache(video_id, title, channel, duration, downloaded_file, audio_message, thumb_path)
                        
                        try:
                            await status_msg.delete()
                        except:
                            pass
                        
                        try:
                            os.remove(downloaded_file)
                        except:
                            pass
                        
                        # ╪н╪░┘Б ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                        if thumb_path and os.path.exists(thumb_path):
                            try:
                                os.remove(thumb_path)
                            except:
                                pass
                        
                        LOGGER(__name__).info(f"тЬЕ ╪к┘Е ╪е╪▒╪│╪з┘Д ╪з┘Д╪г╪║┘Ж┘К╪й ╪и╪п┘И┘Ж cookies: {title}")
                        return True
                        
            except Exception as e2:
                LOGGER(__name__).error(f"тЭМ ┘Б╪┤┘Д ╪з┘Д╪к╪н┘Е┘К┘Д ╪и╪п┘И┘Ж cookies ╪г┘К╪╢╪з┘Л: {e2}")
                return False
        
        return False
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ╪╣╪з┘Е ┘Б┘К ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К: {e}")
        return False

async def save_to_cache(video_id: str, title: str, artist: str, duration: int, file_path: str, audio_message, thumb_path: str = None) -> bool:
    """╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ╪з┘Д┘Г╪з╪┤ ╪з┘Д┘Е╪н┘Д┘К ┘И┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    try:
        LOGGER(__name__).info(f"ЁЯТ╛ ╪н┘Б╪╕ ┘Б┘К ╪з┘Д┘Г╪з╪┤: {title}")
        
        # ╪н┘Б╪╕ ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н┘Д┘К╪й
        try:
            conn = sqlite3.connect(DATABASE_PATH)
            cursor = conn.cursor()
            
            # ╪е╪п╪▒╪з╪м ╪г┘И ╪к╪н╪п┘К╪л ╪з┘Д╪│╪м┘Д
            cursor.execute("""
                INSERT OR REPLACE INTO cached_audio 
                (video_id, title, artist, duration, file_path, thumb, message_id, keywords, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
            """, (
                video_id,
                title,
                artist,
                duration,
                file_path,
                None,  # thumb
                getattr(audio_message, 'id', None),
                f"{title} {artist}".lower(),  # keywords
            ))
            
            conn.commit()
            conn.close()
            
            LOGGER(__name__).info("тЬЕ ╪к┘Е ╪н┘Б╪╕ ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е╪н┘Д┘К╪й")
            
        except Exception as e:
            LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {e}")
        
        # ╪н┘Б╪╕ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж (╪е╪░╪з ┘Г╪з┘Ж╪к ┘Е╪к╪з╪н╪й)
        try:
            import config
            from ZeMusic.core.telethon_client import telethon_manager
            
            if hasattr(config, 'CACHE_CHANNEL_ID') and config.CACHE_CHANNEL_ID:
                LOGGER(__name__).info(f"ЁЯТ╛ ╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж...")
                
                # ╪е╪╣╪п╪з╪п ╪и┘К╪з┘Ж╪з╪к ╪з┘Д┘Е┘В╪╖╪╣ ┘Д┘Д╪н┘Б╪╕
                result_data = {
                    'title': title,
                    'uploader': artist,
                    'duration': duration,
                    'source': 'YouTube',
                    'elapsed': 0
                }
                
                # ╪н┘Б╪╕ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪и╪з╪│╪к╪о╪п╪з┘Е save_to_smart_cache
                if telethon_manager and telethon_manager.bot_client:
                    saved = await save_to_smart_cache(
                        telethon_manager.bot_client, 
                        file_path, 
                        result_data, 
                        f"{title} {artist}",
                        thumb_path  # ╪к┘Е╪▒┘К╪▒ ╪з┘Д╪╡┘И╪▒╪й ╪з┘Д┘Е╪╡╪║╪▒╪й
                    )
                    if saved:
                        LOGGER(__name__).info("тЬЕ ╪к┘Е ╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж")
                    else:
                        LOGGER(__name__).warning("тЪая╕П ┘Б╪┤┘Д ╪н┘Б╪╕ ╪з┘Д┘Е┘В╪╖╪╣ ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж")
                
        except Exception as e:
            LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {e}")
        
        return True
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪н┘Б╪╕ ╪з┘Д┘Г╪з╪┤: {e}")
        return False

LOGGER(__name__).info("ЁЯЪА ╪к┘Е ╪к╪н┘Е┘К┘Д ┘Ж╪╕╪з┘Е ╪з┘Д╪к╪н┘Е┘К┘Д ╪з┘Д╪░┘Г┘К ╪з┘Д╪о╪з╪▒┘В ╪з┘Д┘Е╪к╪╖┘И╪▒ V2")

# ╪е╪╢╪з┘Б╪й ┘Ж╪╕╪з┘Е ╪з┘Д┘Б╪н╪╡ ╪з┘Д╪п┘И╪▒┘К ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
LAST_CHANNEL_SYNC = 0
CHANNEL_SYNC_INTERVAL = 3600  # ┘Г┘Д ╪│╪з╪╣╪й

async def sync_channel_to_database(bot_client, force_sync: bool = False) -> Dict:
    """┘Е╪▓╪з┘Е┘Ж╪й ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Е╪╣ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪и╪┤┘Г┘Д ╪░┘Г┘К"""
    global LAST_CHANNEL_SYNC
    
    current_time = time.time()
    
    # ┘Б╪н╪╡ ╪з┘Д╪н╪з╪м╪й ┘Д┘Д┘Е╪▓╪з┘Е┘Ж╪й
    if not force_sync and (current_time - LAST_CHANNEL_SYNC) < CHANNEL_SYNC_INTERVAL:
        return {'skipped': True, 'reason': '┘Д┘Е ╪к╪н┘Ж ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й ╪и╪╣╪п'}
    
    try:
        import config
        
        if not hasattr(config, 'CACHE_CHANNEL_ID') or not config.CACHE_CHANNEL_ID:
            return {'error': '┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪║┘К╪▒ ┘Е╪н╪п╪п╪й'}
        
        cache_channel = config.CACHE_CHANNEL_ID
        LOGGER(__name__).info(f"тЪая╕П ┘Е╪▓╪з┘Е┘Ж╪й ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Е╪╣╪╖┘Д╪й ┘Е╪д┘В╪к╪з┘Л (┘В┘К┘И╪п API ┘Д┘Д╪и┘И╪к╪з╪к)")
        return {'error': '┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д┘В┘Ж╪з╪й ┘Е╪╣╪╖┘Д╪й ┘Е╪д┘В╪к╪з┘Л'}
        
        # ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й
        sync_stats = {
            'processed': 0,
            'added': 0,
            'updated': 0,
            'errors': 0,
            'start_time': current_time
        }
        
        # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ╪в╪о╪▒ message_id ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        
        cursor.execute("SELECT MAX(message_id) FROM channel_index")
        last_db_message_id = cursor.fetchone()[0] or 0
        
        LOGGER(__name__).info(f"ЁЯУК ╪в╪о╪▒ ╪▒╪│╪з┘Д╪й ┘Б┘К ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к: {last_db_message_id}")
        
        # ┘Б╪н╪╡ ╪з┘Д╪▒╪│╪з╪ж┘Д ╪з┘Д╪м╪п┘К╪п╪й ┘Б┘К ╪з┘Д┘В┘Ж╪з╪й
        new_messages_found = 0
        batch_size = 100
        
        async for message in bot_client.iter_messages(cache_channel, limit=1000):
            if not (message.text and message.file):
                continue
                
            sync_stats['processed'] += 1
            
            # ╪к╪о╪╖┘К ╪з┘Д╪▒╪│╪з╪ж┘Д ╪з┘Д┘Е┘И╪м┘И╪п╪й ╪и╪з┘Д┘Б╪╣┘Д
            if message.id <= last_db_message_id:
                continue
                
            new_messages_found += 1
            
            try:
                # ╪з╪│╪к╪о╪▒╪з╪м ╪з┘Д┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е┘Ж ╪з┘Д╪▒╪│╪з┘Д╪й
                title = extract_title_from_cache_text(message.text)
                uploader = extract_uploader_from_cache_text(message.text)
                duration = extract_duration_from_cache_text(message.text)
                
                # ╪з╪│╪к╪о╪▒╪з╪м ┘З╪з╪┤ ╪з┘Д╪и╪н╪л ┘Е┘Ж ╪з┘Д┘Ж╪╡ ╪е┘Ж ┘И╪м╪п
                import re
                hash_match = re.search(r'┘З╪з╪┤ ╪з┘Д╪и╪н╪л.*?`([a-f0-9]+)`', message.text)
                search_hash = hash_match.group(1) if hash_match else None
                
                # ╪е┘Ж╪┤╪з╪б ┘З╪з╪┤ ╪м╪п┘К╪п ╪е╪░╪з ┘Д┘Е ┘К┘И╪м╪п
                if not search_hash:
                    title_normalized = normalize_search_text(title)
                    uploader_normalized = normalize_search_text(uploader)
                    search_data = f"{title_normalized}|{uploader_normalized}"
                    search_hash = hashlib.md5(search_data.encode()).hexdigest()[:12]
                
                # ╪к╪╖╪и┘К╪╣ ╪з┘Д┘Ж╪╡┘И╪╡
                title_normalized = normalize_search_text(title)
                uploader_normalized = normalize_search_text(uploader)
                
                # ╪е┘Ж╪┤╪з╪б vector ╪з┘Д┘Г┘Д┘Е╪з╪к ╪з┘Д┘Е┘Б╪к╪з╪н┘К╪й
                keywords_vector = f"{title_normalized} {uploader_normalized}"
                
                # ┘Б╪н╪╡ ┘И╪м┘И╪п ╪з┘Д╪│╪м┘Д
                cursor.execute("SELECT id FROM channel_index WHERE message_id = ?", (message.id,))
                existing = cursor.fetchone()
                
                if existing:
                    # ╪к╪н╪п┘К╪л ╪з┘Д╪│╪м┘Д
                    cursor.execute("""
                        UPDATE channel_index 
                        SET file_id = ?, title_normalized = ?, artist_normalized = ?, 
                            keywords_vector = ?, original_title = ?, original_artist = ?, 
                            duration = ?, file_size = ?, search_hash = ?
                        WHERE message_id = ?
                    """, (
                        message.file.id, title_normalized, uploader_normalized,
                        keywords_vector, title, uploader, duration,
                        message.file.size or 0, search_hash, message.id
                    ))
                    sync_stats['updated'] += 1
                else:
                    # ╪е╪╢╪з┘Б╪й ╪│╪м┘Д ╪м╪п┘К╪п
                    cursor.execute("""
                        INSERT INTO channel_index 
                        (message_id, file_id, file_unique_id, search_hash, title_normalized, 
                         artist_normalized, keywords_vector, original_title, original_artist, 
                         duration, file_size, access_count, popularity_rank)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 0, 0.5)
                    """, (
                        message.id, message.file.id, getattr(message.file, 'unique_id', None),
                        search_hash, title_normalized, uploader_normalized, keywords_vector,
                        title, uploader, duration, message.file.size or 0
                    ))
                    sync_stats['added'] += 1
                
                # ╪н┘Б╪╕ ╪╣┘Д┘Й ╪п┘Б╪╣╪з╪к
                if sync_stats['processed'] % batch_size == 0:
                    conn.commit()
                    LOGGER(__name__).info(f"ЁЯТ╛ ╪к┘Е ╪н┘Б╪╕ ╪п┘Б╪╣╪й: {sync_stats['processed']} ╪▒╪│╪з┘Д╪й ┘Е╪╣╪з┘Д╪м╪й")
                
            except Exception as msg_error:
                sync_stats['errors'] += 1
                LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ┘Е╪╣╪з┘Д╪м╪й ╪▒╪│╪з┘Д╪й {message.id}: {msg_error}")
                continue
        
        # ╪н┘Б╪╕ ┘Ж┘З╪з╪ж┘К
        conn.commit()
        conn.close()
        
        # ╪к╪н╪п┘К╪л ┘И┘В╪к ╪в╪о╪▒ ┘Е╪▓╪з┘Е┘Ж╪й
        LAST_CHANNEL_SYNC = current_time
        
        # ╪н╪│╪з╪и ╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Ж┘З╪з╪ж┘К╪й
        sync_stats['duration'] = time.time() - current_time
        sync_stats['new_messages'] = new_messages_found
        
        LOGGER(__name__).info(
            f"тЬЕ ╪з┘Г╪к┘Е┘Д╪к ┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д┘В┘Ж╪з╪й: "
            f"┘Е╪╣╪з┘Д╪м={sync_stats['processed']} | "
            f"╪м╪п┘К╪п={sync_stats['added']} | "
            f"┘Е╪н╪п╪л={sync_stats['updated']} | "
            f"╪г╪о╪╖╪з╪б={sync_stats['errors']} | "
            f"┘Е╪п╪й={sync_stats['duration']:.2f}s"
        )
        
        return sync_stats
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д┘В┘Ж╪з╪й: {e}")
        return {'error': str(e)}

async def auto_sync_channel_if_needed(bot_client):
    """┘Б╪н╪╡ ╪к┘Д┘В╪з╪ж┘К ┘Д┘Д╪н╪з╪м╪й ┘Д┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д┘В┘Ж╪з╪й"""
    try:
        # ┘Б╪н╪╡ ╪в╪о╪▒ ┘Е╪▓╪з┘Е┘Ж╪й
        current_time = time.time()
        if (current_time - LAST_CHANNEL_SYNC) > CHANNEL_SYNC_INTERVAL:
            LOGGER(__name__).info("ЁЯФД ╪и╪п╪б ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д╪к┘Д┘В╪з╪ж┘К╪й ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж...")
            
            # ╪к╪┤╪║┘К┘Д ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й ┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й
            asyncio.create_task(sync_channel_to_database(bot_client, force_sync=False))
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д╪к┘Д┘В╪з╪ж┘К╪й: {e}")

async def force_channel_sync_handler(event):
    """┘Е╪╣╪з┘Д╪м ╪г┘Е╪▒ ╪з┘Д┘Е╪╖┘И╪▒ ┘Д╪е╪м╪и╪з╪▒ ┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д┘В┘Ж╪з╪й"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        await event.reply("ЁЯФД **╪и╪п╪б ┘Е╪▓╪з┘Е┘Ж╪й ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж...**")
        
        result = await sync_channel_to_database(event.client, force_sync=True)
        
        if 'error' in result:
            await event.reply(f"тЭМ **╪о╪╖╪г ┘Б┘К ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й:** {result['error']}")
        elif 'skipped' in result:
            await event.reply(f"тПня╕П **╪к┘Е ╪к╪о╪╖┘К ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й:** {result['reason']}")
        else:
            response = f"""тЬЕ **╪з┘Г╪к┘Е┘Д╪к ┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д┘В┘Ж╪з╪й!**

ЁЯУК **╪з┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к:**
тАв ╪▒╪│╪з╪ж┘Д ┘Е╪╣╪з┘Д╪м╪й: {result['processed']}
тАв ╪│╪м┘Д╪з╪к ╪м╪п┘К╪п╪й: {result['added']}
тАв ╪│╪м┘Д╪з╪к ┘Е╪н╪п╪л╪й: {result['updated']}
тАв ╪г╪о╪╖╪з╪б: {result['errors']}
тАв ╪▒╪│╪з╪ж┘Д ╪м╪п┘К╪п╪й: {result['new_messages']}
тАв ╪з┘Д┘Е╪п╪й: {result['duration']:.2f}s

ЁЯТ╛ ╪к┘Е ╪к╪н╪п┘К╪л ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪и┘Ж╪м╪з╪н"""
            
            await event.reply(response)
        
    except Exception as e:
        await event.reply(f"тЭМ **╪о╪╖╪г:** {e}")

# ╪к╪н╪п┘К╪л ┘Е╪╣╪з┘Д╪м ╪з┘Д╪и╪н╪л ┘Д┘К╪┤┘Е┘Д ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д╪к┘Д┘В╪з╪ж┘К╪й

# ╪е╪╢╪з┘Б╪й ╪п╪з┘Д╪й ┘Б╪н╪╡ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
async def verify_cache_channel(bot_client) -> Dict:
    """┘Б╪н╪╡ ┘И╪з┘Д╪к╪н┘В┘В ┘Е┘Ж ╪╡╪н╪й ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    try:
        import config
        
        # ┘Б╪н╪╡ ┘И╪м┘И╪п ╪з┘Д╪к╪╣╪▒┘К┘Б
        if not hasattr(config, 'CACHE_CHANNEL_ID') or not config.CACHE_CHANNEL_ID:
            return {
                'status': 'error',
                'message': '┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪║┘К╪▒ ┘Е╪н╪п╪п╪й ┘Б┘К config.py',
                'solution': '╪к╪г┘Г╪п ┘Е┘Ж ╪к╪╣┘К┘К┘Ж CACHE_CHANNEL_USERNAME ┘Б┘К ┘Е╪к╪║┘К╪▒╪з╪к ╪з┘Д╪и┘К╪ж╪й'
            }
        
        cache_channel = config.CACHE_CHANNEL_ID
        
        # ┘Б╪н╪╡ ┘Ж┘И╪╣ ╪з┘Д┘Е╪╣╪▒┘Б
        channel_type = "unknown"
        if cache_channel.startswith('@'):
            channel_type = "username"
        elif cache_channel.startswith('-100'):
            channel_type = "supergroup_id"
        elif cache_channel.startswith('-'):
            channel_type = "group_id"
        elif cache_channel.isdigit():
            channel_type = "user_id"
        
        LOGGER(__name__).info(f"ЁЯФН ┘Б╪н╪╡ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {cache_channel} (┘Ж┘И╪╣: {channel_type})")
        
        # ┘Е╪н╪з┘И┘Д╪й ╪з┘Д┘И╪╡┘И┘Д ┘Д┘Д┘В┘Ж╪з╪й
        try:
            entity = await bot_client.get_entity(cache_channel)
            
            # ╪з┘Д╪н╪╡┘И┘Д ╪╣┘Д┘Й ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘В┘Ж╪з╪й
            channel_info = {
                'status': 'success',
                'channel_id': cache_channel,
                'channel_type': channel_type,
                'entity_id': entity.id,
                'title': getattr(entity, 'title', 'Unknown'),
                'username': getattr(entity, 'username', None),
                'participants_count': getattr(entity, 'participants_count', 0),
                'is_channel': hasattr(entity, 'broadcast'),
                'is_megagroup': getattr(entity, 'megagroup', False),
                'access_hash': getattr(entity, 'access_hash', None)
            }
            
            # ┘Б╪н╪╡ ╪╡┘Д╪з╪н┘К╪з╪к ╪з┘Д╪е╪▒╪│╪з┘Д
            try:
                # ┘Е╪н╪з┘И┘Д╪й ╪е╪▒╪│╪з┘Д ╪▒╪│╪з┘Д╪й ╪з╪о╪к╪и╪з╪▒
                test_message = await bot_client.send_message(
                    entity, 
                    "ЁЯзк **╪з╪о╪к╪и╪з╪▒ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К**\n\nтЬЕ ╪з┘Д╪и┘И╪к ┘К┘Е┘Г┘Ж┘З ╪з┘Д╪е╪▒╪│╪з┘Д ╪и┘Ж╪м╪з╪н!\n\nЁЯЧСя╕П ╪│┘К╪к┘Е ╪н╪░┘Б ┘З╪░┘З ╪з┘Д╪▒╪│╪з┘Д╪й ╪о┘Д╪з┘Д 10 ╪л┘И╪з┘Ж..."
                )
                
                # ╪н╪░┘Б ╪з┘Д╪▒╪│╪з┘Д╪й ╪и╪╣╪п 10 ╪л┘И╪з┘Ж
                await asyncio.sleep(10)
                await test_message.delete()
                
                channel_info['can_send'] = True
                channel_info['permissions'] = 'full'
                
            except Exception as perm_error:
                channel_info['can_send'] = False
                channel_info['permissions'] = 'limited'
                channel_info['permission_error'] = str(perm_error)
            
            # ┘Б╪н╪╡ ╪╣╪п╪п ╪з┘Д╪▒╪│╪з╪ж┘Д ╪з┘Д┘Е┘И╪м┘И╪п╪й
            try:
                message_count = 0
                audio_count = 0
                
                async for message in bot_client.iter_messages(entity, limit=100):
                    message_count += 1
                    if message.file and message.file.mime_type and 'audio' in message.file.mime_type:
                        audio_count += 1
                
                channel_info['recent_messages'] = message_count
                channel_info['recent_audio_files'] = audio_count
                
            except Exception as count_error:
                channel_info['recent_messages'] = 0
                channel_info['recent_audio_files'] = 0
                channel_info['count_error'] = str(count_error)
            
            LOGGER(__name__).info(f"тЬЕ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Е╪к╪з╪н╪й: {channel_info['title']}")
            return channel_info
            
        except Exception as access_error:
            return {
                'status': 'error',
                'channel_id': cache_channel,
                'channel_type': channel_type,
                'message': f'┘Д╪з ┘К┘Е┘Г┘Ж ╪з┘Д┘И╪╡┘И┘Д ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {access_error}',
                'solutions': [
                    '╪к╪г┘Г╪п ┘Е┘Ж ╪г┘Ж ╪з┘Д╪и┘И╪к ╪╣╪╢┘И ┘Б┘К ╪з┘Д┘В┘Ж╪з╪й',
                    '╪к╪г┘Г╪п ┘Е┘Ж ╪г┘Ж ╪з┘Д╪и┘И╪к ┘Д╪п┘К┘З ╪╡┘Д╪з╪н┘К╪й ╪з┘Д╪е╪▒╪│╪з┘Д',
                    '╪к╪г┘Г╪п ┘Е┘Ж ╪╡╪н╪й ┘Е╪╣╪▒┘Б/┘К┘И╪▓╪▒ ╪з┘Д┘В┘Ж╪з╪й',
                    '╪к╪г┘Г╪п ┘Е┘Ж ╪г┘Ж ╪з┘Д┘В┘Ж╪з╪й ┘Е┘И╪м┘И╪п╪й ┘И┘Д┘К╪│╪к ┘Е╪н╪░┘И┘Б╪й'
                ]
            }
            
    except Exception as e:
        return {
            'status': 'error',
            'message': f'╪о╪╖╪г ┘Б┘К ┘Б╪н╪╡ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {e}',
            'solution': '╪к╪н┘В┘В ┘Е┘Ж ╪е╪╣╪п╪з╪п╪з╪к config.py'
        }

async def cache_channel_info_handler(event):
    """┘Е╪╣╪з┘Д╪м ╪г┘Е╪▒ ╪з┘Д┘Е╪╖┘И╪▒ ┘Д╪╣╪▒╪╢ ┘Е╪╣┘Д┘И┘Е╪з╪к ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        await event.reply("ЁЯФН **╪м╪з╪▒┘К ┘Б╪н╪╡ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж...**")
        
        # ┘Б╪н╪╡ ╪з┘Д┘В┘Ж╪з╪й
        result = await verify_cache_channel(event.client)
        
        if result['status'] == 'error':
            error_msg = f"тЭМ **╪о╪╖╪г ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж**\n\n"
            error_msg += f"**╪з┘Д┘Е╪┤┘Г┘Д╪й:** {result['message']}\n\n"
            
            if 'solutions' in result:
                error_msg += "**╪з┘Д╪н┘Д┘И┘Д ╪з┘Д┘Е┘В╪к╪▒╪н╪й:**\n"
                for i, solution in enumerate(result['solutions'], 1):
                    error_msg += f"{i}. {solution}\n"
            elif 'solution' in result:
                error_msg += f"**╪з┘Д╪н┘Д:** {result['solution']}\n"
            
            await event.reply(error_msg)
        else:
            # ╪е╪╣╪п╪з╪п ╪▒╪│╪з┘Д╪й ╪з┘Д┘Ж╪м╪з╪н
            success_msg = f"тЬЕ **┘Е╪╣┘Д┘И┘Е╪з╪к ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж**\n\n"
            success_msg += f"ЁЯП╖я╕П **╪з┘Д╪╣┘Ж┘И╪з┘Ж:** {result['title']}\n"
            success_msg += f"ЁЯЖФ **╪з┘Д┘Е╪╣╪▒┘Б:** `{result['channel_id']}`\n"
            success_msg += f"ЁЯФв **ID ╪з┘Д╪н┘В┘К┘В┘К:** `{result['entity_id']}`\n"
            
            if result.get('username'):
                success_msg += f"ЁЯСд **╪з┘Д┘К┘И╪▓╪▒:** @{result['username']}\n"
            
            success_msg += f"ЁЯУК **╪з┘Д┘Ж┘И╪╣:** {result['channel_type']}\n"
            success_msg += f"ЁЯСе **╪з┘Д╪г╪╣╪╢╪з╪б:** {result.get('participants_count', '╪║┘К╪▒ ┘Е╪╣╪▒┘И┘Б')}\n"
            success_msg += f"ЁЯУ║ **┘В┘Ж╪з╪й:** {'┘Ж╪╣┘Е' if result.get('is_channel') else '┘Д╪з'}\n"
            success_msg += f"ЁЯФУ **┘Е╪м┘Е┘И╪╣╪й ┘Г╪и┘К╪▒╪й:** {'┘Ж╪╣┘Е' if result.get('is_megagroup') else '┘Д╪з'}\n\n"
            
            # ╪╡┘Д╪з╪н┘К╪з╪к ╪з┘Д╪е╪▒╪│╪з┘Д
            if result.get('can_send'):
                success_msg += "тЬЕ **╪з┘Д╪╡┘Д╪з╪н┘К╪з╪к:** ╪з┘Д╪и┘И╪к ┘К┘Е┘Г┘Ж┘З ╪з┘Д╪е╪▒╪│╪з┘Д\n"
            else:
                success_msg += "тЭМ **╪з┘Д╪╡┘Д╪з╪н┘К╪з╪к:** ╪з┘Д╪и┘И╪к ┘Д╪з ┘К┘Е┘Г┘Ж┘З ╪з┘Д╪е╪▒╪│╪з┘Д\n"
                if 'permission_error' in result:
                    success_msg += f"**╪з┘Д╪│╪и╪и:** {result['permission_error']}\n"
            
            # ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Е╪н╪к┘И┘Й
            success_msg += f"\nЁЯУИ **╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д┘Е╪н╪к┘И┘Й:**\n"
            success_msg += f"тАв ╪▒╪│╪з╪ж┘Д ╪н╪п┘К╪л╪й: {result.get('recent_messages', 0)}\n"
            success_msg += f"тАв ┘Е┘Д┘Б╪з╪к ╪╡┘И╪к┘К╪й: {result.get('recent_audio_files', 0)}\n"
            
            # ╪е╪╢╪з┘Б╪й ┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е┘Ж ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
            try:
                conn = sqlite3.connect(DB_FILE)
                cursor = conn.cursor()
                
                cursor.execute("SELECT COUNT(*) FROM channel_index")
                total_cached = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM channel_index WHERE last_accessed > datetime('now', '-7 days')")
                recent_accessed = cursor.fetchone()[0]
                
                conn.close()
                
                success_msg += f"\nЁЯТ╛ **┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к:**\n"
                success_msg += f"тАв ╪е╪м┘Е╪з┘Д┘К ╪з┘Д┘Е╪н┘Б┘И╪╕: {total_cached}\n"
                success_msg += f"тАв ╪з╪│╪к┘П╪о╪п┘Е ┘Е╪д╪о╪▒╪з┘Л: {recent_accessed}\n"
                
            except Exception as db_error:
                success_msg += f"\nтЪая╕П **┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к:** ╪о╪╖╪г ┘Б┘К ╪з┘Д┘В╪▒╪з╪б╪й\n"
            
            await event.reply(success_msg)
        
    except Exception as e:
        await event.reply(f"тЭМ **╪о╪╖╪г:** {e}")

async def test_cache_channel_handler(event):
    """┘Е╪╣╪з┘Д╪м ╪г┘Е╪▒ ╪з┘Д┘Е╪╖┘И╪▒ ┘Д╪з╪о╪к╪и╪з╪▒ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        await event.reply("ЁЯзк **╪и╪п╪б ╪з╪о╪к╪и╪з╪▒ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж...**")
        
        # ┘Б╪н╪╡ ╪з┘Д┘В┘Ж╪з╪й ╪г┘И┘Д╪з┘Л
        result = await verify_cache_channel(event.client)
        
        if result['status'] == 'error':
            await event.reply(f"тЭМ **┘Б╪┤┘Д ╪з┘Д╪з╪о╪к╪и╪з╪▒:** {result['message']}")
            return
        
        # ╪з╪о╪к╪и╪з╪▒ ╪н┘Б╪╕ ┘Е┘Д┘Б ╪к╪м╪▒┘К╪и┘К
        import tempfile
        import os
        
        # ╪е┘Ж╪┤╪з╪б ┘Е┘Д┘Б ╪╡┘И╪к┘К ╪к╪м╪▒┘К╪и┘К
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
            # ┘Г╪к╪з╪и╪й ╪и┘К╪з┘Ж╪з╪к ╪к╪м╪▒┘К╪и┘К╪й (┘Е┘Д┘Б ┘Б╪з╪▒╪║)
            temp_file.write(b'test audio data')
            temp_path = temp_file.name
        
        try:
            # ┘Е╪н╪з┘И┘Д╪й ╪н┘Б╪╕ ┘Б┘К ╪з┘Д╪к╪о╪▓┘К┘Ж ╪з┘Д╪░┘Г┘К
            test_result = {
                'title': '╪з╪о╪к╪и╪з╪▒ ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪░┘Г┘К',
                'uploader': 'ZeMusic Test Bot',
                'duration': 30,
                'file_size': 1024,
                'source': 'test_system',
                'elapsed': 0.5
            }
            
            success = await save_to_smart_cache(
                event.client, 
                temp_path, 
                test_result, 
                '╪з╪о╪к╪и╪з╪▒ ╪з┘Д┘Ж╪╕╪з┘Е',
                None  # ┘Д╪з ╪к┘И╪м╪п ╪╡┘И╪▒╪й ┘Е╪╡╪║╪▒╪й ┘Б┘К ╪з┘Д╪з╪о╪к╪и╪з╪▒
            )
            
            if success:
                await event.reply("тЬЕ **┘Ж╪м╪н ╪з┘Д╪з╪о╪к╪и╪з╪▒!**\n\nЁЯОп ╪к┘Е ╪н┘Б╪╕ ┘Е┘Д┘Б ╪к╪м╪▒┘К╪и┘К ╪и┘Ж╪м╪з╪н\nЁЯТ╛ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ┘Е╪н╪п╪л╪й\nЁЯЪА ╪з┘Д┘Ж╪╕╪з┘Е ╪м╪з┘З╪▓ ┘Д┘Д╪╣┘Е┘Д")
            else:
                await event.reply("тЭМ **┘Б╪┤┘Д ╪з┘Д╪з╪о╪к╪и╪з╪▒:** ┘Д┘Е ┘К╪к┘Е ╪н┘Б╪╕ ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪к╪м╪▒┘К╪и┘К")
            
        finally:
            # ╪н╪░┘Б ╪з┘Д┘Е┘Д┘Б ╪з┘Д╪к╪м╪▒┘К╪и┘К
            if os.path.exists(temp_path):
                os.remove(temp_path)
        
    except Exception as e:
        await event.reply(f"тЭМ **╪о╪╖╪г ┘Б┘К ╪з┘Д╪з╪о╪к╪и╪з╪▒:** {e}")
        import traceback
        LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ╪з╪о╪к╪и╪з╪▒ ╪з┘Д┘В┘Ж╪з╪й: {traceback.format_exc()}")

# ╪к╪н╪п┘К╪л ┘Е╪╣╪з┘Д╪м ╪з┘Д╪и╪н╪л ┘Д┘К╪┤┘Е┘Д ┘Б╪н╪╡ ╪з┘Д┘В┘Ж╪з╪й ╪з┘Д╪к┘Д┘В╪з╪ж┘К

async def smart_download_handler(event):
    """╪з┘Д┘Е╪╣╪з┘Д╪м ╪з┘Д╪░┘Г┘К ┘Д┘Д╪к╪н┘Е┘К┘Д ╪з┘Д┘Б┘И╪▒┘К ╪з┘Д┘Е╪к┘И╪з╪▓┘К ┘Е╪╣ ┘Е╪▓╪з┘Е┘Ж╪й ╪к┘Д┘В╪з╪ж┘К╪й ┘И┘Б╪н╪╡ ╪з┘Д┘В┘Ж╪з╪й"""
    start_time = time.time()
    user_id = event.sender_id
    
    try:
        # ╪к╪к╪и╪╣ ┘Е╪╣╪п┘Д ╪з┘Д╪╖┘Д╪и╪з╪к (┘Д┘Д╪е╪н╪╡╪з╪ж┘К╪з╪к ┘Б┘В╪╖)
        await check_rate_limit(user_id)
        
        # ╪к┘З┘К╪ж╪й ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к ╪е╪░╪з ┘Д┘Е ╪к┘Г┘Ж ┘Е┘З┘К╪г╪й
        await ensure_database_initialized()
        
        # ┘Б╪н╪╡ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪и╪┤┘Г┘Д ╪п┘И╪▒┘К (┘Г┘Д 50 ╪╖┘Д╪и)
        if PERFORMANCE_STATS['total_requests'] % 50 == 0:
            asyncio.create_task(verify_cache_channel_periodic(event.client))
        
        # ╪з┘Д┘Е╪▓╪з┘Е┘Ж╪й ╪з┘Д╪к┘Д┘В╪з╪ж┘К╪й ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж (┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й)
        asyncio.create_task(auto_sync_channel_if_needed(event.client))
        
        # ╪к┘Ж╪╕┘К┘Б ╪п┘И╪▒┘К ┘Д┘Д┘Г┘И┘Г┘К╪▓ ╪з┘Д┘Е╪н╪╕┘И╪▒╪й (┘Г┘Д 100 ╪╖┘Д╪и)
        if PERFORMANCE_STATS['total_requests'] % 100 == 0:
            cleanup_blocked_cookies()
        
        # ╪╣╪▒╪╢ ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б (┘Г┘Д 50 ╪╖┘Д╪и)
        if PERFORMANCE_STATS['total_requests'] % 50 == 0:
            log_performance_stats()
        
        # ┘Б╪н╪╡ ╪з┘Д╪╡┘Д╪з╪н┘К╪з╪к
        chat_id = event.chat_id
        if chat_id > 0:  # ┘Е╪н╪з╪п╪л╪й ╪о╪з╪╡╪й
            if not await is_search_enabled1():
                await event.reply("тЯб ╪╣╪░╪▒╪з┘Л ╪╣╪▓┘К╪▓┘К ╪з┘Д┘К┘И╪к┘К┘И╪и ┘Е╪╣╪╖┘Д ┘Е┘Ж ┘В╪и┘Д ╪з┘Д┘Е╪╖┘И╪▒")
                return
        else:  # ┘Е╪м┘Е┘И╪╣╪й ╪г┘И ┘В┘Ж╪з╪й
            if not await is_search_enabled(chat_id):
                await event.reply("тЯб ╪╣╪░╪▒╪з┘Л ╪╣╪▓┘К╪▓┘К ╪з┘Д┘К┘И╪к┘К┘И╪и ┘Е╪╣╪╖┘Д ┘Е┘Ж ┘В╪и┘Д ╪з┘Д┘Е╪╖┘И╪▒")
                return
                
        # ┘Е╪╣╪з┘Д╪м╪й ┘Б┘И╪▒┘К╪й ╪и╪п┘И┘Ж ╪н╪п┘И╪п ┘Е╪╣ ╪к╪н╪│┘К┘Ж╪з╪к ╪е╪╢╪з┘Б┘К╪й
        LOGGER(__name__).info(f"ЁЯЪА ┘Е╪╣╪з┘Д╪м╪й ╪░┘Г┘К╪й ┘Е╪н╪│┘Ж╪й ┘Д┘Д┘Е╪│╪к╪о╪п┘Е {user_id} - ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {len(active_downloads)}")
        
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ┘Б╪н╪╡ ╪з┘Д╪н┘Е┘И┘Д╪й ╪з┘Д┘Е╪н╪│┘Ж: {e}")
        await update_performance_stats(False, time.time() - start_time)
        return
    
    # ╪к┘Ж╪╕┘К┘Б ╪п┘И╪▒┘К ┘Д┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘В╪п┘К┘Е╪й (┘Г┘Д 50 ╪╖┘Д╪и)
    # if len(active_downloads) % 50 == 0:
    #     asyncio.create_task(cleanup_old_downloads())
    
    # ╪к╪н┘Г┘Е ╪░┘Г┘К ┘Б┘К ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Е╪к┘И╪з╪▓┘К╪й
    current_downloads = len(active_downloads)
    
    if current_downloads < MAX_CONCURRENT_DOWNLOADS:
        # ╪к┘Ж┘Б┘К╪░ ╪з┘Д┘Е╪╣╪з┘Д╪м╪й ╪з┘Д┘Б┘И╪▒┘К╪й ╪з┘Д┘Е╪к┘И╪з╪▓┘К╪й ╪з┘Д┘Е╪н╪│┘Ж╪й
        asyncio.create_task(process_unlimited_download_enhanced(event, user_id, start_time))
        LOGGER(__name__).info(f"тЪб ╪к┘Е ╪е┘Ж╪┤╪з╪б ┘Е┘З┘Е╪й ┘Е╪к┘И╪з╪▓┘К╪й ┘Е╪н╪│┘Ж╪й ┘Д┘Д┘Е╪│╪к╪о╪п┘Е {user_id} - ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {current_downloads + 1}")
    else:
        # ╪е╪░╪з ╪к╪м╪з┘И╪▓┘Ж╪з ╪з┘Д╪н╪п╪М ┘Ж┘Ж╪к╪╕╪▒ ┘В┘Д┘К┘Д╪з┘Л ╪л┘Е ┘Ж╪н╪з┘И┘Д ┘Е╪▒╪й ╪г╪о╪▒┘Й
        LOGGER(__name__).info(f"тП│ ╪к╪г╪м┘К┘Д ╪з┘Д╪╖┘Д╪и - ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {current_downloads} (╪з┘Д╪н╪п ╪з┘Д╪г┘В╪╡┘Й: {MAX_CONCURRENT_DOWNLOADS})")
        
        async def delayed_process():
            await asyncio.sleep(0.5)  # ╪з┘Ж╪к╪╕╪з╪▒ ┘Ж╪╡┘Б ╪л╪з┘Ж┘К╪й
            if len(active_downloads) < MAX_CONCURRENT_DOWNLOADS:
                await process_unlimited_download_enhanced(event, user_id, start_time)
            else:
                # ╪е╪░╪з ┘Д╪з ┘К╪▓╪з┘Д ┘Е╪▓╪п╪н┘Е╪з┘Л╪М ┘Ж┘Ж╪┤╪ж ╪з┘Д┘Е┘З┘Е╪й ╪и╪г┘К ╪н╪з┘Д
                asyncio.create_task(process_unlimited_download_enhanced(event, user_id, start_time))
        
        asyncio.create_task(delayed_process())

async def cleanup_old_downloads():
    """╪к┘Ж╪╕┘К┘Б ╪п┘И╪▒┘К ┘Д┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘В╪п┘К┘Е╪й ┘Д┘Е┘Ж╪╣ ╪к╪▒╪з┘Г┘Е┘З╪з"""
    try:
        current_time = time.time()
        old_tasks = []
        
        for task_id, task_info in active_downloads.items():
            # ╪е╪░╪з ┘Е╪▒╪к ╪г┘Г╪л╪▒ ┘Е┘Ж 10 ╪п┘В╪з╪ж┘В ╪╣┘Д┘Й ╪з┘Д╪╣┘Е┘Д┘К╪й╪М ╪з╪н╪░┘Б┘З╪з
            if current_time - task_info.get('start_time', current_time) > 600:
                old_tasks.append(task_id)
        
        for task_id in old_tasks:
            del active_downloads[task_id]
            LOGGER(__name__).info(f"ЁЯз╣ ╪к┘Е ╪к┘Ж╪╕┘К┘Б ╪╣┘Е┘Д┘К╪й ┘В╪п┘К┘Е╪й: {task_id}")
            
        if old_tasks:
            LOGGER(__name__).info(f"ЁЯз╣ ╪к┘Е ╪к┘Ж╪╕┘К┘Б {len(old_tasks)} ╪╣┘Е┘Д┘К╪й ┘В╪п┘К┘Е╪й - ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {len(active_downloads)}")
            
    except Exception as e:
        LOGGER(__name__).warning(f"тЪая╕П ╪о╪╖╪г ┘Б┘К ╪к┘Ж╪╕┘К┘Б ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘В╪п┘К┘Е╪й: {e}")

async def verify_cache_channel_periodic(bot_client):
    """┘Б╪н╪╡ ╪п┘И╪▒┘К ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ┘Б┘К ╪з┘Д╪о┘Д┘Б┘К╪й"""
    try:
        result = await verify_cache_channel(bot_client)
        
        if result['status'] == 'error':
            LOGGER(__name__).warning(f"тЪая╕П ┘Е╪┤┘Г┘Д╪й ┘Б┘К ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {result['message']}")
        else:
            LOGGER(__name__).info(f"тЬЕ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж ╪к╪╣┘Е┘Д ╪и╪┤┘Г┘Д ╪╖╪и┘К╪╣┘К: {result['title']}")
            
    except Exception as e:
        LOGGER(__name__).error(f"тЭМ ╪о╪╖╪г ┘Б┘К ╪з┘Д┘Б╪н╪╡ ╪з┘Д╪п┘И╪▒┘К ┘Д┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж: {e}")

# ╪е╪╢╪з┘Б╪й ╪п╪з┘Д╪й ┘Д╪╣╪▒╪╢ ╪н╪з┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪┤╪з┘Е┘Д╪й
async def system_status_handler(event):
    """┘Е╪╣╪з┘Д╪м ╪г┘Е╪▒ ╪з┘Д┘Е╪╖┘И╪▒ ┘Д╪╣╪▒╪╢ ╪н╪з┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪┤╪з┘Е┘Д╪й"""
    import config
    if event.sender_id != config.OWNER_ID:
        return
    
    try:
        await event.reply("ЁЯУК **╪м╪з╪▒┘К ┘Б╪н╪╡ ╪н╪з┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪┤╪з┘Е┘Д╪й...**")
        
        # ┘Б╪н╪╡ ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
        cache_status = await verify_cache_channel(event.client)
        
        # ┘Б╪н╪╡ ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        try:
            conn = sqlite3.connect(DB_FILE)
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(*) FROM channel_index")
            total_cached = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM channel_index WHERE last_accessed > datetime('now', '-1 day')")
            daily_accessed = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM channel_index WHERE created_at > datetime('now', '-1 day')")
            daily_added = cursor.fetchone()[0]
            
            cursor.execute("SELECT AVG(popularity_rank) FROM channel_index")
            avg_popularity = cursor.fetchone()[0] or 0
            
            conn.close()
            
            db_status = {
                'working': True,
                'total_cached': total_cached,
                'daily_accessed': daily_accessed,
                'daily_added': daily_added,
                'avg_popularity': avg_popularity
            }
            
        except Exception as db_error:
            db_status = {
                'working': False,
                'error': str(db_error)
            }
        
        # ┘Б╪н╪╡ ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓
        cookies_stats = get_cookies_statistics()
        
        # ╪е╪╣╪п╪з╪п ╪▒╪│╪з┘Д╪й ╪з┘Д╪н╪з┘Д╪й ╪з┘Д╪┤╪з┘Е┘Д╪й
        status_msg = "ЁЯУК **╪н╪з┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е ╪з┘Д╪┤╪з┘Е┘Д╪й**\n\n"
        
        # ╪н╪з┘Д╪й ┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж
        if cache_status['status'] == 'success':
            status_msg += f"тЬЕ **┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж:** ╪к╪╣┘Е┘Д ╪и╪┤┘Г┘Д ╪╖╪и┘К╪╣┘К\n"
            status_msg += f"   ЁЯУЭ ╪з┘Д╪╣┘Ж┘И╪з┘Ж: {cache_status['title']}\n"
            status_msg += f"   ЁЯО╡ ┘Е┘Д┘Б╪з╪к ╪╡┘И╪к┘К╪й: {cache_status.get('recent_audio_files', 0)}\n"
            status_msg += f"   ЁЯУд ╪╡┘Д╪з╪н┘К╪й ╪з┘Д╪е╪▒╪│╪з┘Д: {'тЬЕ' if cache_status.get('can_send') else 'тЭМ'}\n"
        else:
            status_msg += f"тЭМ **┘В┘Ж╪з╪й ╪з┘Д╪к╪о╪▓┘К┘Ж:** ┘Е╪┤┘Г┘Д╪й\n"
            status_msg += f"   тЪая╕П {cache_status['message']}\n"
        
        status_msg += "\n"
        
        # ╪н╪з┘Д╪й ┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к
        if db_status['working']:
            status_msg += f"тЬЕ **┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к:** ╪к╪╣┘Е┘Д ╪и╪┤┘Г┘Д ╪╖╪и┘К╪╣┘К\n"
            status_msg += f"   ЁЯТ╛ ╪е╪м┘Е╪з┘Д┘К ╪з┘Д┘Е╪н┘Б┘И╪╕: {db_status['total_cached']}\n"
            status_msg += f"   ЁЯУИ ╪з╪│╪к┘П╪о╪п┘Е ╪з┘Д┘К┘И┘Е: {db_status['daily_accessed']}\n"
            status_msg += f"   тЮХ ╪г┘П╪╢┘К┘Б ╪з┘Д┘К┘И┘Е: {db_status['daily_added']}\n"
            status_msg += f"   тнР ┘Е╪к┘И╪│╪╖ ╪з┘Д╪┤╪╣╪и┘К╪й: {db_status['avg_popularity']:.2f}\n"
        else:
            status_msg += f"тЭМ **┘В╪з╪╣╪п╪й ╪з┘Д╪и┘К╪з┘Ж╪з╪к:** ┘Е╪┤┘Г┘Д╪й\n"
            status_msg += f"   тЪая╕П {db_status['error']}\n"
        
        status_msg += "\n"
        
        # ╪н╪з┘Д╪й ┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓
        if cookies_stats:
            status_msg += f"ЁЯНк **┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓:**\n"
            status_msg += f"   ЁЯУК ╪з┘Д╪е╪м┘Е╪з┘Д┘К: {cookies_stats.get('total', 0)}\n"
            status_msg += f"   тЬЕ ╪з┘Д┘Е╪к╪з╪н: {cookies_stats.get('available', 0)}\n"
            status_msg += f"   ЁЯЪл ╪з┘Д┘Е╪н╪╕┘И╪▒: {cookies_stats.get('blocked', 0)}\n"
            status_msg += f"   ЁЯПЖ ╪з┘Д╪г┘Г╪л╪▒ ╪з╪│╪к╪о╪п╪з┘Е╪з┘Л: {cookies_stats.get('most_used_file', '┘Д╪з ┘К┘И╪м╪п')}\n"
        else:
            status_msg += f"тЭМ **┘Е┘Д┘Б╪з╪к ╪з┘Д┘Г┘И┘Г┘К╪▓:** ╪║┘К╪▒ ┘Е╪к╪з╪н╪й\n"
        
        status_msg += "\n"
        
        # ╪е╪н╪╡╪з╪ж┘К╪з╪к ╪з┘Д╪г╪п╪з╪б
        stats = PERFORMANCE_STATS
        success_rate = (stats['successful_downloads'] / max(stats['total_requests'], 1)) * 100
        cache_hit_rate = (stats['cache_hits'] / max(stats['total_requests'], 1)) * 100
        
        status_msg += f"тЪб **╪з┘Д╪г╪п╪з╪б:**\n"
        status_msg += f"   ЁЯФв ╪е╪м┘Е╪з┘Д┘К ╪з┘Д╪╖┘Д╪и╪з╪к: {stats['total_requests']}\n"
        status_msg += f"   тЬЕ ┘Ж╪│╪и╪й ╪з┘Д┘Ж╪м╪з╪н: {success_rate:.1f}%\n"
        status_msg += f"   ЁЯТ╛ ┘Ж╪│╪и╪й ╪з┘Д┘Г╪з╪┤: {cache_hit_rate:.1f}%\n"
        status_msg += f"   тП▒я╕П ┘Е╪к┘И╪│╪╖ ╪з┘Д┘И┘В╪к: {stats['avg_response_time']:.2f}s\n"
        status_msg += f"   ЁЯФД ╪з┘Д╪╣┘Е┘Д┘К╪з╪к ╪з┘Д┘Ж╪┤╪╖╪й: {stats['current_concurrent']}\n"
        status_msg += f"   ЁЯПФя╕П ╪з┘Д╪░╪▒┘И╪й: {stats['peak_concurrent']}\n"
        
        # ╪е╪╢╪з┘Б╪й ┘Е╪╣┘Д┘И┘Е╪з╪к ╪з┘Д┘Ж╪╕╪з┘Е
        import psutil
        memory = psutil.virtual_memory()
        cpu = psutil.cpu_percent()
        
        status_msg += f"\nЁЯЦея╕П **╪з┘Д┘Ж╪╕╪з┘Е:**\n"
        status_msg += f"   ЁЯза ╪з┘Д╪░╪з┘Г╪▒╪й: {memory.percent}% ({memory.used//1024//1024}MB)\n"
        status_msg += f"   тЪЩя╕П ╪з┘Д┘Е╪╣╪з┘Д╪м: {cpu}%\n"
        status_msg += f"   ЁЯХР ┘И┘В╪к ╪з┘Д╪к╪┤╪║┘К┘Д: {time.time() - start_time:.0f}s\n"
        
        await event.reply(status_msg)
        
    except Exception as e:
        await event.reply(f"тЭМ **╪о╪╖╪г ┘Б┘К ┘Б╪н╪╡ ╪з┘Д┘Ж╪╕╪з┘Е:** {e}")
        import traceback
        LOGGER(__name__).error(f"╪о╪╖╪г ┘Б┘К ┘Б╪н╪╡ ╪н╪з┘Д╪й ╪з┘Д┘Ж╪╕╪з┘Е: {traceback.format_exc()}")
